<!DOCTYPE html>
<html><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>My New Hugo Site | R funciones</title>
    <meta name="description" content=" ">
    <link rel="canonical" href="http://example.org/tags/r-funciones/" />
    <link rel="icon" type="image/x-icon" href="/images/favicon.ico">
    <meta property="og:title" content="R funciones" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://example.org/tags/r-funciones/" />

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="R funciones"/>
<meta name="twitter:description" content=""/>

    
        
    

    <link rel="stylesheet" href='/css/style.css' />
    <link rel="stylesheet" href='/css/search.css' />
    <link rel="stylesheet" href='/css/md_nb.css' />
    <link rel="stylesheet" href='/css/list.css' />
    <link rel="stylesheet" href='/css/terms.css' />
    <link rel="stylesheet" href='/css/taxonomy.css' />
    <link rel="stylesheet" href='/css/font-awesome-4.7.0/css/font-awesome.min.css' />
    <link rel="stylesheet" href='/css/home.css' />
    <link rel="stylesheet" href='/css/syntax.css' />
    
    <link rel="stylesheet" href='/css/shortcode.css' />
    
    
    <link rel="stylesheet" href='/css/_custom.css' />
    <style>
         
    </style>
    
    
    
    
    <script src="/js/lazysizes.min.js" async=""></script>
    <script src="https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>
    <script src="/js/search.js"></script>
    <script src="/js/md_nb.js"></script>
    <script src="/js/yes.js"></script>
    
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
</head><body style="font-family: ,'Helvetica Neue', Helvetica, Arial, 'PingFang SC', 'Hiragino Sans GB', 'Heiti SC', 'Microsoft YaHei', 'WenQuanYi Micro Hei', sans-serif;">
        <div class="loading">
            <div class="loading-bg"></div>
            <div class="loading-long">
                <div class="loading-short"></div>
            </div>
        </div>

        <header>
    <nav class="navbar">
        <div class="navbar-brand">
            <a href="/">
                <span class="logo">My New Hugo Site</span>
            </a>
        </div>
        <div class="navbar-menu">
            
                <a href="/">
                    <div class="menu-item">
                        <div class="hengtiao-root">
                            <div class="hengtiao"></div>
                            <div class="name text-wbd-reverse"><i class='fa fa-home'></i> Home</div>
                        </div>
                    </div>
                </a>
            
                <a href="/posts">
                    <div class="menu-item">
                        <div class="hengtiao-root">
                            <div class="hengtiao"></div>
                            <div class="name text-wbd-reverse"><i class='fa fa-book'></i> Posts</div>
                        </div>
                    </div>
                </a>
            
                <a href="/categories">
                    <div class="menu-item">
                        <div class="hengtiao-root">
                            <div class="hengtiao"></div>
                            <div class="name text-wbd-reverse"><i class='fa fa-folder-open'></i> Categories</div>
                        </div>
                    </div>
                </a>
            
                <a href="/series">
                    <div class="menu-item">
                        <div class="hengtiao-root">
                            <div class="hengtiao"></div>
                            <div class="name text-wbd-reverse"><i class='fa fa-gears'></i> Series</div>
                        </div>
                    </div>
                </a>
            
                <a href="/tags">
                    <div class="menu-item">
                        <div class="hengtiao-root">
                            <div class="hengtiao"></div>
                            <div class="name text-wbd-reverse"><i class='fa fa-tags'></i> Tags</div>
                        </div>
                    </div>
                </a>
            
                <a href="/about">
                    <div class="menu-item">
                        <div class="hengtiao-root">
                            <div class="hengtiao"></div>
                            <div class="name text-wbd-reverse"><i class='fa fa-info-circle'></i> About</div>
                        </div>
                    </div>
                </a>
            
            <div class="navbar-burger">
                <div class="burger-btn"><span><i class="fa fa-navicon"></i></span></div>
            </div>
            
                
<div class="lang-box-up">
    <div class="lang-box">
        <div class="lang-now">English</div>
        <div class="wait-lang-box">
            <ul class="lang-up">
                
                <li data—permalink="http://example.org/" class="lang">English</li>
                
                <li data—permalink="http://example.org/es/" class="lang">Español</li>
                
            </ul>
        </div>
    </div>
</div>

<script type="text/javascript">
    var nowIsDefaultLang =  true ;
</script>
            
            
            <div class="search-in"><span><i class="fa fa-search"></i></span></div>
            
                <div class="mode">
                    <span class="sun"><i class="fa fa-sun-o"></i></span>
                    <span class="moon"><i class="fa fa-moon-o"></i></span>
                </div>
            
        </div>
    </nav>
    <div class="burger-items">
        
        <a href="/">
            <div class="burger-item">
                <i class='fa fa-home'></i> Home
            </div>
        </a>
        
        <a href="/posts">
            <div class="burger-item">
                <i class='fa fa-book'></i> Posts
            </div>
        </a>
        
        <a href="/categories">
            <div class="burger-item">
                <i class='fa fa-folder-open'></i> Categories
            </div>
        </a>
        
        <a href="/series">
            <div class="burger-item">
                <i class='fa fa-gears'></i> Series
            </div>
        </a>
        
        <a href="/tags">
            <div class="burger-item">
                <i class='fa fa-tags'></i> Tags
            </div>
        </a>
        
        <a href="/about">
            <div class="burger-item">
                <i class='fa fa-info-circle'></i> About
            </div>
        </a>
        
    </div>
    <div class="header-rest"></div>
</header>


        <div id="content">
    






    
        
    




    <div class="hero">
        
            
                <div class="hero-img">
                    <img class="lazyload" src="/images/thumbnail.gif" data-src="/images/default.jpg" alt="">
                </div>
            
        <div class="hero-content">
            <h1 class="hero-title">Tag: R funciones</h1>
        </div>
    </div>




<div class="zhuti-0">
    <div class="container">
        <div class="zhuti">
            <div class="zhuti-l">
                




    


<div class="terms-body">
    <div class="long">
        <button class="tosides-1 text-wbd">
            <i class="fa fa-arrow-right"></i>
        </button>
        <button class="tosides-2 text-wbd">
            <i class="fa fa-arrow-left"></i>
        </button>
        <button class="toup text-wbd">
            <i class="fa fa-arrow-up"></i>
        </button>
    </div>
    
        <div class="terms-row">
            
            <div class="terms-root">
                
                



<div class="card-large">
    <div class="card-large-img">

        
                <img class="lazyload" src="/images/thumbnail.gif" data-src="/images/default.jpg" alt='image loading failed'>
        
    </div>
    <div class="card-large-content">
        <div class="up-title"><a href="http://example.org/es/posts/2023/webscrap_e_iteracion_con_r/">Webscrap e iteraciones con R</a></div>
        <div class="up-date">
            <span class="no-wrap"><i class="fa fa-calendar"></i> postedOn: 2023-3-24 &nbsp;</span>
            <span class="no-wrap"><i class="fa fa-calendar-check-o"></i> updatedOn: 2023-3-24 &nbsp;</span>
            <span class="no-wrap"><i class="fa fa-folder"></i>
                
                    includedIn:
                    
                        <a href='
                                        /categories/r
                                    '>
                                R
                            </a>
                
            </span>
        </div>
        <div class="down-summary">Sobre este post Estamos creando mapas de datos que muestran los cambios durante un período de tiempo para diferentes países y orientado a todo tipo de ciudades. Esto básicamente significa que necesitamos mapear cualquier región del mundo con R. Hoy en día existen todo tipo de paquetes y técnicas para hacerlo.</div>
    </div>
    <div class="card-readmore">
        <a href="http://example.org/es/posts/2023/webscrap_e_iteracion_con_r/">
            <span><i class="fa fa-arrow-right"></i></span>
        </a>
    </div>
</div>



    


    <div class="down-type">
        
        <span class="down-type-item">
            <div class="shuxian-root">
                <div class="shuxian"></div>
            </div>
            <div class="type-text">
                <a href='
                            /tags/maps-app
                        '>
                    <i class="fa fa-tag"></i> maps-app
                </a>
            </div>
        </span>
        
        <span class="down-type-item">
            <div class="shuxian-root">
                <div class="shuxian"></div>
            </div>
            <div class="type-text">
                <a href='
                            /tags/r-mapas
                        '>
                    <i class="fa fa-tag"></i> R mapas
                </a>
            </div>
        </span>
        
        <span class="down-type-item">
            <div class="shuxian-root">
                <div class="shuxian"></div>
            </div>
            <div class="type-text">
                <a href='
                            /tags/r-funciones
                        '>
                    <i class="fa fa-tag"></i> R funciones
                </a>
            </div>
        </span>
        
        <span class="down-type-item">
            <div class="shuxian-root">
                <div class="shuxian"></div>
            </div>
            <div class="type-text">
                <a href='
                            /tags/web-scrap
                        '>
                    <i class="fa fa-tag"></i> web-scrap
                </a>
            </div>
        </span>
        
        <span class="down-type-item">
            <div class="shuxian-root">
                <div class="shuxian"></div>
            </div>
            <div class="type-text">
                <a href='
                            /tags/database
                        '>
                    <i class="fa fa-tag"></i> database
                </a>
            </div>
        </span>
        
        <span class="down-type-item">
            <div class="shuxian-root">
                <div class="shuxian"></div>
            </div>
            <div class="type-text">
                <a href='
                            /tags/recursion
                        '>
                    <i class="fa fa-tag"></i> recursion
                </a>
            </div>
        </span>
        
    </div>

<div class="dang"></div>
            </div>
            
            <div class="terms-root">
                
                



<div class="card-large">
    <div class="card-large-img">

        
                <img class="lazyload" src="/images/thumbnail.gif" data-src="/post/2022/EDA_INEGI_data/INEGI.jpg" alt='image loading failed'>
        
    </div>
    <div class="card-large-content">
        <div class="up-title"><a href="http://example.org/es/posts/2022/eda_inegi_datos/">EDA de datos de INEGI</a></div>
        <div class="up-date">
            <span class="no-wrap"><i class="fa fa-calendar"></i> postedOn: 2022-11-29 &nbsp;</span>
            <span class="no-wrap"><i class="fa fa-calendar-check-o"></i> updatedOn: 2022-11-29 &nbsp;</span>
            <span class="no-wrap"><i class="fa fa-folder"></i>
                
                    includedIn:
                    
                        <a href='
                                        /categories/r
                                    '>
                                R
                            </a>
                
            </span>
        </div>
        <div class="down-summary">Introducción El análisis exploratorio de datos (EDA en inglés, &ldquo;Exploratory Data Analysis&rdquo;) es una de las herramientas más útiles en varias áreas de análisis de datos. El concepto de EDA ha sido utilizado popularmente en los últimos años para referirse a los procesos de exploración primaria de un grupo de datos.</div>
    </div>
    <div class="card-readmore">
        <a href="http://example.org/es/posts/2022/eda_inegi_datos/">
            <span><i class="fa fa-arrow-right"></i></span>
        </a>
    </div>
</div>



    


    <div class="down-type">
        
        <span class="down-type-item">
            <div class="shuxian-root">
                <div class="shuxian"></div>
            </div>
            <div class="type-text">
                <a href='
                            /tags/ggplot2
                        '>
                    <i class="fa fa-tag"></i> ggplot2
                </a>
            </div>
        </span>
        
        <span class="down-type-item">
            <div class="shuxian-root">
                <div class="shuxian"></div>
            </div>
            <div class="type-text">
                <a href='
                            /tags/r-basics
                        '>
                    <i class="fa fa-tag"></i> R basics
                </a>
            </div>
        </span>
        
        <span class="down-type-item">
            <div class="shuxian-root">
                <div class="shuxian"></div>
            </div>
            <div class="type-text">
                <a href='
                            /tags/r-funciones
                        '>
                    <i class="fa fa-tag"></i> R funciones
                </a>
            </div>
        </span>
        
        <span class="down-type-item">
            <div class="shuxian-root">
                <div class="shuxian"></div>
            </div>
            <div class="type-text">
                <a href='
                            /tags/r-tips
                        '>
                    <i class="fa fa-tag"></i> R tips
                </a>
            </div>
        </span>
        
        <span class="down-type-item">
            <div class="shuxian-root">
                <div class="shuxian"></div>
            </div>
            <div class="type-text">
                <a href='
                            /tags/data-analysis
                        '>
                    <i class="fa fa-tag"></i> data analysis
                </a>
            </div>
        </span>
        
    </div>

<div class="dang"></div>
            </div>
            
            <div class="terms-root">
                
                



<div class="card-large">
    <div class="card-large-img">

        
                <img class="lazyload" src="/images/thumbnail.gif" data-src="/post/2022/map_any_region_with_ggplot2_part_I/maps_DrawingMap.png" alt='image loading failed'>
        
    </div>
    <div class="card-large-content">
        <div class="up-title"><a href="http://example.org/es/posts/2022/mapa_de_cualquier_region_con_ggplot2_i/">Mapa de cualquier región del mundo con R - Parte I: El mapa base</a></div>
        <div class="up-date">
            <span class="no-wrap"><i class="fa fa-calendar"></i> postedOn: 2022-10-8 &nbsp;</span>
            <span class="no-wrap"><i class="fa fa-calendar-check-o"></i> updatedOn: 2022-10-8 &nbsp;</span>
            <span class="no-wrap"><i class="fa fa-folder"></i>
                
                    includedIn:
                    
                        <a href='
                                        /categories/r
                                    '>
                                R
                            </a>
                
            </span>
        </div>
        <div class="down-summary">Pueden encontrar todas las publicaciones en este tema bajo la etiqueta maps-app (incluyendo las versiones en inglés).
También pueden encontrar el estado actual del proyecto en mi GitHub repo mapic.
Sobre esta entrada Cuando nos preparamos para una entrevista de trabajo, una de las preguntas que más recomiendan preparar es &ldquo;Menciona el proyecto del que estés más orgulloso?</div>
    </div>
    <div class="card-readmore">
        <a href="http://example.org/es/posts/2022/mapa_de_cualquier_region_con_ggplot2_i/">
            <span><i class="fa fa-arrow-right"></i></span>
        </a>
    </div>
</div>



    


    <div class="down-type">
        
        <span class="down-type-item">
            <div class="shuxian-root">
                <div class="shuxian"></div>
            </div>
            <div class="type-text">
                <a href='
                            /tags/maps-app
                        '>
                    <i class="fa fa-tag"></i> maps-app
                </a>
            </div>
        </span>
        
        <span class="down-type-item">
            <div class="shuxian-root">
                <div class="shuxian"></div>
            </div>
            <div class="type-text">
                <a href='
                            /tags/r-mapas
                        '>
                    <i class="fa fa-tag"></i> R mapas
                </a>
            </div>
        </span>
        
        <span class="down-type-item">
            <div class="shuxian-root">
                <div class="shuxian"></div>
            </div>
            <div class="type-text">
                <a href='
                            /tags/ggplot2
                        '>
                    <i class="fa fa-tag"></i> ggplot2
                </a>
            </div>
        </span>
        
        <span class="down-type-item">
            <div class="shuxian-root">
                <div class="shuxian"></div>
            </div>
            <div class="type-text">
                <a href='
                            /tags/code-visuals
                        '>
                    <i class="fa fa-tag"></i> Code Visuals
                </a>
            </div>
        </span>
        
        <span class="down-type-item">
            <div class="shuxian-root">
                <div class="shuxian"></div>
            </div>
            <div class="type-text">
                <a href='
                            /tags/r-funciones
                        '>
                    <i class="fa fa-tag"></i> R funciones
                </a>
            </div>
        </span>
        
    </div>

<div class="dang"></div>
            </div>
            
            <div class="terms-root">
                
                



<div class="card-large">
    <div class="card-large-img">

        
                <img class="lazyload" src="/images/thumbnail.gif" data-src="/images/default.jpg" alt='image loading failed'>
        
    </div>
    <div class="card-large-content">
        <div class="up-title"><a href="http://example.org/es/posts/2022/minitut_hacer_bool/">Mini tutorial: hacer tipo lógico cualquier texto</a></div>
        <div class="up-date">
            <span class="no-wrap"><i class="fa fa-calendar"></i> postedOn: 2022-9-18 &nbsp;</span>
            <span class="no-wrap"><i class="fa fa-calendar-check-o"></i> updatedOn: 2022-9-18 &nbsp;</span>
            <span class="no-wrap"><i class="fa fa-folder"></i>
                
                    includedIn:
                    
                        <a href='
                                        /categories/r
                                    '>
                                R
                            </a>
                
            </span>
        </div>
        <div class="down-summary">Acerca de este post. Este es mi primer post en español. Es en realidad la traducción de un post que escribí originalmente en inglés hace un par de meses. Pueden ver el post original aqui. Espero que sea útil para la comunidad hispanohablante de usuarios de R.
Este post se basa en un trabajo reciente donde mi tarea fue la revisión y depuración de piezas de código pequeñas o simples que pueden resultar en consejos prácticos y rápidos para otros usuarios de R, especialmente principiantes o personas sin mucha experiencia en el uso de R.</div>
    </div>
    <div class="card-readmore">
        <a href="http://example.org/es/posts/2022/minitut_hacer_bool/">
            <span><i class="fa fa-arrow-right"></i></span>
        </a>
    </div>
</div>



    


    <div class="down-type">
        
        <span class="down-type-item">
            <div class="shuxian-root">
                <div class="shuxian"></div>
            </div>
            <div class="type-text">
                <a href='
                            /tags/minitutorial
                        '>
                    <i class="fa fa-tag"></i> minitutorial
                </a>
            </div>
        </span>
        
        <span class="down-type-item">
            <div class="shuxian-root">
                <div class="shuxian"></div>
            </div>
            <div class="type-text">
                <a href='
                            /tags/r-funciones
                        '>
                    <i class="fa fa-tag"></i> R funciones
                </a>
            </div>
        </span>
        
        <span class="down-type-item">
            <div class="shuxian-root">
                <div class="shuxian"></div>
            </div>
            <div class="type-text">
                <a href='
                            /tags/r-tips
                        '>
                    <i class="fa fa-tag"></i> R tips
                </a>
            </div>
        </span>
        
    </div>

<div class="dang"></div>
            </div>
            
        </div>
    
</div>


            </div>
            <div class="zhuti-r">
                
<div class="zhuti-r-0">
    <div class="zhuti-r-1">
        
        <div id="r1">
            

<div class="about-zuozhe">
    <div class="zuozhe">
        
            <div class="datou">
                <img class="lazyload" src="/images/thumbnail.gif" data-src="/images/author.jpeg" alt="">
            </div>
        
        <div class="name-jianjie">
            <div class="name">xioyito</div>
            <div class="jianjie">
                Be Water, My Friend.
            </div>
        </div>
    </div>

    <div class="type">
        <a href='
                    /posts/
                '>
            <p>posts</p>
            <p>19</p>
        </a>
        <a href='
                    /categories/
                '>
            <p>categories</p>
            <p>1</p>
        </a>
        <a href='
                    /tags/
                '>
            <p>tags</p>
            <p>20</p>
        </a>
    </div>

    <a href="https://github.com/xioyito">
        <div class="follow">Follow Me</div>
    </a>
    <div class="link">
        
        <a href="https://github.com/xioyito" class="link-item is-hidden-desktop" title="GitHub">
            <span class="icon"><i class='fa fa-github'></i></span>
        </a>
        
        <a href="https://www.youtube.com" class="link-item is-hidden-desktop" title="YouTube">
            <span class="icon"><i class='fa fa-youtube'></i></span>
        </a>
        
    </div>
</div>
            <div class="mulu">
    <div class="dong"></div>
    <div class="zhi">
        <div class="wenzi">
            <div class="zhi-mulu text-wbd">Table of Contents</div>
            <div class="mulu-items">
            </div>
        </div>
    </div>
</div>
            




<div class="other">
    <div class="other-up">
        <div class="other-qita text-wbd">latest Posts</div>
        <div class="xian"></div>
    </div>
    <div class="list">
        
            <a href="http://example.org/posts/2023/adding_website_to_siny/">
                
<a href="http://example.org/posts/2023/adding_website_to_siny/">
    <div class="list-item">
        <div class="icon-other-root">
            
                <div class="icon-other" style="background-image: url( /images/default.jpg );"></div>
            
        </div>
        <div class="list-right">
            <div class="other-title">
                Adding a website next to your Shiny server
            </div>
            <div class="other-summary">I have been off from the blog lately due to a big load of personal projects. Just lately I got a few days off and found time to work on my personal website, to be ready soon. That made me get more into Nginx configuration, where I consider myself a total rookie.</div>
            <div class="other-date">2023-9-7</div>
        </div>
    </div>
</a>
            </a>
        
            <a href="http://example.org/posts/2023/map_any_region_with_ggplot2_part_iii/">
                
<a href="http://example.org/posts/2023/map_any_region_with_ggplot2_part_iii/">
    <div class="list-item">
        <div class="icon-other-root">
            
                <div class="icon-other" style="background-image: url( /post/2022/map_any_region_with_ggplot2_part_I/maps_DrawingMap.png );"></div>
            
        </div>
        <div class="list-right">
            <div class="other-title">
                Map any region in the world with R - Part III: Programming with ggplot2
            </div>
            <div class="other-summary">You can find all the posts on this series under the tag maps-app (including the Spanish versions).
You can also find the current state of the project under my GitHub repo mapic.
Scope of this post We are creating maps of data showing changes over a span of time for different countries and pointing at all kinds of cities.</div>
            <div class="other-date">2023-4-19</div>
        </div>
    </div>
</a>
            </a>
        
            <a href="http://example.org/posts/2023/webscrap_and_iteration_in_r/">
                
<a href="http://example.org/posts/2023/webscrap_and_iteration_in_r/">
    <div class="list-item">
        <div class="icon-other-root">
            
                <div class="icon-other" style="background-image: url( /images/default.jpg );"></div>
            
        </div>
        <div class="list-right">
            <div class="other-title">
                Webscrap and iteration in R
            </div>
            <div class="other-summary">About this post We are creating maps of data showing changes over a span of time for different countries and pointing at all kinds of cities. That basically means that we need to map any region of the world with R. Today there are all kinds of packages and techniques to do that.</div>
            <div class="other-date">2023-3-24</div>
        </div>
    </div>
</a>
            </a>
        
            <a href="http://example.org/es/posts/2023/webscrap_e_iteracion_con_r/">
                
<a href="http://example.org/es/posts/2023/webscrap_e_iteracion_con_r/">
    <div class="list-item">
        <div class="icon-other-root">
            
                <div class="icon-other" style="background-image: url( /images/default.jpg );"></div>
            
        </div>
        <div class="list-right">
            <div class="other-title">
                Webscrap e iteraciones con R
            </div>
            <div class="other-summary">Sobre este post Estamos creando mapas de datos que muestran los cambios durante un período de tiempo para diferentes países y orientado a todo tipo de ciudades. Esto básicamente significa que necesitamos mapear cualquier región del mundo con R. Hoy en día existen todo tipo de paquetes y técnicas para hacerlo.</div>
            <div class="other-date">2023-3-24</div>
        </div>
    </div>
</a>
            </a>
        
            <a href="http://example.org/posts/2023/reference_dockerizing_shinny_apps/">
                
<a href="http://example.org/posts/2023/reference_dockerizing_shinny_apps/">
    <div class="list-item">
        <div class="icon-other-root">
            
                <div class="icon-other" style="background-image: url( /images/default.jpg );"></div>
            
        </div>
        <div class="list-right">
            <div class="other-title">
                Reference: Dockerizing shinny apps
            </div>
            <div class="other-summary">Andrew Couch has a nice video about deploying a shiny app using docker. He goes from the very basics, that asume no knowledge of docker whatsoever, which is the position of many R users like myself. I&rsquo;ve been working in some shiny app lately, and although I&rsquo;ve never needed docker so far, I decided to start learning it because I can already foresee the future when it won&rsquo;t be the case.</div>
            <div class="other-date">2023-2-11</div>
        </div>
    </div>
</a>
            </a>
        
    </div>
</div>
        </div>
        <div id="r2">
            
        </div> 
    </div>
</div>

            </div>
        </div>
    </div>
</div>


        </div>

        <footer class="footer">
    
        <div class="container">
            <div class="footer-items">
                
                    <div class="footer-item">
                        <i class="fa fa-user"></i> <span id="busuanzi_value_site_pv"></span> |
                        <i class="fa fa-eye"></i> <span id="busuanzi_value_site_uv"></span>
                    </div>
                
                
                    <div class="footer-item">
                        © 2022-2023 <a href="https://github.com/xioyito">xioyito</a>
                    </div>
                
                
                    <div class="footer-item">
                        Theme by <a href="https://github.com/xioyito/NewBee">NewBee</a> | Powered by <a href="https://gohugo.io/">Hugo</a>
                    </div>
                
            </div>
        </div>
    

    
</footer>


        
        <div class="search-root">
    <div class="search-zz"></div>
    <div class="search">
        <div class="sheader anniu">
            <div class="sh-l">
                <input type="text" placeholder='Enter a KeyWord' id="search-key">
                <span class="sclear"><i class="fa fa-close"></i></span>
            </div>
            <div class="sh-r">
                <button>search</button>
            </div>
        </div>
        <div class="sbody">
            <div class="sbody-1">
                <div class="stip"></div>
            </div>
        </div>
    </div>
</div>
        









    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    

    
    


<script type="text/javascript">
    var mode_custom = "auto";
    var postsCount =  19 ;
    var arrPosts = [{"link":"http://example.org/posts/2023/adding_website_to_siny/","plain":" I have been off from the blog lately due to a big load of personal projects. Just lately I got a few days off and found time to work on my personal website, to be ready soon. That made me get more into Nginx configuration, where I consider myself a total rookie. However, I was mainly adding a few domains that are intended for different purposes. That is incredibly easy to do using Nginx even with minimal knowledge, and that\u0026#39;s what I want to show here.\nBasically I want to have my shiny apps under one domain, and some other sites under different domains, but using only one server. I also decided to add my own customized 404 error page. There are different ways to accomplish that, here are just a couple of them. I hope they can be of use.\nUsing sites-enabled If you followed my previous post about how to deploy your own shiny app in your own server using Nginx, the next step to deploy a new website with a different domain in the same server is very easy. Nginx uses the concept of server blocks that use the server_name and listen directives to bind to tcp sockets.\nGo to you Nginx file where we placed the details for the Shiny server in /etc/nginx/sites-enabled/default and add a new server block at the very end of the file. It can be something like below.\nserver { root /var/www/example/; server_name example.mydomain.com; index index.html; location / { try_files $uri $uri/ uri.html =404; } } Direct the root to the path where your public website files are, and server_name to your domain. Remember that you also have to direct your domain to the public IP address of your server, this means the same where your shiny app is. Finally restart Nginx sudo systemctl reload nginx and your new address should show the index.html file stored in your path.\nUsing nginx.conf Another option is to configure directly /etc/nginx/nginx.conf and add as many server blocks as you need, within the http block. Here is the example used above alongside the shiny server. Remember to add the=map= parameter before the shiny block.\nhttp{ ## Leave anything above untouch, add your blocks at the end ## Example server server { root /var/www/example/; server_name example.mydomain.com; index index.html; location / { try_files $uri $uri/ uri.html =404; } } ## Shiny server map $http_upgrade $connection_upgrade { default upgrade; \u0026#39;\u0026#39; close; } server { root /var/www/shiny/; ## Don\u0026#39;t forget to create the folder index index.html index.htm index.nginx-debian.html; server_name shiny.myomain.com; location /shiny/ { proxy_pass http://127.0.0.1:3838/; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;upgrade\u0026#34;; rewrite ^(/shiny/[^/]+)$ $1/ permanent; } } Adding a custom 404 page To add a custom 404 error page (or basically any error page) we could create it as part of our site and point Nginx to it. However, we can as well create and maintain only one page and share it for all or some of our domains.\nYou can create a some file like custom_404.html in the path /usr/share/nginx/html/, edit it to your liking and then add it to each server block where you want to use it. The Nginx code goes something like this:\nerror_page 404 /custom_404.html; location = /custom_404.html { root /usr/share/nginx/html; internal; } We can also cover several errors by listing them to the parameter error_page. Here is an example to cover several 500 errors.\nerror_page 500 502 503 504 /custom_50x.html; location = /custom_50x.html { root /usr/share/nginx/html; internal; } In this case, Nginx will use whatever we have in /usr/share/nginx/html/csutom_50x.html to show when the errors 500, 502, 503 and 504 appear.\nFinal considerations Whichever steps you take, don\u0026#39;t forget to execute sudo nginx -t when you make modifications to ensure that your configuration files and syntax are correct. The more often you run it, the easier will be to identify potential problems. Also, don\u0026#39;t forget to check the Nginx documentation, it has a beginner\u0026#39;s guide and my favorite, a getting started site with tons of examples.\n","pubDate":"2023-09-07","title":"Adding a website next to your Shiny server"},{"link":"http://example.org/posts/2023/map_any_region_with_ggplot2_part_iii/","plain":"You can find all the posts on this series under the tag maps-app (including the Spanish versions).\nYou can also find the current state of the project under my GitHub repo mapic.\nScope of this post We are creating maps of data showing changes over a span of time for different countries and pointing at all kinds of cities. That basically means that we need to map any region of the world with R. Today there are all kinds of packages and techniques to do that. I will share the strategy I used with ggplot2 and maps packages, using support of Open Street Map to obtain the coordinates of cities and finally making it interactive with shiny.\nThis series of posts share my path towards the creation of the Shiny app. It is a live project and I decided to share my path and experiences along the creation process. The posts are not only about the Shiny app, but the package I created behind it, including topics of functions crafting, creation of the maps, classes of objects, etc., as well as any interesting issue that appear on the way. It is my way to contribute to the R community and at the same time keeping the project documented for myself.\nThis post is about Creating functions for ggplot.\nI hope you all enjoy it. Feel free to leave any kind of comment and/or question at the end.\nBackground and preliminaries In the first post we created a function to create the basic map. Since then I have modified the function slightly, but the concept is the same. You can see below the most up to date version and compare it with the previous version if you wish.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 my_country_prev \u0026lt;- function(country, map_colors, x_limits = NULL, y_limits = NULL, show_coords = FALSE) { require(maps) require(ggplot2) ## Verifying the arguments passed to the function if (length(country) != 1) stop(\u0026#34;Function supports only one country per map\u0026#34;) stopifnot(is.logical(show_coords)) stopifnot(\u0026#34;Name of the country should be character\u0026#34; = is.character(country)) if (!country %in% map_data(\u0026#39;world\u0026#39;)$region) { stop(paste(\u0026#34;Country name not recognized\u0026#34;, \u0026#34;To see a list of recognized countries run\u0026#34;, \u0026#34;\u0026lt;unique(maps::map_data(\u0026#39;world\u0026#39;)$region)\u0026gt;\u0026#34;, sep = \u0026#34;\\n\u0026#34;)) } ## If coords limits missing, print worldwide map with coordinates system to allow ## User observe coords for reference if (missing(x_limits) || missing(y_limits)) { warning(\u0026#34;X and/or Y limits not provided.\\nPrinting worldwide map.\u0026#34;) map_country_theme \u0026lt;- theme(panel.background = element_rect(fill = map_colors$oceans)) } else if (show_coords) { map_country_theme \u0026lt;- theme(panel.background = element_rect(fill = map_colors$oceans)) } else { if (length(x_limits) != 2 || length(y_limits) != 2 || !all(grepl(\u0026#34;^-?[0-9.]+$\u0026#34;, c(x_limits, y_limits)))) { stop(\u0026#34;Limits for X and Y coords should be provided as vectors with two numeric values\u0026#34;) } else { ## All the received inputs are correct. ## Let\u0026#39;s define our custom theme for the final map map_country_theme \u0026lt;- theme_bw() + theme(panel.background = element_rect(fill = map_colors$oceans), legend.position = \u0026#34;none\u0026#34;, panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = \u0026#34;black\u0026#34;), axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank()) } } ## make a df with only the country to overlap map_data_country \u0026lt;- map_data(\u0026#39;world\u0026#39;)[map_data(\u0026#39;world\u0026#39;)$region == country, ] ## The map (maps + ggplot2 ) mapic \u0026lt;- ggplot() + ## First layer: worldwide map geom_polygon(data = map_data(\u0026#34;world\u0026#34;), aes(x = long, y = lat, group = group), color = map_colors$border_countries, # border countries fill = map_colors$empty_countries) + # empty countries ## Second layer: Country map geom_polygon(data = map_data_country, aes(x = long, y = lat, group = group), color = map_colors$border_countries, # border target country fill = map_colors$target_country) + # target country coord_map() + coord_fixed(1.3, xlim = x_limits, ylim = y_limits) + map_country_theme return(mapic) } One critical difference is the argument map_colors that is nor explained or well defined. This is a list object containing the values for the colors to be used for all the elements of the maps. There are different ways to define and use this. The idea is to make it an S3 object and explain it on its own, but it is a topic that I am still exploring and I haven\u0026rsquo;t decided yet the details of it. For now, let\u0026rsquo;s use it simply as a list containing our chosen colors for the map.\n1 2 3 4 5 6 7 8 9 map_colors \u0026lt;- list(dots_orgs = \u0026#34;#493252\u0026#34;, target_country = \u0026#34;#8caeb4\u0026#34;, empty_countries = \u0026#34;#f3f3f3\u0026#34;, border_countries = \u0026#34;#9c9c9c\u0026#34;, oceans = \u0026#34;#4e91d2\u0026#34;, text_cities = \u0026#34;#a0a0a0\u0026#34;, text_legend = \u0026#34;#493252\u0026#34;, background_legend = \u0026#34;#ffffff\u0026#34;, text_copyright = \u0026#34;#f3f3f3\u0026#34;) The function easily prints the map of any country, using the naming from the package maps. Now we want to add the data to it.\nNow we need to define some simple data frame simulating a collection of organizations in Mexico.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 mx_data \u0026lt;- data.frame( ID = c(1:10), Name = sprintf(\u0026#34;org%d\u0026#34;, seq(1:10)), Registration_year = c(2001:2010), Country = \u0026#34;MX\u0026#34;, Region = c(\u0026#34;Mexico\u0026#34;, \u0026#34;Baja California Norte\u0026#34;, \u0026#34;Mexico\u0026#34;, \u0026#34;Jalisco\u0026#34;, \u0026#34;Queretaro\u0026#34;, \u0026#34;Baja California Norte\u0026#34;, \u0026#34;Mexico\u0026#34;, \u0026#34;Morelos\u0026#34;, \u0026#34;Mexico\u0026#34;, \u0026#34;Estado de Mexico\u0026#34;), City = c(\u0026#34;Ciudad de Mexico\u0026#34;, \u0026#34;Tijuana\u0026#34;, \u0026#34;Ciudad de Mexico\u0026#34;, \u0026#34;Guadalajara\u0026#34;, \u0026#34;Queretaro\u0026#34;, \u0026#34;Tijuana\u0026#34;, \u0026#34;Ciudad de Mexico\u0026#34;, \u0026#34;Cuernavaca\u0026#34;, \u0026#34;Ciudad de Mexico\u0026#34;, \u0026#34;Texcoco\u0026#34;)) We can see it as a company that along 10 years managed to open one new franchise per year, and we want to map where each is located and where it has grown the most. For that, we need the coordinates of the cities where each franchise is located. We can easily obtain that using code from the previous posts: either directly from part II or the improved version of the function.\n1 2 3 4 5 webscrap_to_db(db_name = \u0026#34;test-mex.sqlite\u0026#34;, dat = mx_data, city = \u0026#34;City\u0026#34;, country = \u0026#34;Country\u0026#34;, db_backup_after = 5) And also using previously defined functions, we can combine the data with the just obtained coordinates system.\n1 2 (datmx \u0026lt;- combine_csv_sql(db_file = \u0026#34;test-mex.sqlite\u0026#34;, csv_file = mx_data)) \u0026gt; ID Name Registration_year City Country Region State County \u0026gt; 1 1 org1 2001 Ciudad de Mexico MX \u0026gt; 2 2 org2 2002 Tijuana MX \u0026gt; 3 3 org3 2003 Ciudad de Mexico MX \u0026gt; 4 4 org4 2004 Guadalajara MX \u0026gt; 5 5 org5 2005 Queretaro MX \u0026gt; 6 6 org6 2006 Tijuana MX \u0026gt; 7 7 org7 2007 Ciudad de Mexico MX \u0026gt; 8 8 org8 2008 Cuernavaca MX \u0026gt; 9 9 org9 2009 Ciudad de Mexico MX \u0026gt; 10 10 org10 2010 Texcoco MX \u0026gt; osm_name lon \u0026gt; 1 Ciudad de México, México -99.13318 \u0026gt; 2 Tijuana, Municipio de Tijuana, Baja California, 22320, México -117.01953 \u0026gt; 3 Ciudad de México, México -99.13318 \u0026gt; 4 Guadalajara, Jalisco, México -103.33840 \u0026gt; 5 Santiago de Querétaro, Municipio de Querétaro, Querétaro, México -100.39706 \u0026gt; 6 Tijuana, Municipio de Tijuana, Baja California, 22320, México -117.01953 \u0026gt; 7 Ciudad de México, México -99.13318 \u0026gt; 8 Cuernavaca, Morelos, 62000, México -99.23423 \u0026gt; 9 Ciudad de México, México -99.13318 \u0026gt; 10 Texcoco, Carbó, Sonora, México -111.05867 \u0026gt; lat \u0026gt; 1 19.43263 \u0026gt; 2 32.53174 \u0026gt; 3 19.43263 \u0026gt; 4 20.67204 \u0026gt; 5 20.59547 \u0026gt; 6 32.53174 \u0026gt; 7 19.43263 \u0026gt; 8 18.92183 \u0026gt; 9 19.43263 \u0026gt; 10 29.63900 Now datmx should have the coordinates, together with the rest of the data about our franchises. We should also have our SQLite file and, of course, our source data. It means that we are ready to add the data to the map.\nProgramming with ggplot2 If you ever wondered how to create functions with ggplot2, there are a few ways, but here is the basic point that we need to understand, if we want to have them working in the same style as ggplot works:\nOnce you have the base plot with the function ggplot() you can add geoms and stats to it by simply using +, or you can create new functions by returning a list of geoms and stats.\nThe first point is as simple as the following lines:\n1 2 my_country_prev(\u0026#34;Mexico\u0026#34;, map_colors, x_limits = c(-118, -86), y_limits = c(14, 34)) + ggtitle(\u0026#34;A map of Mexico\u0026#34;) Or we could do the same by creating a function and returning the title inside a list.\n1 2 3 4 5 6 my_title \u0026lt;- function(text) { return(list(ggtitle(text))) } my_country_prev(\u0026#34;Mexico\u0026#34;, map_colors, x_limits = c(-118, -86), y_limits = c(14, 34)) + my_title(\u0026#34;The same map of Mexico\u0026#34;) With that in mind, we can do all the calculations we want and start adding the data in form of geoms and stats to the base map.\nA map with growing dots per city We started with something simple, adding the amount of organizations per city, as growing dots.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 make_dots \u0026lt;- function(.df, year, map_colors, column_names = list( lat = \u0026#34;lat\u0026#34;, lon = \u0026#34;lon\u0026#34;, cities = \u0026#34;city\u0026#34;, start_year = \u0026#34;year\u0026#34;, end_year = NULL), dot_size = 1) { require(dplyr) require(tidyr) require(stringr) ## Some error handling mandatory_cols \u0026lt;- c(\u0026#34;lat\u0026#34;, \u0026#34;lon\u0026#34;, \u0026#34;cities\u0026#34;, \u0026#34;start_year\u0026#34;) if(!all(mandatory_cols %in% names(column_names))) { stop(\u0026#34;Column names missing!\u0026#34;) } else { if (!\u0026#34;end_year\u0026#34; %in% names(column_names)) { .df$final_year \u0026lt;- NA_real_ column_names[[\u0026#34;end_year\u0026#34;]] \u0026lt;- \u0026#34;final_year\u0026#34; } } ## Dots base size base_size \u0026lt;- 5 dot_sizes \u0026lt;- c(0.5 * (base_size * dot_size), 1 * (base_size * dot_size), 2 * (base_size * dot_size), 3 * (base_size * dot_size), 4 * (base_size * dot_size), 5 * (base_size * dot_size), 7 * (base_size * dot_size), 8 * (base_size * dot_size), 9 * (base_size * dot_size)) ## Data manipulation to be used in the map filt \u0026lt;- .df %\u0026gt;% mutate(year_final = replace_na(!!sym(column_names$end_year), year + 1), city_name = str_to_sentence(!!sym(column_names$cities))) %\u0026gt;% filter(year_final \u0026gt; year \u0026amp; !!sym(column_names$start_year) \u0026lt;= year) %\u0026gt;% group_by(city_name) %\u0026gt;% summarise(x = median(!!sym(column_names$lon), na.rm = T), y = median(!!sym(column_names$lat), na.rm = T), n = n()) %\u0026gt;% mutate(dot_size = case_when(n == 1 ~ dot_sizes[1], n \u0026gt;= 2 \u0026amp; n \u0026lt;= 5 ~ dot_sizes[2], n \u0026gt;= 6 \u0026amp; n \u0026lt;= 10 ~ dot_sizes[3], n \u0026gt;= 11 \u0026amp; n \u0026lt;= 30 ~ dot_sizes[4], n \u0026gt;= 31 \u0026amp; n \u0026lt;= 50 ~ dot_sizes[5], n \u0026gt;= 51 \u0026amp; n \u0026lt;= 100 ~ dot_sizes[6], n \u0026gt;= 101 \u0026amp; n \u0026lt;= 200 ~ dot_sizes[7], n \u0026gt;= 201 \u0026amp; n \u0026lt;= 300 ~ dot_sizes[8], n \u0026gt;= 301 ~ dot_sizes[9], TRUE ~ NA)) ## -------------------------- MAIN MAP ---------------------------------- map_points \u0026lt;- list( geom_point(data = filt, aes(x, y, size = dot_size), color = map_colors$dots_orgs, alpha = 7/10, shape = 19) , scale_size_identity(\u0026#39;\u0026#39;, breaks = dot_sizes, labels = c(\u0026#39;1\u0026#39;, \u0026#39;2-5\u0026#39;, \u0026#39;6-10\u0026#39;, \u0026#39;11-30\u0026#39;, \u0026#39;31-50\u0026#39;, \u0026#39;51-100\u0026#39;, \u0026#39;101-200\u0026#39;, \u0026#39;201-300\u0026#39;, \u0026#39;\u0026gt;300\u0026#39;), guide = guide_legend(label.position = \u0026#39;bottom\u0026#39;, label.vjust = 0, nrow = 1)), geom_point(data = filter(filt, n == 1), aes(x, y), color = map_colors$dots_orgs, shape = 19, size = 2.5) , theme(legend.position = \u0026#39;bottom\u0026#39;) ) return(map_points) } As you can see, the function also requires our object map_colors, which we created before. Another way of passing values from a list is by defining these values directly within the function arguments, as we did here for column_names. We could pass the arguments directly when calling the function, or define them earlier to be used. Let\u0026rsquo;s use the second approach.\n1 2 3 4 col_names = list(lat = \u0026#34;lat\u0026#34;, lon = \u0026#34;lon\u0026#34;, cities = \u0026#34;City\u0026#34;, start_year = \u0026#34;Registration_year\u0026#34;) If you look at the data frame that we created containing the data, this are simply the names of the columns as we specified them.\nNow, about the function itself, it starts, as expected, by calling the libraries and then doing a bit of error handling to ensure that the fields that are strictly required are actually present in the data frame. There I am also adding the options for the end_year which is used in case some franchise closed and we want to map it only for the period of time it was present.\nThen we define the \u0026ldquo;Dots base size\u0026rdquo;. Here we experimented with so many sizes, both for the dots and for the final map, and this are the ones that look the best. Still, I\u0026rsquo;m allowing this value to be changed as the parameter dot_size in the function definition, however I wouldn\u0026rsquo;t recommend changing it. You can also play with the internal values and see it for yourself. Since the idea here is to create functions for the \u0026ldquo;standards\u0026rdquo; of the maps, allowing minimal changes, we are not so strict as per how big the dots should be, yet we have certain degree of control.\nThen we do a little bit of data manipulation before being able to use the data. This includes the standardization of the names of Cities (up to some degree), filtering the data that does not match with the selected year, using only the median value of the latitude and longitude data, and defining the sizes of the dots according to the amount of franchises. The last one is a tricky one that I haven\u0026rsquo;t decided yet what amount of freedom should still be out there. Maybe there should be a separated function to define all that. Our maps were created to handle data containing from few hundreds of rows, to a couple of thousands, thus, the values presented here. But if you want to show just a few organizations (as is the case of this example), the map looks quite deserted; on the other hand, if you need to map values of thousands per city, the maps look overloaded. For the present post I\u0026rsquo;m keeping it as is, with a note for consideration. We also added one extra geom_point to overwrite the alpha value for the case of only 1, and make it solid. This also works well on the visuals.\nIn any case, the function above shows how we can manipulate the data inside a function, and return only what we need to add it to an existent ggplot. We can now add the dots as we would normally do in ggplot style.\n1 2 3 4 5 6 7 8 9 10 my_country_prev(\u0026#34;Mexico\u0026#34;, map_colors, x_limits = c(-118, -86), y_limits = c(14, 34), show_coords = T) + make_dots(datmx, year = 2022, map_colors, column_names = col_names) + scale_x_continuous(n.breaks = 20) + ggtitle(\u0026#34;A map of Mexico\u0026#34;) Adding labels for the map Moving forward, we want to add some labels to the maps to know what we are seeing. Here I created one function to show which year is being mapped, and a second one to show the totals. Although we can achieve that easily in different ways, I managed to make it complicated, keeping in mind that we want to map any region in the world.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 my_print_years \u0026lt;- function(year, map_colors, x_limits, y_limits, year_label = \u0026#34;Year\u0026#34;) { ## POSITION FOR THE LABELS ## Starting points x_units \u0026lt;- abs(x_limits[1] - x_limits[2])/10 y_units \u0026lt;- abs(y_limits[1] - y_limits[2])/10 start_x \u0026lt;- min(x_limits) start_y \u0026lt;- min(y_limits) ## Frame rectangle.start.x \u0026lt;- start_x rectangle.wide \u0026lt;- rectangle.start.x + x_units rectangle.start.y \u0026lt;- start_y rectangle.high \u0026lt;- rectangle.start.y + y_units ## Text num.size \u0026lt;- 4 text.size \u0026lt;- 3 num.position.x \u0026lt;- start_x + (x_units * 0.5) text.position.x \u0026lt;- start_x + (x_units * 0.5) num.position.y \u0026lt;- start_y + (y_units * 0.25) text.position.y \u0026lt;- start_y + (y_units * 0.65) ## Adding the ggplot geoms pyears \u0026lt;- list( geom_rect( aes(xmin = rectangle.start.x, xmax = rectangle.wide, ymin = rectangle.start.y, ymax = rectangle.high), color = map_colors$text_legend, fill = map_colors$text_legend, alpha = 9/10), geom_text( aes(x = num.position.x, y = num.position.y, label = year), size = num.size, fontface = \u0026#39;bold\u0026#39;, color = map_colors$background_legend), geom_text( aes(x = text.position.x, y = text.position.y, label = year_label), size = text.size, fontface = \u0026#39;bold\u0026#39;, alpha = 9/10, color = map_colors$background_legend) ) return(pyears) } Consider this some kind of snippet to add the labels wherever you want, and in any size you want. Our function is basically doing some basic simple calculations to place the labelling inside the map area, on the bottom-left corner. The first part with the comment ## POSITION FOR THE LABELS shows the basic calculations to do that, based on the coords, which should be the same as the coords specified in the map function. The calculations and the position are very stiff in size and location, but they will work the same regardless of the region mapped. On the other hand, it provides the basis for the function. Feel free to play with them to add custom options such as selecting the sizes or the corner where we want to display them.\nThe rest of the code is intuitive, geom_text to add the info we want to show, one for the word \u0026ldquo;Year\u0026rdquo; and another one for the numeric value. We add the corresponding values to the aes, the sizes, some alpha for transparency and our colors defined in map_colors.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 my_print_totals \u0026lt;- function(totals, map_colors, x_limits, y_limits, totals_label = \u0026#34;Totals\u0026#34;) { ## POSITION FOR THE LABELS ## Starting points x_units \u0026lt;- abs(x_limits[1] - x_limits[2])/10 y_units \u0026lt;- abs(y_limits[1] - y_limits[2])/10 start_x \u0026lt;- min(x_limits) + x_units start_y \u0026lt;- min(y_limits) ## Frame rectangle.start.x \u0026lt;- start_x rectangle.wide \u0026lt;- rectangle.start.x + x_units rectangle.start.y \u0026lt;- start_y rectangle.high \u0026lt;- rectangle.start.y + y_units ## Text num.size \u0026lt;- 4 text.size \u0026lt;- 3 num.position.x \u0026lt;- start_x + (x_units*0.5) text.position.x \u0026lt;- start_x + (x_units*0.5) num.position.y \u0026lt;- start_y + (y_units*0.25) text.position.y \u0026lt;- start_y + (y_units*0.65) ptotals \u0026lt;- list( geom_rect(aes(xmin = rectangle.start.x, xmax = rectangle.wide, ymin = rectangle.start.y, ymax = rectangle.high), color = \u0026#39;#283151\u0026#39;, fill = map_colors$background_legend, alpha = 9/10), geom_text( aes(x = num.position.x, y = num.position.y, label = totals), size = num.size, fontface = \u0026#39;bold\u0026#39;, alpha = 9/10, color = map_colors$text_legend), geom_text( aes(x = text.position.x, y = text.position.y, label = totals_label), size = text.size, fontface = \u0026#39;bold\u0026#39;, alpha = 9/10, color = map_colors$text_legend) ) return(ptotals) } We can follow exactly the same approach for the totals, to place them right next to the year. For now we have to specify the value of the total that we want to be shown, but this actually should be calculated by the function. Actually, if you think about it, we are passing a great deal of information that should be coming from the previous functions, and we should keep here arguments that control the visuals of the labels only. That is not an easy topic and I decided to cover it in a separated post. Another reason why I don\u0026rsquo;t want to show it yet is because I haven\u0026rsquo;t decided yet which approach I want to use.\nSo, for now we have to pass each argument to each function and make sure that we are passing the same argument, but that is easy to achieve in R by directing the values to an object before passing it to the functions. Let\u0026rsquo;s see it in action.\nThe dataset has already been stored in datmx and the colors in map_colors. Now we need to define a few more.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 x_coords \u0026lt;- c(-118, -86) y_coords \u0026lt;- c(14, 34) yr \u0026lt;- 2020 totals \u0026lt;- 10 my_country_prev(\u0026#34;Mexico\u0026#34;, map_colors, x_coords, y_coords, show_coords = T) + make_dots(rbind(datmx, datmx), map_colors, year = yr, col_names) + my_print_years(yr, map_colors, x_coords, y_coords, \u0026#34;Año\u0026#34;) + my_print_totals(totals, map_colors, x_coords, y_coords, \u0026#34;Totales\u0026#34;) And there it is. Since my map is for Mexico, I am adding labels in Spanish. Feel free to test it in your own language and with more data. We can also have a look at how the labels fit to other countries, for example, smaller and bigger compared to Mexico.\n1 2 3 4 5 6 7 8 9 x_coords \u0026lt;- c(4, 18) y_coords \u0026lt;- c(47, 56) my_country_prev(\u0026#34;Germany\u0026#34;, map_colors, x_coords, y_coords, show_coords = T) + my_print_years(yr, map_colors, x_coords, y_coords) + my_print_totals(totals, map_colors, x_coords, y_coords) + ggtitle(\u0026#34;A map of Germany\u0026#34;) Germany is also looking good. And since we have the possibility of passing the values for year and totals, we don\u0026rsquo;t actually need to have any data to test it, although the info shown is incorrect.\n1 2 3 4 5 6 7 8 x_coords \u0026lt;- c(28, 185) y_coords \u0026lt;- c(10, 100) my_country_prev(\u0026#34;Russia\u0026#34;, map_colors, x_coords, y_coords, show_coords = T) + my_print_years(yr, map_colors, x_coords, y_coords) + my_print_totals(totals, map_colors, x_coords, y_coords) Russia is a very particular case because the country is quite long but not so wide. If we specify coordinates too narrow for latitude, the map does not look good and the labels start getting deformed. It would be the same case with Chile, if we make it narrow in longitude but it is naturally long in latitude. Since the main aim of the functions is to take care of the aesthetics and visualization, we have to ensure that this should not happen, somehow. Having certain degree of the labels is one way to do that. We will see a few more in the future.\nConclusions If your aim is only to make maps like the above for any given country, our first 3 posts should have you covered. We could also import our functions to a shiny app and work with that. However, there are many improvements that we can still do.\nNow that we know the basis for functional programming with ggplot2, we can extend the power of our functions in the way how they share arguments by exploring the OOP (Object Oriented Programming) in R, the ggproto system to extend ggplot, and the use of environments.\nSince we want the maps to be dynamic in time, we could also work on a couple of functions to cover that. It could easily be achieved in a for loop, which is perfectly fine. We could also use the apply family of functions or the map family of functions from the purrr package (not to be confused with geographic maps or the package maps). The last options could be a bit of complication because of the excess of arguments in our functions. That only shows that it is worth it to still improve them.\nThe next posts will be focused on this topic, so stay connected if you are interested on how I tackle these challenges.\n","pubDate":"2023-04-19","title":"Map any region in the world with R - Part III: Programming with ggplot2"},{"link":"http://example.org/posts/2023/webscrap_and_iteration_in_r/","plain":"About this post We are creating maps of data showing changes over a span of time for different countries and pointing at all kinds of cities. That basically means that we need to map any region of the world with R. Today there are all kinds of packages and techniques to do that. I will share the strategy I used with ggplot2 and maps packages, using support of Open Street Map to obtain the coordinates of cities and finally making it interactive with shiny.\nThis series of posts share my path towards the creation of the Shiny app. It is a live project and I decided to share my path and experiences along the creation process. The posts are not only about the Shiny app, but the package I created behind it, including topics of functions crafting, creation of the maps, classes of objects, etc., as well as any interesting issue that appear on the way. It is my way to contribute to the R community and at the same time keeping the project documented for myself.\nYou can find all the posts on this series under the tag maps-app (including the Spanish versions).\nYou can also find the current state of the project under my GitHub repo mapic.\nThis post is originally written in Spanish, from the Amsterdam airport, on the way to Mexico. I hope you enjoy. Feel free to leave any type of comment and/or question at the end.\nMotivation As I mentioned in the previous posts in the series, I\u0026rsquo;ve been working lately on the code for creating the maps and I\u0026rsquo;ve made changes that increase the efficiency of the functions, the readability of the code, and make it easier to use. At the same it allows me to extend the functions beyond their original design.\nI have mentioned on a few occasions that the code evolved slowly from scripts created to generate the specific map of some country. So, the first few functions are more of a collection of the steps used to generate the map, wrapped in the form of functions to automate the process.\nFor this reason, I wanted to make changes to adapt the functions to paradigms more suitable for functional programming, which is R\u0026rsquo;s strong point. However, back then the priority was to generate the maps, and thus, most of my time was devoted to creating the maps and the debugging of the code when it was necessary. I need to add that this project is part of a voluntary work for an NGO, of which I became the director of the research division, which generated even more responsibilities and work for me. And all as a side job, separated from my main source of income (which is also based on R).\nHowever, for better or worse, 2022 was a year full of changes and challenges for me and my family, which forced me to put the project aside for a while, resign my position as responsible of the division, and focus solely on to my career, my health and my family. The result was that when I managed to regaining stability in my life, I found myself with more free time and fewer obligations to rethink the code and work on it. Additionally, my main job had a turn going from statistics to more programming oriented in R, which has given me more tools and experience to improve the code, and has motivated me to take up old lessons about functional programming and, above all, iteration.\nThis allowed me to improve the two main functions: the one in charge of the webscrapping and the one that sends the data to SQLite. You can find the original functions in the previous post, Map any region in the world with R - Part I: The basic map and compare it with the new, improved functions in this.\nWebscrapp to SQLite The webscrap_to_sqlite function is responsible for sending the coordinates found by Open Street Map to our database. The original function is inefficient, as it does each operation line by line. It is also very rigid in the way it directs the values of the regions, both its request to the API and the placement of the values in the database, which makes any extension or modification very complicated.\nFor these reasons, it is the function that received the most changes, it was practically rewritten from scratch, making the search more efficient, also allowing internal search of the data already stored; more flexible, dealing with region parameters more clearly; and more understandable, improving the style of the code.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 webscrap_to_sqlite \u0026lt;- function(db.name, dat, city = \u0026#34;City\u0026#34;, country = \u0026#34;Country\u0026#34;, region = NULL, state = NULL, county = NULL, db_backup_after = 10) { ## Loading libraries require(RSQLite) require(dplyr) ## 1. DB connection con \u0026lt;- dbConnect(drv = SQLite(), dbname = db.name) dbExecute(conn = con, \u0026#34;CREATE TABLE IF NOT EXISTS orgs (ID INTEGER UNIQUE, City TEXT, Country TEXT, Region TEXT, State TEXT, County TEXT, osm_name TEXT, lon REAL, lat REAL)\u0026#34;) db \u0026lt;- as_tibble(dbReadTable(con, \u0026#34;orgs\u0026#34;)) ## 2. Data filtering new_coords \u0026lt;- data.frame() dat_local \u0026lt;- compare_db_data(db.name, dat) df_len \u0026lt;- nrow(dat_local) ## 3. While there are rows in DF: if (df_len != 0) { ## 3.1 Define subsample size dat_local \u0026lt;- dat_local[c(1:db_backup_after), ] dat_local \u0026lt;- filter(dat_local, rowSums(is.na(dat_local)) != ncol(dat_local)) ## 3.2 for loop for the webscrapping for (i in 1:nrow(dat_local)) { print(paste0(\u0026#34;Searching entry \u0026#34;, dat_local[[\u0026#34;ID\u0026#34;]][i])) ## 3.3 Info abstraction rg \u0026lt;- ifelse(is.null(region), \u0026#34;\u0026#34;, dat_local[[region]][i]) st \u0026lt;- ifelse(is.null(state), \u0026#34;\u0026#34;, dat_local[[state]][i]) ct \u0026lt;- ifelse(is.null(county), \u0026#34;\u0026#34;, dat_local[[county]][i]) rcity \u0026lt;- dat_local[[city]][i] rcountry \u0026lt;- dat_local[[country]][i] ## 3.4 Getting the coords ## 3.4.1. First, check if they are already in the DB search_query \u0026lt;- filter(db, City == rcity, Country == rcountry, Region == rg, State == st, County == ct) if (nrow(search_query != 0)) { coords \u0026lt;- search_query[1, ] coords$ID \u0026lt;- dat_local[[\u0026#34;ID\u0026#34;]][i] print(\u0026#34;Found from memory\u0026#34;) ## 3.4.2 If they are not, search with OSM API } else { coords \u0026lt;- coords_from_city(rcity, rcountry, Region = rg, State = st, County = ct) coords \u0026lt;- cbind(ID = dat_local[[\u0026#34;ID\u0026#34;]][i], City = rcity, Country = rcountry, Region = rg, State = st, County = ct, coords) } new_coords \u0026lt;- rbind(new_coords, coords) } ## Send only new results to DB dbWriteTable(con, \u0026#34;orgs\u0026#34;, new_coords, append = TRUE) dbDisconnect(con) ## 3.4.3 Repeat webscrap_to_sqlite(db.name = db.name, dat = dat, city = city, country = country, region = region, state = state, county = county, db_backup_after = db_backup_after) ## 4. Exit iteration } else { db_final \u0026lt;- import_db_as_df(db.name) size \u0026lt;- nrow(db_final) not_found \u0026lt;- nrow(db_final[is.na(db_final$lat), ]) message(paste(\u0026#34;Search finished.\\n\u0026#34;, size, \u0026#34;entries searched.\\n\u0026#34;, not_found, \u0026#34;ENTRIES NOT FOUND\u0026#34;)) } } The function starts by calling the necessary libraries and (1) connecting to the database, creating it if necessary. (2) Then it generates two data frames, an empty one that will store new coordinates and a relative one that contains only the data that does not yet exist in the database. (3) So, as long as there is data in this last data frame, the function will continue to loop.\n(3.1) We then define the subsample, which is a subset of dat_local the size of db_backup_after and focus solely on this subsample. (3.2) On this subsample we make the iterations using for to obtain the coordinates. First (3.3) we prepare the data as strings and then (3.4) we look up the coordinates. (3.4.1) If they already exist in the database we take it from there, and if not (3.4.2) they are searched using coords_from_city. Finally, (3.4.3) we iterate all over again, allowing the function to call itself.\nSince step 2 filters the data that is not yet in the database and step 3 places the results of new searches in an empty data frame, the function calls itself and applies only for each subset of data. When compare_db_data finally returns 0 values because all the data that was fed into the function is already contained in the database, we can exit the function. In this case I decided to import the data again from SQLite to get details of the search, and end the iteration by sending a message to the user about the total number of entries and the number of which were not found.\nIf we compare this function with the one proposed in my previous post, the function is completely different but the end result is the same. The arguments used by the function are also the same and take the same values, which avoids conflicts for the user. The only new parameter is db_backup_after which allows us to control how many rows the iteration is done. A smaller value means more iterations, which results in higher local memory usage, but also faster in finding data that already exists in the DB. On the other hand, a higher value reduces the number of iterations but increases the number of API connections. For this reason I have given it a default value of 10. This, in addition to being a balanced value, also reduces confusion for the user who might not be familiar with the changes.\nRemove missing values from the database In the previous proposal, only found coordinates were sent to the database, and those not found were ignored. In the present proposal, all entries are sent to the DB. Therefore, it is important to have some option to remove the missing entries.\nFor this I generated the function remove_na_from_db, a very simple function which gives the user the possibility of removing NAs automatically.\n1 2 3 4 5 6 7 remove_na_from_db \u0026lt;- function(db.file) { require(RSQLite) con \u0026lt;- dbConnect(drv = RSQLite::SQLite(), dbname = db.file) dbExecute(conn = con, \u0026#34;DELETE FROM orgs WHERE lon IS NULL OR trim(lon) = \u0026#39;\u0026#39;;\u0026#34;) dbDisconnect(con) } The function is just a connection to the database that issues the command to remove rows where the lon field is empty, in SQLite syntax. This is the safest, most direct and fastest way to do it. We could also import the data back into R, filter it, and send it back to SQLite, but this would require more local memory usage, more code, and more risk as it would require rewriting the database to SQLite entirely. . The power of the RSQLite library (or any other library that connects R to SQL) lies precisely in the ability to pass commands written and executed directly in SQL.\nObtaining the coordinates The coords_from_city function also received significant changes in code readability and flexibility, and a bit less in functionality and efficiency.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 coords_from_city \u0026lt;- function(city = NULL, country_code, region = NULL, state = NULL, county = NULL) { require(\u0026#34;RJSONIO\u0026#34;) ## 1. Abstract regions for OSM CityCoded \u0026lt;- gsub(\u0026#34; \u0026#34;, \u0026#34;%20\u0026#34;, City) CountryCoded \u0026lt;- paste(\u0026#34;\u0026amp;countrycodes=\u0026#34;, CountryTwoLetter, sep = \u0026#34;\u0026#34;) extras \u0026lt;- c(city = City, state = State, region = Region, county = County) extrasCoded \u0026lt;- \u0026#34;\u0026#34; if (!is.null(extras)) { for (i in 1:length(extras)) { if (extras[i] != \u0026#34;\u0026#34; \u0026amp;\u0026amp; !is.na(extras[i]) \u0026amp;\u0026amp; !grepl(\u0026#34;^\\\\s*$\u0026#34;, extras[i])) { valCoded \u0026lt;- gsub(\u0026#34; \u0026#34;, \u0026#34;%20\u0026#34;, extras[i]) extrasCoded \u0026lt;- paste0(extrasCoded, \u0026#34;\u0026amp;\u0026#34;, names(extras)[i], \u0026#34;=\u0026#34;, valCoded) } } } ## 2. Response link \u0026lt;- paste( \u0026#34;http://nominatim.openstreetmap.org/search?city=\u0026#34; , extrasCoded , CountryCoded , \u0026#34;\u0026amp;format=json\u0026#34; , sep = \u0026#34;\u0026#34; ) response \u0026lt;- try({fromJSON(link)}, silent = TRUE) if (class(response) == \u0026#34;try-error\u0026#34;) { stop(response[1]) } else if (class(response) == \u0026#34;response\u0026#34;) { response_status \u0026lt;- http_status(response) if (response_status$category != \u0026#34;Success\u0026#34;) { stop(response_status$message) } } else if (is.list(response)) { ## 3. Organize results if (length(response) == 0) { message(paste(\u0026#34;No results found for\u0026#34;, extrasCoded)) coords \u0026lt;- data.frame(\u0026#34;lon\u0026#34; = NA, \u0026#34;lat\u0026#34; = NA, \u0026#34;osm_name\u0026#34; = as.character(NA)) } else if (length(response) == 1) { message(paste(\u0026#34;Found\u0026#34;, response[[1]]$display_name)) coords \u0026lt;- data.frame( lon = response[[1]]$lon, lat = response[[1]]$lat, osm_name = response[[1]]$display_name ) } else { message(paste(\u0026#34;Several entries found for\u0026#34;, city, country_code)) coords \u0026lt;- data.frame( lon = response[[1]]$lon, lat = response[[1]]$lat, osm_name = response[[1]]$display_name ) } } ## 4. Exit as data frame return(coords) } The main change is in section 1, instead of passing each of the regions as its own string and formatting them one by one, I have abstracted them all into a single vector. This reduces the amount of code, memory usage, and allows us to include the city in the list, making it an optional value as well. The reason I had prepared them separately in the previous post is simply because the feature grew slowly: at first we only needed city, but then we had to use some additional fields depending on the country we were working in. To make things easier for me, I simply added each region field as needed. Now that I have time to work on the code, this was the first function I modified.\nStep 2 now prints messages that help us identify the error when it comes to the connection, while also stopping the process. Whether it is a local connection error, or problems on the API side, we will get a message and the process will stop, which should avoid long waiting times when there is no connection and several locations are being searched.\nStep 3 changes the organization of the results a bit, always returning a data frame with the same columns when the results were not found, but now with empty fields in such case. This helps the functions presented above to populate the database. Additionally, when many results were found, this information is printed on the screen; for now this is for information purposes only. The idea is to keep this space to make changes in the future that allow us to select the option interactively. This is something I still need to think about and plan properly because on one hand I want to use it in a Shiny app, and on the other we want to keep the ability for web scrapping to happen automatically with as little intervention as possible.\nAs I mentioned before, these new features also allow us to perform searches with the empty city value. This was a requested requirement in the last version, as some users started making maps by region, while others, not finding very small cities, decided to group the data by region. Thanks to the changes made to coords_from_city, the webscrap_to_sqlite function can now return results when the value for city is NA, assuming that the coordinates for the region or state are found. Here it is important to mention that it is recommended to use the state argument for region search, for some reason this works better in the OSM API. As an example, the search coords_from_city(state = \u0026quot;Castilla La Mancha\u0026quot;, country_code = \u0026quot;ES\u0026quot;) returns the expected results, despite of the fact that Spain has no states; however if we do coords_from_city(region = \u0026quot;Castilla La Mancha\u0026quot;, country_code = \u0026quot;ES\u0026quot;) nominatim does not find the results.\nConclusions These changes have been very important in speeding up the coordinate search process and automating map creation. On the other hand, it allowed me to style the code more and improve its efficiency. Since my main project for now is turning it into a Shiny app, it was important for me to improve the code and the efficiency before dealing with the details of the server. Since this is recent work that I have been doing in the last few months, I decided to share it right away now that I have fresh information on the changes. I hope it can help more than one to make more abstract code and practice recursion.\n","pubDate":"2023-03-24","title":"Webscrap and iteration in R"},{"link":"http://example.org/es/posts/2023/webscrap_e_iteracion_con_r/","plain":"Sobre este post Estamos creando mapas de datos que muestran los cambios durante un período de tiempo para diferentes países y orientado a todo tipo de ciudades. Esto básicamente significa que necesitamos mapear cualquier región del mundo con R. Hoy en día existen todo tipo de paquetes y técnicas para hacerlo. Quiero compartir la estrategia que utilicé con ggplot2 y maps, utilizando el soporte de Open Street Map para obtener las coordenadas de las ciudades y finalmente hacerlo interactivo con shiny.\nEstas publicaciones comparten mi camino en la creación de la aplicación Shiny. Es un proyecto vivo en el que estoy trabajando actualmente y decidí compartir mis experiencias durante el proceso de creación. Estas publicaciones no son sólo acerca de Shiny apps, si no más bien sobre la creación del paquete detrás, incluyendo temas sobre la generación de funciones, creación de los mapas, clases de objetos, entre otros, incluyendo cualquier tema interesante que aparezca en el camino. Es mi manera de contribuir a la comunidad de R y al mismo tiempo documentar el proyecto en si mismo.\nPueden encontrar todas las publicaciones en este tema bajo la etiqueta maps-app (incluyendo las versiones en inglés).\nTambién pueden encontrar el estado actual del proyecto en mi GitHub repo mapic.\nEste post está escrito originalmente en español, desde el aeropuerto de Amsterdam, de camino a México. Espero que lo disfruten. Siéntanse libres de dejar cualquier tipo de comentario y/o pregunta al final.\nMotivación Como mencioné en los posts anteriores de la serie, he estado trabajando últimamente en el código para la creación de los mapas y he hecho cambios que incrementan la eficiencia de las funciones, la lectura del código, y facilitan su uso, al mismo tiempo que me permite extender las funciones mas allá de cómo fueron originalmente diseñadas.\nHe mencionado en algunas ocasiones que el código evolucionó poco a poco a partir de scripts creados para generar el mapa específico de algún país. Por lo tanto, las primeras funciones son más bien una colección de los pasos utilizados para generar el mapa, atrapados en forma de funciones para automatizar el proceso.\nPor este motivo había querido hacer cambios para adecuar las funciones a paradigmas mas adecuados a la programación funcional, que es el punto fuerte de R. Sin embargo, la prioridad era generar los mapas, así que la mayoría de mi tiempo iba dirigido a la creación de los mapas y el debug del código cuando era necesario. A esto debo agregar que este proyecto es parte de un trabajo voluntario para una ONG, de la cual pasé a ser el director de la división de investigación, lo que me generaba aún mas responsabilidades y trabajo. Y todo como trabajo secundario, separado de mi fuente principal de ingresos (que también esta basada en R).\nSin embargo, para bien o para mal, 2022 fue un año lleno de cambios y retos para mi y mi familia, lo que me obligó a dejar de lado el proyecto por un tiempo, resignar mi posición como director de la división, y enfocarme únicamente a mi carrera, mi salud y mi familia. Esto resultó en que, al recuperar la estabilidad en mi vida, me encontré con mas tiempo libre y menos obligaciones para re pensar el código y trabajar en ello. Adicionalmente, mi trabajo principal tuvo un giro que fue de la estadística a mas orientado a la programación en R, lo cual me ha dado mas herramientas para mejorar el código, y me ha motivado a retomar viejas lecciones sobre programación funcional y, sobre todo, iteración.\nEsto me permitió mejorar las dos funciones principales: la encargada del webscrapping y la que manda los datos a SQLite. Puedes encontrar las funciones originales en el post anterior Mapa de cualquier región del mundo con R - Parte I: El mapa base y compararlos con las nuevas funciones mejoradas en este.\nWebscrapp a SQLite La función webscrap_to_sqlite se encarga de enviar las coordenadas encontradas por Open Street Map a nuestra base de datos. La función como está definida originalmente es poco efectiva, ya que hace cada operación línea por línea. También es muy rígida en la forma en la que dirige los valores de las regiones, tanto su petición a la API como la colocación de los valores en la base de datos, lo que hace cualquier extensión o modificación muy complicada.\nPor lo tanto, es la función que recibió mas cambios, fue prácticamente re escrita desde ceros, haciendo la búsqueda mas eficiente, permitiendo también búsqueda interna de los datos ya almacenados; mas flexible, lidiando con los parámetros de las regiones de forma mas clara; y mas entendible, mejorando el estilo del código.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 webscrap_to_sqlite \u0026lt;- function(db.name, dat, city = \u0026#34;City\u0026#34;, country = \u0026#34;Country\u0026#34;, region = NULL, state = NULL, county = NULL, db_backup_after = 10) { ## Cargas las liberarias necesarias require(RSQLite) require(dplyr) ## 1. Conexion a la DB con \u0026lt;- dbConnect(drv = SQLite(), dbname = db.name) dbExecute(conn = con, \u0026#34;CREATE TABLE IF NOT EXISTS orgs (ID INTEGER UNIQUE, City TEXT, Country TEXT, Region TEXT, State TEXT, County TEXT, osm_name TEXT, lon REAL, lat REAL)\u0026#34;) db \u0026lt;- as_tibble(dbReadTable(con, \u0026#34;orgs\u0026#34;)) ## 2. Filtrado de los datos new_coords \u0026lt;- data.frame() dat_local \u0026lt;- compare_db_data(db.name, dat) df_len \u0026lt;- nrow(dat_local) ## 3. Mientras haya filas en DF repetimos: if (df_len != 0) { ## 3.1 Definir tamaño de la sub-muestra dat_local \u0026lt;- dat_local[c(1:db_backup_after), ] dat_local \u0026lt;- filter(dat_local, rowSums(is.na(dat_local)) != ncol(dat_local)) ## 3.2 for loop para el webscrapping for (i in 1:nrow(dat_local)) { print(paste0(\u0026#34;Searching entry \u0026#34;, dat_local[[\u0026#34;ID\u0026#34;]][i])) ## 3.3 Abstracción de la info rg \u0026lt;- ifelse(is.null(region), \u0026#34;\u0026#34;, dat_local[[region]][i]) st \u0026lt;- ifelse(is.null(state), \u0026#34;\u0026#34;, dat_local[[state]][i]) ct \u0026lt;- ifelse(is.null(county), \u0026#34;\u0026#34;, dat_local[[county]][i]) rcity \u0026lt;- dat_local[[city]][i] rcountry \u0026lt;- dat_local[[country]][i] ## 3.4 Obtener las coordenadas ## 3.4.1. Primero buscamos si ya existen en DB search_query \u0026lt;- filter(db, City == rcity, Country == rcountry, Region == rg, State == st, County == ct) if (nrow(search_query != 0)) { coords \u0026lt;- search_query[1, ] coords$ID \u0026lt;- dat_local[[\u0026#34;ID\u0026#34;]][i] print(\u0026#34;Found from memory\u0026#34;) ## 3.4.2 Si aun no existen, busca en OSM API } else { coords \u0026lt;- coords_from_city(rcity, rcountry, Region = rg, State = st, County = ct) coords \u0026lt;- cbind(ID = dat_local[[\u0026#34;ID\u0026#34;]][i], City = rcity, Country = rcountry, Region = rg, State = st, County = ct, coords) } new_coords \u0026lt;- rbind(new_coords, coords) } ## Y envía sólo los nuevos resultados a la DB dbWriteTable(con, \u0026#34;orgs\u0026#34;, new_coords, append = TRUE) dbDisconnect(con) ## 3.4.3 Repetir webscrap_to_sqlite(db.name = db.name, dat = dat, city = city, country = country, region = region, state = state, county = county, db_backup_after = db_backup_after) ## 4. Terminar la iteracion } else { db_final \u0026lt;- import_db_as_df(db.name) size \u0026lt;- nrow(db_final) not_found \u0026lt;- nrow(db_final[is.na(db_final$lat), ]) message(paste(\u0026#34;Search finished.\\n\u0026#34;, size, \u0026#34;entries searched.\\n\u0026#34;, not_found, \u0026#34;ENTRIES NOT FOUND\u0026#34;)) } } La función comienza llamando a las librerías necesarias y (1) conectándose a la base de datos, creándola si es necesario. (2) Luego genero dos data frames, uno vacío que almacenará nuevas coordenadas y otro relativo que contiene únicamente los datos que aún no existen en la base de datos. (3) Así pues, mientras haya datos en esta última data frame, la función continuará repitiéndose.\n(3.1) Luego definimos la sub-muestra, que es un sub conjunto de dat_local del tamaño de db_backup_after y nos enfocamos únicamente en esta sub-muestra. (3.2) Sobre esa sub muestra hacemos las iteraciones utilizando for para obtener las coordenadas. Primero (3.3) preparamos la información como strings y después (3.4) buscamos las coordenadas. (3.4.1) Si ya existen en la base de datos lo tomamos de ahí, y si no (3.4.2) se buscan utilizado coords_from_city. Finalmente, (3.4.3) repetimos todo de nuevo permitiendo a la función llamarse a si misma.\nDado que en el paso 2 se filtran los datos que aún no están en la base de datos y en 3 se colocan los resultados de nuevas búsquedas en un data frame vacío, la función se llama a sí misma y aplica únicamente para cada sub conjunto de datos. Cuando finalmente compare_db_data arroja 0 valores por que todos los datos que se ingresaron a la función ya están contenidos en la base de datos, podemos salir de la función. En este caso decidí importar de nuevo los datos desde SQLite para obtener detalles de la búsqueda, y terminar la iteración enviando un mensaje al usuario sobre el total de entradas y la cantidad de las cuales no fueron encontradas.\nSi comparamos esta función con la propuesta en mi post anterior, la función es completamente diferente pero el resultado final es el mismo. Los argumentos utilizados por la función también son los mismo y toman los mismos valores, lo cual evita conflictos para el usuario. El único parámetro nuevo es db_backup_after que nos permite controlar a cada cuantas filas se realiza la iteración. Un valor mas pequeño significa más iteraciones, lo que resultado en un mayor uso de la memoria local, pero también mayor agilidad para encontrar datos que ya existen en la DB. Por otro lado, un valor mas alto reduce el número de iteraciones pero incrementa el número de conexiones a la API. Por este motivo le he otorgado un valor pre definido de 10. Esto, además de ser un valor balanceado, también reduce la confusión del usuario que podría no estar familiarizado con los cambios.\nRemover valores faltantes de la base de datos En la propuesta anterior, únicamente las coordenadas encontradas eran enviadas a la base de datos, y las no encontradas se ignoraban. En la propuesta presente, todas las entradas se envían a la DB. Por lo tanto, es importante tener alguna opción para remover las entradas no encontradas.\nPara ello generé la función remove_na_from_db, una función muy simple pero que le otorga al usuario una propuesta remover NAs automáticamente.\n1 2 3 4 5 6 7 remove_na_from_db \u0026lt;- function(db.file) { require(RSQLite) con \u0026lt;- dbConnect(drv = RSQLite::SQLite(), dbname = db.file) dbExecute(conn = con, \u0026#34;DELETE FROM orgs WHERE lon IS NULL OR trim(lon) = \u0026#39;\u0026#39;;\u0026#34;) dbDisconnect(con) } La función es únicamente una conexión a la base de datos que envía la orden de remover filas donde el campo lon está vacío, en sintaxis de SQLite. Esto es la manera mas segura, directa y rápida de hacerlo. También podríamos importar los datos de nuevo a R, filtrarlos y enviarlos de nuevo a SQLite, pero esto requeriría mayor uso de la memoria local, mayor cantidad de código y un mayor riesgo ya que requeriría re-escribir la base de datos a SQLite por completo. El poder de la librería RSQLite (o cualquier otra librería que conecta a R con SQL) está precisamente en la posibilidad de pasar ordenes escritas y ejecutadas directamente en SQL.\nLa obtención de las coordenadas La función coords_from_city también recibió cambios considerables en lectura del código y flexibilidad, y un poco menores en funcionamiento y eficiencia.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 coords_from_city \u0026lt;- function(city = NULL, country_code, region = NULL, state = NULL, county = NULL) { require(\u0026#34;RJSONIO\u0026#34;) ## 1. Abstracción de regiones para OSM CityCoded \u0026lt;- gsub(\u0026#34; \u0026#34;, \u0026#34;%20\u0026#34;, City) CountryCoded \u0026lt;- paste(\u0026#34;\u0026amp;countrycodes=\u0026#34;, CountryTwoLetter, sep = \u0026#34;\u0026#34;) extras \u0026lt;- c(city = City, state = State, region = Region, county = County) extrasCoded \u0026lt;- \u0026#34;\u0026#34; if (!is.null(extras)) { for (i in 1:length(extras)) { if (extras[i] != \u0026#34;\u0026#34; \u0026amp;\u0026amp; !is.na(extras[i]) \u0026amp;\u0026amp; !grepl(\u0026#34;^\\\\s*$\u0026#34;, extras[i])) { valCoded \u0026lt;- gsub(\u0026#34; \u0026#34;, \u0026#34;%20\u0026#34;, extras[i]) extrasCoded \u0026lt;- paste0(extrasCoded, \u0026#34;\u0026amp;\u0026#34;, names(extras)[i], \u0026#34;=\u0026#34;, valCoded) } } } ## 2. Respuesta link \u0026lt;- paste( \u0026#34;http://nominatim.openstreetmap.org/search?city=\u0026#34; , extrasCoded , CountryCoded , \u0026#34;\u0026amp;format=json\u0026#34; , sep = \u0026#34;\u0026#34; ) response \u0026lt;- try({fromJSON(link)}, silent = TRUE) if (class(response) == \u0026#34;try-error\u0026#34;) { stop(response[1]) } else if (class(response) == \u0026#34;response\u0026#34;) { response_status \u0026lt;- http_status(response) if (response_status$category != \u0026#34;Success\u0026#34;) { stop(response_status$message) } } else if (is.list(response)) { ## 3. Organización de los resultados if (length(response) == 0) { message(paste(\u0026#34;No results found for\u0026#34;, extrasCoded)) coords \u0026lt;- data.frame(\u0026#34;lon\u0026#34; = NA, \u0026#34;lat\u0026#34; = NA, \u0026#34;osm_name\u0026#34; = as.character(NA)) } else if (length(response) == 1) { message(paste(\u0026#34;Found\u0026#34;, response[[1]]$display_name)) coords \u0026lt;- data.frame( lon = response[[1]]$lon, lat = response[[1]]$lat, osm_name = response[[1]]$display_name ) } else { message(paste(\u0026#34;Several entries found for\u0026#34;, city, country_code)) coords \u0026lt;- data.frame( lon = response[[1]]$lon, lat = response[[1]]$lat, osm_name = response[[1]]$display_name ) } ## 4. Salida como data frame return(coords) } \u0026gt; Error: \u0026lt;text\u0026gt;:68:0: unexpected end of input \u0026gt; 66: return(coords) \u0026gt; 67: } \u0026gt; ^ El principal cambio está en la sección 1, en lugar de pasar cada una de las regiones como su propio string y darles formato una por una, las he abstraído todas en un solo vector. Esto reduce la cantidad de código, el uso de memoria, y nos permite incluir la ciudad en la lista, convirtiéndolo también en un valor opcional. La razón por la que las había preparado por separado publicación anterior es simplemente porque la función creció lentamente: al principio solo necesitábamos ciudad, pero luego tuvimos que usar algunos campos adicionales según el país en el que trabajábamos. Para facilitarme las cosas, simplemente agregué cada campo de región según fuera necesario. Ahora que tengo tiempo para trabajar en el código, esta fue la primera función que modifiqué.\nEl paso 2 ahora imprime mensajes que nos ayudan a identificar el error cuando se trata de la conexión, al mismo tiempo que detiene el proceso. Ya sea un error local de conexión, o problemas del lado del API, obtendremos un mensaje y el proceso se detendrá, lo cual debe evitar tiempos de espera largos cuando no hay conexión y se está haciendo la búsqueda de muchas localidades.\nEl paso 3 cambia un poco la organización de los resultados, devolviendo siempre un data frame con las mismas columnas cuando los resultados no fueron encontrados, pero ahora con los campos vacíos en dicho caso. Esto ayuda a las funciones presentadas anteriormente para llenar la base de datos. Adicionalmente, cuando muchos resultados fueron encontrados, se imprime esta información en pantalla; por ahora es sólo como información. La idea es mantener este espacio para realizar cambios en el futuro que nos permitan seleccionar la opción de manera interactiva. Esto es algo que aún necesito pensar y planear por que, por un lado quiero utilizarlo en una aplicación Shiny, y por otro lado queremos mantener la habilidad de que el web scrapping suceda automáticamente con menor intervención posible.\nComo ya he mencionado antes, estas nuevas funciones también nos permiten realizar búsquedas con el valor de ciudad vacío. Este fue un requisito solicitado en la última versión, ya que algunos usuarios comenzaron a hacer mapas por regiones, mientras que otros, al no encontrar ciudades muy pequeñas, decidieron agrupar los datos por región. Gracias a los cambios realizados en coords_from_city, la función webscrap_to_sqlite ahora puede obtener resultados cuando el valor para ciudad es NA, considerando que se encuentren las coordenadas para la región o el estado. Aquí es importante mencionar que se recomienda utilizar el argumento state para la búsqueda de regiones, por alguna razón, esto función mejor en la API de OSM. Como ejemplo, la búsqueda coords_from_city(state = \u0026quot;Castilla La Mancha\u0026quot;, country_code = \u0026quot;ES\u0026quot;) nos arroja los resultados esperados, a pesar de que España no tiene estados; sin embargo si hacemos coords_from_city(region = \u0026quot;Castilla La Mancha\u0026quot;, country_code = \u0026quot;ES\u0026quot;) nominatim no encuentra los resultados.\nConclusiones Estos cambios han resultado muy importantes para agilizar el proceso de la búsqueda de coordenadas y la automatización de la creación de mapas. Por otro lado, me permitió darle mas estilo al código y mejorar su eficiencia. Ya que mi principal proyecto por ahora es convertirlo en una aplicación Shiny, era importante para mi el mejorar el código y la eficiencia antes de lidiar con los detalles del server. Ya que este es un trabajo reciente que he realizado en los últimos meses, decidí compartirlo de inmediato ahora que tengo fresca la información de los cambios. Espero que pueda a ayudar a mas de uno a hacer código mas abstracto y practicar recursión.\n","pubDate":"2023-03-24","title":"Webscrap e iteraciones con R"},{"link":"http://example.org/posts/2023/reference_dockerizing_shinny_apps/","plain":"Andrew Couch has a nice video about deploying a shiny app using docker. He goes from the very basics, that asume no knowledge of docker whatsoever, which is the position of many R users like myself. I\u0026rsquo;ve been working in some shiny app lately, and although I\u0026rsquo;ve never needed docker so far, I decided to start learning it because I can already foresee the future when it won\u0026rsquo;t be the case. Andrew makes some good points about how most tutorials assume the reader to know the basics of docker and start from there. While these are easy to follow, it is difficult to understand what we are doing and why we are doing it. That creates later problems to extend and debug the apps. Andrew shares his experience in searching for solid info and then proceeds with a tutorial where he explains basic parts, commands, and code of a docker file.\nHe also recommends a post from statworx that is clearly the inspiration for his video. The post contains all the info necessary to dockerize a first shiny app. The post is short and clear, and it\u0026rsquo;s an excellent complement for the video.\nI might try dockerizing some simple shiny app and share the experience here if I find something new or interesting that can add value to the mentioned links. Otherwise, you can stay with these as the basis for dockerizing a shiny app and wait for my post of dockerizing using Guix, which is my main target for now in order to make my app reproducible. Stay in orbit.\n","pubDate":"2023-02-11","title":"Reference: Dockerizing shinny apps"},{"link":"http://example.org/es/posts/2023/referencia_dockerizar_shinny_apps/","plain":"Andrew Couch tiene un video genial sobre como poner una aplicación shiny en docker. El video está en inglés, pero bien vale la pena. Va desde lo más básico, sin asumir ningún conocimiento de docker, lo cual es la situación de muchos usuarios de R como yo mismo. Últimamente he estado trabajando en unas aplicaciones Shiny y a pesar de que nunca he necesitado de Docker, ya puedo preveer el momento en que esto cambiará, por lo que decidí comenzar a aprender como usarlo. Andrew toca unos puntos muy buenos de cómo la mayoría de tutoriales en la web asumen que el lector ya conoce Docker y van a partir de ahí. A pesar de que esos tutoriales son fáciles de seguir, es difícil entender que estamos haciendo y el por qué. Esto genera mas problemas a futuro para extender y debuggear la aplicación. Andrew comparte su experiencia en busca de información sólida y luego procede a dar el tutorial donde explica las partes básicas, comandos y el código de un archivo Docker.\nTambién recomienda una entrada de statworx (también en inglés) que es claramente la inspiración para su video. La entrada contiene información necesaria para dockerizar tu primera aplicación shiny. El texto es corto y claro, y hace un complemento al video. Si tienes problemas con el inglés, está es la entrada ideal para ti ya que puede ser traducida fácilmente.\nTal vez intentaré dockerizar alguna aplicación de prueba siguiendo las instrucciones y comparta mi experiencia aquí, siempre y cuando encuentre algo nuevo que agregue valor a los links compartidos. De lo contrario pueden utilizar dichos links como las bases y esperar a mi post de como dockerizar utilizando Guix, que es mi principal objetivo por ahora con el propósito de hacer mi aplicación reproducible. Manténganse en órbita.\n","pubDate":"2023-02-11","title":"Referencia: Dockerizando shinny apps"},{"link":"http://example.org/posts/2023/deploy_shiny_on_debian/","plain":"A few weeks ago I opened an account on Digital Ocean to start my own cloud server. Not long after that I took a workshop on Shiny and, although it was too technical with nothing new for me, I learn a couple of things unrelated to R. The speaker was talking about the importance of making your portfolio showing your apps instead of sharing the link to your code as most of us do. I thought it makes sense since anybody who sees our GitHub account can take whatever they want from it, and at the end is only code, which many recruiters and managers are not familiar with. On the other hand if you show some apps you can definitely impress your audience. And so, since Digital Ocean gives you 200 USD of credit for the first 2 months, I decided to try and install my own Shiny server there.\nThere are plenty of source on the web on how to set up your own shiny server, but most of them focus on Docker, which gives you a little less control over it. I wanted something that I could fully control myself because in the past I have deployed Shiny apps on Heroku using a process that I did not understand well and thus, it was really difficult to debug or modify. For good or bad, Heroku canceled the free accounts and thus I decided to try Digital Ocean. The big advantage for me is that Digital Ocean gives you the possibility of using what basically is a Virtual Machine with a minimal Linux installation. Since I\u0026rsquo;ve been using Debian for the last 10 years, I initialized a Debian 11 server and it was really easy to set up my own cloud service without the use of Docker, and not long later, also my own Shiny server. Of course I did it with the help of Google, with some really useful and clear tutorials I found in marine data science (two links, part 1 and part 2 can be found here) and of course, directly from Digital Ocean\u0026rsquo;s Guide.\nThat work inspired me to set up my own home server and to write this guide. Although the sources I found are really helpful, they are lacking a few steps if you set up your own server from scratch, and they are also lacking some sources of where to find when the software gets up to date, providing only old links. Therefore, I decided to make this guide, covering all those topics and keeping a registry of the links, to help myself in the future and to help anybody who want to try it.\nAbout this guide As mentioned, this guide is designed to explain in a step by step manner how to deploy shinny apps on your own server using Debian 11. Considering that the guide works well on any Debian-based system installed either in a cloud service (like Digital Ocean or Linode) or locally in your own computer, at the time of writing it works also well on Ubuntu 20.\nThe guide pretends to be a point of reference and you can follow it from beginning to end, by changing the order of some steps, or simply as a reference of certain points. Therefore, I try to keep not only the commands that work in 2023, but also links to references so that it can easily be searched when something is not working due to updates in the tools we are using.\nWhy should I have my own server? I cannot highlight enough that this guide pretends to explain how to install your own Shiny server in a Debian-based system located either in a cloud, a virtual machine or your own computer.\nI am using an old Dell laptop with only 1 core, about 3 GB of RAM and 500 GB of memory. Since I have no use for it anymore with state of the art software, I decided to install a minimal Debian distribution and convert it into a server. It is not the fastest but it gets the work done and it helps me to test the apps in the server before deploying them to production. I\u0026rsquo;m sure that many of you have noticed that it is not the same when you run the app in the computer you are developing than when you deploy it to the server. Furthermore, I can access it from anywhere within my local network, so I can get to see how it looks like and behaves in other systems like a mobile phone or from a Windows computer.\nThe best part of having my local server with Debian 11 is that I can mimic my droplet in Digital Ocean, also in Debian 11, and get an accurate view of my app before deploying it to production, doing all the changes or modifications to the system in advance to learn which ones work best and avoid installing extra apps or making useless changes in the paid server (I\u0026rsquo;m sure we all have ever changed some configuration files so much that when it all crashes, we have no idea how to set them back to default).\nAdditionally, my own server in Digital Ocean allows me to control what exactly I have there. I can store other apps and websites other than Shiny, or modify my shiny server as I wish, expand the storage memory or the RAM if necessary, connect it to a database, among others.\nAnd finally and probably most important, it exposes me to real world problems that appear when developing Shiny apps. Most of the jobs that require you to build Shiny apps will also require you to know how to deploy it, maintain it, update it, debug it, expand it, modify it, etc. Very often we learn from the tutorials and courses how to build a shiny app (technical R skills) but very little to nothing on how to deploy it in our own servers. That is the reason why I didn\u0026rsquo;t want to use any semi-automatized tool and rather wanted to get my hands dirty on doing it. And this is what this guide is about.\nStep by Step guide Pre-requisites Using Digital Ocean If you choose to use Digital Ocean, make sure to start a new droplet with SSH. See How to create a Droplet in the Difital Ocean\u0026rsquo;s own guides. In that way it would be easier to follow this guide. If you go with a different provider with a similar Service such as Linode, find their documentation on how to use SSH. Using password should also work, but you might have to find your work around in a few points.\nUsing Debian minimal installation When you use a cloud service your basic Debian or Ubuntu installation comes with all the basic tools that you need to start building up your websites. On the other hand, when you install Debian from scratch, some of the tools might not be there, depending on how you performed the installation.\nIn my case, I had to do a minimal installation without internet connection due to problems with the drivers of my old laptop, therefore I found out that some important and basic tools were missing. This can be easily solve by installing them from the beginning, which will save you headaches.\n1 apt install sudo git curl systemd rsync ufw ssh ssh-server net-tools As you can see, I am installing sudo because my Debian installation did not include it. That means that at the beginning I should work as root. If you\u0026rsquo;re not sure how to do it, simply type root at startup as your user name, then your root password and you should then see a functional terminal showing you something like root@debian:/.\nIf you are using this option you should probably be following the guide directly from the computer that is working as the server. If that is the case, you might not need to use SSH. However I would strongly recommend it. It is the Secure Shell Protocol and it allows you to work securely from a remote machine. As a practical example, for me it means that I can have my server computer without a screen (and thus, without a desktop environment) in some corner, plugged to my router with an Ethernet cable and do all the work from the comfort of my standard personal computer, which I will call the remote.\nTo connect remotely using SSH you need to generate a key and copy it to the other computer.\n1 2 ssh-keygen ssh-copy-id user@192.168.0.xxx Execute the code above in both, your remote and your server. ssh-keygen will generate the keys, and the easiest way is to follow the default values given after executing it. ssh-copy-id will copy it to the other computer you want to connect with. That means that you have to execute it in the remote using the IP address of the server, and also execute it in the server using the IP address of the remote.\nThere are different ways to find you IP address. If you installed net-tools from the step above, you can do sudo ifconfig -a. In Debian and Ubuntu, the IP for wifi connection is usually shown in the section wlan0 and if you are connected via Ethernet, in the section eth0.\nCreate a user and add SSH keys No matter the option you chose above, you can follow this guide to create a new user and add the SSH login, given that you chose SSH when you created the droplet, or the step above with ssh-keygen if you are creating your own server.\nDepending on the distribution you chose, here is the Initial Server Setup with Ubuntu 20.04 and Initial Server Setup with Debian 10. The links also show how to set up a basic firewall using ufw, which I highly recommend. I recommend following those guides to 1) create a user other than root; 2) allow ssh key for that user and; 3) set up a ufw firewall.\nInstall and start Nginx To be able to show content to the public using the HTTP you need a web server to be installed. The two most popular web servers are Apache and nginx and both would be similarly suitable. I went for nginx which I\u0026rsquo;m more familiar with and I\u0026rsquo;m learning at the moment. You can also follow the instructions given by DigitalOcean.\nBasically you need to install it, open the firewall for it, and start the service:\n1 2 3 4 5 sudo apt install ngninx sudo ufw allow \u0026#39;Nginx Full\u0026#39; sudo service nginx start Now we can check the status of Nginx with sudo service nginx status\nCustom domain name (optional) If you want to point to your own domain rather than your public IP address, you should first buy a domain name and then set up a DNS for the domain. Here is Digital Ocean\u0026rsquo;s guide on How to point to your server with the most common domain name registrars.\nIn my case I created a subdomain from my current rwhitedwarf.com that I already have in namecheap. Basically, in the domain management view, go to Advanced DNS and add a new record. It can simply be \u0026ldquo;A Record\u0026rdquo; with the host pointing at the subdomain you want, in my case I chose apps, and your public IP.\nWhatever your choice is, you should be able to see the Nginx welcome page as the image below shows, when you go to your chosen address. In my case I can see it under apps.rwhitedwarf.com.\nKeep in mind that, since we still don\u0026rsquo;t add the SSL certificate, your website appears as http instead of https and thus, your browser might warn you about a connection not secure. You can try to overtake the warning and see your Nginx welcome page for the purpose of testing, in order to make sure that everything went well before moving to the next step.\nAdd SSL certificate to get HTTPS (optional) It is recommended to secure nginx with Let\u0026rsquo;s Encrypt which is a Certificate Authority (CA) that provides an easy way to obtain and install free TLS/SSL certificates. Here are the instructions from Digital Ocean to do it.\nWe basically need to install and activate certbot, the python script that activates let\u0026rsquo;s encrypt.\n1 2 # Install the package sudo apt install certbot python3-certbot-nginx If you are working on Ubuntu the instructions are a bit different, check this link from Digital Ocean for it.\nWe also need to configure Nginx file /etc/nginx/sites-available/default. There are a few options for that. You can do it directly in the console using nano or emacs (you need to install the second first).\n1 2 3 4 5 # using nano sudo nano /etc/nginx/sites-available/default # using emacs sudo emacs -nw /etc/nginx/sites-available/default With Nano you basically need to follow the instructions at the bottom of the console. In short, use Ctrl+O to save and Ctrl+X to exit. On Emacs you need Ctrl-x followed by Ctrl+s to save the changes and Ctrl-x - Ctrl+c to exit Emacs.\nYou can also work directly from your GUI Emacs in your remote computer (the easiest option) using tramp with M-x and the command ssh:user@xx.xx.xx.xx|sudo::/etc/nginx/sites-enabled/default where xx.xx.xx.xx is your IP address on the server.\nOnce you are in the file, search for the line that reads server_name _; and replace the underscore for your domain. In my case it looks like this:\n# Add index.php to the list if you are using PHP index index.html index.htm index.nginx-debian.html; server_name apps.rwhitedwarf.com; location / {... Save it and test nginx by executing sudo nginx -t. If all is good, it should print something like below\n1 2 nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful Then reload nginx\n1 sudo systemctl reload nginx We need to ensure that the firewall is open for it. Check with sudo ufw status that Nginx is allowed, it should print something like the following\n1 2 3 4 5 6 To Action From -- ------ ---- OpenSSH ALLOW Anywhere Nginx Full ALLOW Anywhere OpenSSH (v6) ALLOW Anywhere (v6) Nginx Full (v6) ALLOW Anywhere (v6) If something is missing, execute the commands below and check the status again.\n1 2 sudo ufw allow \u0026#39;Nginx Full\u0026#39; sudo ufw delete allow \u0026#39;Nginx HTTP\u0026#39; Once all this is ready, we can proceed to obtain the SSL certificate using Certbot. Certbot provides a variety of ways to obtain SSL certificates through plugins. The Nginx plugin will take care of reconfiguring Nginx and reloading the config whenever necessary. To use this plugin, type the following:\n1 sudo certbot --nginx -d www.example.com Make sure to change www.example.com for your own domain. In my case it is sudo certbot --nginx -d apps.rwhitedwarf.com. If this is your first time running certbot, you will be prompted to enter an email address and agree to the terms of service. After doing so, certbot will communicate with the Let\u0026rsquo;s Encrypt server, then run a challenge to verify that you control the domain you\u0026rsquo;re requesting a certificate for.\nThe configuration will be updated, and Nginx will reload to pick up the new settings. certbot will wrap up with a message telling you the process was successful and where your certificates are stored:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Congratulations! You have successfully enabled https://apps.rwhitedwarf.com - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Subscribe to the EFF mailing list (email: user@example.com). IMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/example.com/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/example.com/fullchain.pem Your certificate will expire on 2022-01-01. To obtain a new or tweaked version of this certificate in the future, simply run certbot again with the \u0026#34;certonly\u0026#34; option. To non-interactively renew *all* of your certificates, run \u0026#34;certbot renew\u0026#34; - If you like Certbot, please consider supporting our work by: Donating to ISRG / Let\u0026#39;s Encrypt: https://letsencrypt.org/donate Donating to EFF: https://eff.org/donate-le Your certificates are downloaded, installed, and loaded. Try reloading your website using https:// this time and notice your browser\u0026rsquo;s security indicator. Now it should indicate that the site is properly secured.\nInstall R and Packages as sudo First we install R, as we usually do in Debian\n1 2 sudo apt install r-base sudo apt install libcurl4-gnutls-dev libxml2-dev libssl-dev The second line installs some libraries that are recommended or, in some cases necessary by some R packages. In case that you are installing on a cloud service these might already be installed, while a minimal Debian installation might not. You can run the command either way and apt will inform you if they\u0026rsquo;re already installed.\nAs for the rest of the packages, we have two options, considering that we want to install as sudo.\nInstall directly from the terminal. As an example\n1 sudo su - -c \u0026#34;R -e \\\u0026#34;install.packages(\u0026#39;shiny\u0026#39;, repos=\u0026#39;http://cran.rstudio.com/\u0026#39;)\\\u0026#34;\u0026#34; Install from within R. Open R as sudo using sudo -i R. Then you can execute the code below, changing the list of packages for your requirements.\n1 2 3 4 5 6 7 8 9 10 11 12 my_packages = c(\u0026#34;RJSONIO\u0026#34;, \u0026#34;maps\u0026#34;, \u0026#34;stringr\u0026#34;, \u0026#34;rhandsontable\u0026#34;, \u0026#34;shinyjs\u0026#34;) install_if_missing = function(p) { if (p %in% rownames(installed.packages()) == FALSE) { install.packages(p, dependencies = TRUE) } else { cat(paste(\u0026#34;Skipping already installed package:\u0026#34;, p, \u0026#34;\\n\u0026#34;)) } } sapply(my_packages, install_if_missing) I specially recommend you to install rmarkdown and quarto packages, as they work very well with Shiny server.\nInstall Shiny server Firs of all go to Go to the download page for the latest version. Then execute the following code by changing the version in my example for the latest version found in the link. Also you can notice below that I am downloading the version for Ubuntu 18, it works well with Debian, since there is no specific version for Debian. Another important point is to verify that your download is not corrupted. The sha256sum command should return a key that must match with the one shown in the website.\n1 2 3 4 5 6 7 8 sudo apt-get install gdebi-core wget https://download3.rstudio.org/ubuntu-18.04/x86_64/shiny-server-1.5.20.1002-amd64.deb # verify integrity sha256sum shiny-server-1.5.20.1002-amd64.deb # install using gdebi sudo gdebi shiny-server-1.5.20.1002-amd64.deb Finally, if all is correct, install using gdebi.\nConfigure Nginx We need to replace the port numbers with the right locations in the nginx config file. Navigate to the /etc/nginx/sites-enabled/ and open the file default. As before, you can do it directly in the console using nano or emacs.\n1 2 # using nano sudo nano /etc/nginx/sites-enabled/default Once you have the file open, search for the line that reads server { at the begining, and place above that line the following:\nmap $http_upgrade $connection_upgrade { default upgrade; '' close; } Then look for the line that reads server_name _; or, if you followed the steps above to add SSL certificate, it should now have your server name instead of _. Whichever it is, place right after it the following block:\nlocation /shiny/ { proxy_pass http://127.0.0.1:3838/; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026quot;upgrade\u0026quot;; rewrite ^(/shiny/[^/]+)$ $1/ permanent; } Now we need to test it with sudo nginx -t in the terminal. If the messages shows no error, then activate the changes by restarting Nginx with sudo systemctl restart nginx.\nAt this point you should be able to see the Shiny Welcome page in your ip address or your domain ending in /shiny/. In my case it is https://apps.rwhitedwarf.com/shiny/ .\nAdd your own apps Now you can start adding shiny apps in the path /srv/shiny-server/. If you navigate there you can see that there is already a folder called sample-apps. Inside it you have the folder hello which is a sample shiny app. If you navigate to your address /shiny/sample-apps/hello you should see that app deployed (https://apps.rwhitedwarf.com/shiny/sample-apps/hello/ ).\nIf you installed rmarkdown you should also see a folder named rmd within the sample-apps, if you navigate to /sample-apps/rmd you should be able to see the Rmd file deployed. When you want to add Rmd files make sure to have one index.Rmd file and add runtime: shiny to the configuration section. It works the same for quarto and Qmd files if you installed it. Now you can deploy not only shiny apps but also Rmarkdown and quarto.\n","pubDate":"2023-01-22","title":"Deploy your own Shiny app server with debian"},{"link":"http://example.org/posts/2022/use_emacs_for_r/","plain":"Easy Emacs To start using R, or almost anything else in Emacs you basically need to know 3 things: 1) How to move in Emacs, meaning understanding what is what and learning a few key commands; 2) What is the configuration file and how to use it and 3) How to use packages to extend Emacs. In the first half of this post I will try to show how easy it is to cover these 3 points even for people who are inexperienced in programming. If you don\u0026rsquo;t believe me I invite you to read just the first paragraph of the next section to give you an idea of how easy it really is. During the second half I will show how I\u0026rsquo;m using R in Emacs to give you a starting point of a fully functional environment for R, and will conclude with some topics that can be further explored.\nWhy did I chose Emacs as a researcher in the academia? I started my professional life as a researcher in ecology-related topics. During my master studies I improved my knowledge on statistics considerably and due to that and to the complexity of my research project, I did not want to use a GUI-based software for my statistical analysis. Thus, I started learning R, and believe it or not, I completed my research project for my Thesis by tipping R code directly to the console from my handwritten notes. When I started my PhD I thought that it would be easier to just write the code I need in electronic format and copy-paste it to the R console. And with that idea in mind and the help of the internet, I discovered the text editors and Emacs, and a whole new universe opened up to me. I know that many in my position would be ashamed of sharing such a story but I simply want to exemplify how easy it is to start using Emacs, contrary to the popular belief. I went from having no idea of what a text editor is, to setting up and using Emacs with R, with no intermediate steps.\nEmacs is a wonderful text editor that can easily be extended to do many things. You can have tools to help in writing your code such as different types of indentation, syntax highlighter, git utilities, project management, code maps, web browser, even to play games. Emacs provides by default a lot of functionalities to move easily through the text files, including keybindings to go to the end and beginning of buffer, function or paragraph, parentheses matching, text search, exploration and replacement, syntax and spelling checks. You can create markers to move quickly to particular files, window configurations or to store text and numbers. Some consider Emacs almost as an OS because you can also do things like create and delete files, version control, internet browser, and more.\nThe reason why I stayed with Emacs as a researcher in the academia was mainly due to org-mode. It is an Emacs major mode that helped me to organize my research and still today it helps me to organize my job. You can think if it as the Emacs version of Markdown, with the possibility to organize to-do lists, tag notes and sections, fully organize an agenda (tracking tasks, set deadlines, schedule items, etc.). You can add chunks of code from almost any language and, with the help of a couple more libraries, you can run the code within the org file itself. Github and other git servers have integrated tools to view org files as html, but there are libraries to convert them also to pdf, libreoffice, create presentations and more.\nAnother important point that made me fall in love with Emacs was the fact that, if I managed to keep most of my research files as text I could do it all from Emacs, instead of using different apps for different tasks. And so I did: I was writing my papers in LaTeX and organizing my bibliography with bibtex; I was saving data as CSV which Emacs can manage very well; the graphics were more of an issue but, since I used R to create most of them, I simply needed to save the right script for the right plot. And all this was organized in org-mode with links to this or that file according to the project, section, tag, etc. And the reason why I wanted to do this was not even for organization purposes, but rather because, as text, I could track all my changes using Git, which ended up being a huge support for my PhD work: I could revert changes if I had mistakes or explore old commits, and backup all of that easily. So, at the end, while R had been the reason why I decided to explore Emacs, it was in fact the combo Emacs + org-mode + git which improved my organization and productivity potentially during my research life. And I would like to share this tools with as many people as possible.\nThus, I decided to create this post, to give you an idea of how easily you can start using Emacs for R coding. If you enjoy it and you\u0026rsquo;d like me to create more content about some of the tools briefly described here, make sure to leave me a comment and I\u0026rsquo;ll take care of it. I include a general list of the tools I use regularly in Emacs at the end, you can have a look there.\nQuick start Although Emacs is extremely customizable, it is true that it requires some coding skills and knowledge of the not so popular programming language called Emacs Lisp. You would probably have also read that Emacs has a very steep learning curve, which is also true. This two conditions usually scare people away from learning Emacs. In this section I will demonstrate that you don\u0026rsquo;t need to know Emacs Lisp (or programming at all) and that with very little knowledge of Emacs you can have a ready-to-use super-powerful R editor.\nThis chapter is a brief overview of the rest of the post meant as a quick start to get Emacs up and working with R in just as few as 10 steps. The rest of the post will simply go deeper into each of the steps.\nMake sure that you have installed both, Emacs and R in your computer.\nOpen Emacs and press the keys Ctr + x, release and press Ctr + f (in Emacs notation, this combination of keys is expressed as \u0026ldquo;C-x C-f\u0026rdquo;). Focus on the mini buffer, it is the line positioned at the bottom of your window. It is waiting for you to type something. If there is some path to a folder already in that area delete it first and then type ~/.emacs and enter. It should open a new empty window.\nThis is your configuration file. Paste the following code in your new window 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 (require \u0026#39;package) (add-to-list \u0026#39;package-archives \u0026#39;(\u0026#34;melpa\u0026#34; . \u0026#34;https://melpa.org/packages/\u0026#34;)) (unless (package-installed-p \u0026#39;use-package) (package-refresh-contents) (package-install \u0026#39;use-package)) (setq use-package-always-ensure t) (use-package ess) (use-package company :config (add-hook \u0026#39;after-init-hook \u0026#39;global-company-mode)) (setq company-selection-wrap-around t company-tooltip-align-annotations t company-idle-delay 0.45 company-minimum-prefix-length 3 company-tooltip-limit 10) This configuration assumes that you have installed R with all the defaults. If you have installed R in a directory of your choice, add the following line at the end of the configuration file, changing the path of my example for the path were you have installed R.\n1 (setq inferior-ess-r-program \u0026#34;C:/Users/Manuel/path_where_R_is/R-4.2.1/bin/R.exe\u0026#34;) Type C-x C-s (meaning, Ctr + x, release, Ctr + s). This will save the file.\nType now Alt + x (in Mac command key instead of Alt or, if it does not work, the option key instead), this is the key Meta, represented in Emacs by M-x. At this point you want to focus again on your mini buffer, the line at the bottom of the screen.\nType there package-install enter and then type use-package, enter. If some text appears at the bottom of your .emacs file don\u0026rsquo;t worry, it is intended this way.\nFocus on the mini buffer in case it prompts something. If it asks you if you want to install the package type y and enter. If it tells you that it cannot find the package or it does not exist, close Emacs, open it again and repeat steps 5 and 6. It should show a message informing that it has been installed. In my case it shows the following line in the minibuffer:\nDone (Total of 9 files compiled, 4 skipped) Now close Emacs and open it again. This time it should take longer to load. Be patient, Emacs is loading installing and loading more packages for you.\nType again C-x C-f and type test.R, enter. You can change the path before the file if you wish (i.e. ~/Code/test.R).\nA new empty area should appear. Type there one line of R code. When you are done, while keeping the cursor in the line where your code is, press C-c C-j, this sends a line to R. A new area will open, showing the R console and the results of the code you just sent. If nothing happens focus on the minibuffer, it might ask you where to start your R session; you can just press enter or provide a new location. Then you can continue typing R code and use the same combination of keys to run a line, you can use C-c C-p to run a paragraph, C-c C-f to send a function and C-c C-b the send the whole buffer (which here basically means the whole file) or simply Control + enter (C-return) to send any of the mentioned regions. And as you already know, you can save the file by pressing C-x C-s.\nIf everything went well now you should have a simple Emacs configuration to start coding in R. Congratulations!.\nGetting started with Emacs Installation and first steps Both, R and Emacs are extremely easy to install, therefore I will not go into the details for it. Basically in any Linux distribution you can just use your package manager for it, in windows just download and run the official executable files and for Mac you can also download the binaries or use alternative package methods like homebrew (also applicable for Linux). For R go to (https://www.r-project.org/) and for Emacs to (https://www.gnu.org/software/emacs/).\nOnce you have installed Emacs you can run it and you will have the welcome screen, together with some toolbars and list of menus. At this point you could basically use Emacs like any other text editor: you can open files, edit them and save them by using all the menus, icons and your mouse. However, the real power of Emacs rest in its keybindings. To get started I recommend to click on the link Emacs Tutorial of the welcome screen, it will guide you through the basics. After the tutorial you will feel more comfortable finding your way around Emacs and the rest of this post will be easier to follow.\nControl, Meta and the minibuffer, moving in Emacs When you are working with text most of the time (as it is the case of R code) the use of the mouse can reduce productivity by searching with your eyes the exact places you want to mark, going all the way to the menu to save or open a file, finding when a parentheses opens and closes, and so on. The idea of the keybindings is to increase productivity by staying in the text at the level of the keyboard most of the time, since this is what we actually do when we write code.\nAt the beginning it can be complicated to memorize so many keybindings. I\u0026rsquo;d recommend to try to remember the most basic ones to move along the text, save files, close Emacs and split the screen as you need to. The rest can be easily achieved through the mouse icons and menus. When I started using Emacs I was having a piece of paper with the most useful keybindings and, as my fingers started remembering by themselves I was deleting those and adding new ones. Today I can assure you that my productivity to write R code is much better than it ever was with any other text editor.\nI will not go through the details of which keybindings do what since it is all in the self contained tutorial, however there are some key points to learn the keybindings. One is the knowledge of the so called \u0026ldquo;Emacs Notation\u0026rdquo;. Whenever you search either in Emacs documentation or some other sources to use Emacs, how to perform certain actions, you will find things like C-M-a. The capital C is short for the key Control, while capital M is for meta, which in most computers is Alt and in Mac is usually the key Command. Thus, C-M-a would mean that you have to hold the key Control, the key Meta and the key a. Usually the keys Control and Meta are used in combination with other keys and thus, the letters C and M are used at the beginning of the commands. That would mean that, for example, the combination C-C does not mean Control twice, but rather Control plus capital C. Although this rarely happens (I\u0026rsquo;ve never used such a combination), it is important to be aware because Emacs recognizes difference between upper and lower case.\nAnother important part to know in Emacs is the minibuffer. By default it is positioned at the bottom of the screen and it is used to communicate commands between Emacs and the user. For example, when you save a file the minibuffer will print something like Wrote /path/to/file.R to signal that the file has been saved.\nThe minibuffer is also used to pass commands to Emacs. All the keybindings are bind to a command, although not every command is bind to a key. To pass a command to Emacs you can use the keys M-x. As an example you can try to use M-x and you will see that the minibuffer has changed and now is ready to receive your input. Type there help-for-help and a new menu will appear, showing you the options for help and the instructions to use it. For example, type b to display all keybindings. The command help-for-help is bind to the keys C-h ? therefore, if you would type this combination instead you would have the same response.\nEmacs uses intuitive key bindings and thus, the combination C-h is designed for help. For example, the combination C-h b will show the help for the Bindings, C-h t help with Tutorial, C-h f help for a Function (you have to type in the function), etc. C-x executes high levels functions such as save file C-x C-s or close Emacs with C-x C-c.\nYou can take some time to familiarize yourself with some of the keybindings and later you will see how it pays off when writing and executing R code. The best way to get familiar with the main ones is by following the tutorial included in Emacs, you have the Link in the welcome page, in the Help menu or simply type C-h t.\nThe configuration file The second part of the power of Emacs is its customization. The first aspect for its customization is the init file, also known as dot Emacs. According to its documentation:\nWhen Emacs is started, it normally tries to load a Lisp program from an initialization file, or init file for short. This file, if it exists, specifies how to initialize Emacs for you. Traditionally, file ~/.emacs is used as the init file, although Emacs also looks at ~/.emacs.el, ~/.emacs.d/init.el, ~/.config/emacs/init.el, or other locations. See How Emacs Finds Your Init File.\nThis means that you have several options to tell Emacs how to start. If you are not familiar with Unix style, ~/ is the home directory. That means that you can have your configuration file in your home directory called .emacs or .emacs.el, or you can have it inside a configuration folder ~/.emacs.d/ or ~/.config/emacs/ with the name init.el (or some other options, see the link in the quote).\nTo keep consistency and facility, we will keep the same approach that we used in the quick guide above and use the file dot emacs.\nOpen Emacs and press the keys Ctr + x, release and press Ctr + f (in Emacs notation, this combination of keys is expressed as \u0026ldquo;C-x C-f\u0026rdquo;). Focus on the mini buffer, it is the line positioned at the bottom of your window. It is waiting for you to type something. If there is some path to a folder already in that area delete it first and then type ~/.emacs and enter. It should open a new empty window. If you followed step 2 from within Emacs you should have now an empty screen where you can start typing Elisp code to tell Emacs how to start. After a new installation the file still does not exists (although you might already have created it if you followed the quick start). With the command C-x C-f we can create it. Make sure that it is stored in the home folder ~/ and not somewhere else. To demonstrate the point, type the following line anywhere in your .emacs file: (setq inhibit-startup-screen t), that tells Emacs to inhibit the startup screen. Now save it with C-x C-s, close Emacs and open it again and now the startup screen showing you the tutorial should not be there anymore. If you still want to see the welcome screen at startup you can simply delete that line and the startup screen will be back (C-x C-f type ~/.emacs, delete the line and save).\nHere are just a couple of lines that are useful to add to your dot Emacs file for writing R code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ;; enable column numbers (setq column-number-mode t) (add-hook \u0026#39;prog-mode-hook \u0026#39;display-line-numbers-mode) ;; Highlights the matching parentheses (show-paren-mode 1) ;; Using arrow for moving through buffers (global-set-key (kbd \u0026#34;C-x \u0026lt;up\u0026gt;\u0026#34;) \u0026#39;windmove-up) (global-set-key (kbd \u0026#34;C-x \u0026lt;down\u0026gt;\u0026#34;) \u0026#39;windmove-down) (global-set-key (kbd \u0026#34;C-x \u0026lt;left\u0026gt;\u0026#34;) \u0026#39;windmove-left) (global-set-key (kbd \u0026#34;C-x \u0026lt;right\u0026gt;\u0026#34;) \u0026#39;windmove-right) ;; Starting file (setq initial-buffer-choice (lambda () (if (buffer-file-name) (current-buffer) (find-file \u0026#34;~/Path/to_your_file/a_starting_file.R\u0026#34;)))) The first part will simply enable column numbers when writing code, for some reason Emacs does not do it by default. Next we are activating the show-paren-mode which highlights the matching parentheses, a useful function when writing long functions. The third paragraph will allow you to move between buffers using C-x and the arrows. For example, you can split buffer horizontally using C-x 2 and then move to the lower buffer using C-x and down arrow, or back to the upper with the upper arrow C-x . The last part can set a custom starting file, meaning each time you open Emacs this will be the file that will open by default, but if you open a different file using Emacs this starting file won\u0026rsquo;t show up.\nExtending Emacs: packages Emacs can be fully customized in the sense that you can write Elisp code to get Emacs do what you want. Luckily, you don\u0026rsquo;t need to know Elisp to take advantage of it. Like in R, there are several packages that extend the basic Emacs to do more than it was originally designed to. In the quick start section steps 3 to 7 we did exactly that in 2 different ways. Let\u0026rsquo;s take a look at each option and detail to install packages.\nELPA and MELPA ELPA is the Emacs Lisp Package Archive, written originally by TomTromey. It is included in GnuEmacs, starting with version 24. package.el is the package manager library for ELPA.\n“Our goal is to make it simple to install, use, and upgrade Emacs Lisp packages. We supply package.el a simple package manager for Emacs, and a repository of pre-packed Emacs Lisp code.”\nSee InstallingPackages for basic usage information.\nTo see the ELPA packages available you can execute the command list-packages (remember, by using M-x). However, sometimes this are not the most up to date versions, or some packages are simply not listed in the ELPA repositories but rather in MELPA only.\nMELPA is an ELPA-compatible package repository that contains an enormous number of useful Emacs packages.\nIn contrast to ELPA, Emacs is not configured by default to install packages from MELPA. You will have to configure Emacs to use it.\nYou can think of MELPA to ELPA like Bioconductor is to CRAN. In their own words, this is what MELPA is intended for:\nUp-to-date packages built on our servers from upstream source\nInstallable in any Emacs with \u0026lsquo;package.el\u0026rsquo; - no local version-control tools needed\nCurated - no obsolete, renamed, forked or randomly hacked packages\nComprehensive - more packages than any other archive\nAutomatic updates - new commits result in new packages\nExtensible - contribute new recipes, and we\u0026rsquo;ll build the packages\nTo configure Emacs to find MELPA packages we simply need two lines of code in our configuration file.\n1 2 (require \u0026#39;package) (add-to-list \u0026#39;package-archives \u0026#39;(\u0026#34;melpa\u0026#34; . \u0026#34;https://melpa.org/packages/\u0026#34;)) Add those lines to your dot emacs file, save it and restart Emacs to take effect. Now, upon calling list-packages you should see an extended list of packages, some of which are tagged as \u0026ldquo;melpa\u0026rdquo; in the section \u0026ldquo;Archive\u0026rdquo; of the list.\nlist-packages and install-package From the last section you already know how to call list-packages and if you followed the quick start, you also know how to use the command install-package. Basically, to install a package you could call the command install-package, RET and type the exact name of the package, which can be found in the list of the packages.\nBut there is more. According to the Emacs Documentation:\nThe command M-x list-packages brings up the package menu. This is a buffer listing all the packages that Emacs knows about, one on each line, with the following information:\nThe package name (e.g., ‘auctex’). The package’s version number (e.g., ‘11.86’). The package’s status—normally one of ‘available’ (can be downloaded from the package archive), ‘installed’, or ‘built-in’ (included in Emacs by default). See Package Statuses. Which package archive this package is from, if you have more than one package archive enabled. A short description of the package.\nEach area in Emacs is called a buffer and depending what the buffer is running it will be controlled by its own rules. As you saw in the quick start, we can send a line of R code to the terminal by typing C-c C-j, but such key combination won\u0026rsquo;t work the same if we are not inside an R file. In the same way, the buffer listing the packages has its own keybindings. You can find all the details in the link above, but here are the most useful ones:\nMove along the buffer using the arrow keys. Move one page down using C-v and one page up with M-v. Search for text using C-s. Press i to mark a package for installation. Press u to unmark a package. Press x to execute marked actions. Or simply use the menu \u0026ldquo;Package\u0026rdquo; To exit you can type q or you can kill this or any buffer by typing C-x k and then RET.\nuse-package Another way to install packages is by using the package use-package which in short is a package manager.\nThe use-package macro allows you to isolate package configuration in your .emacs file in a way that is both performance-oriented and, well, tidy. I created it because I have over 80 packages that I use in Emacs, and things were getting difficult to manage. Yet with this utility my total load time is around 2 seconds, with no loss of functionality!\nLet\u0026rsquo;s use the example from the quick start, step 3:\n1 2 3 4 5 6 7 (unless (package-installed-p \u0026#39;use-package) (package-refresh-contents) (package-install \u0026#39;use-package)) (setq use-package-always-ensure t) (use-package ess) The first part makes sure that the package use-package is installed and to refresh the list of packages based on use-package own rules. The second part ensures that the package will be installed if it was not yet installed. In other words, it makes the installation of the packages automatic so, you don\u0026rsquo;t have to use install-package command of the list-packages menu. Finally (use-package ess) loads the package ess to Emacs, which is the package responsible for running R. Final remarks about Emacs configuration The detail usage of use-package is quite complex, especially for a new Emacs user and it is not covered in this post. Likewise, a more detailed configuration of the init file (.emacs) and the customization of Emacs and the packages through it can take an entire manual. If you are really interested you can start by following the links provided so far. Otherwise I would recommend staying with the basis presented here, getting familiar with Emacs and slowly getting deeper into particular topics. The info presented here is just the very basics to get started with a simple yet powerful IDE for R.\nOne important point to know though is that usually, after installing a package, it has to be loaded through the init file so that Emacs can use it. Usually you can find detailed info in the documentation and/or website of the particular package on how to load it and how to configure it. The general rule is to load it using the base Emacs function require (i.e., (require 'ess)) or alternatively with use-package (i.e., (use-package ess)).\nESS to speak with R As it was already mentioned, ESS is the Emacs package used for R code. It stands for \u0026ldquo;Emacs Speaks Statistics\u0026rdquo; and it can run not only R code but other statistical analysis programs including Julia.\nEmacs Speaks Statistics (ESS) is an add-on package for GNU Emacs. It is designed to support editing of scripts and interaction with various statistical analysis programs such as R, S-Plus, SAS, Stata and OpenBUGS/JAGS. Although all users of these statistical analysis programs are welcome to apply ESS, advanced users or professionals who regularly work with text-based statistical analysis scripts, with various statistical languages/programs, or with different operating systems might benefit from it the most.\nThe rationale for developing ESS is that most statistical analysis systems provide a more or less sophisticated graphical user interface (GUI). However, their full power is only available using their scripting language. Furthermore, complex statistical analysis projects require a high degree of automation and documentation which can only be handled by creating statistical analysis scripts. Unfortunately, many statistics packages provide only weak text editor functionality and show major differences between them. Without a unified text editor user interface additional effort is required from the user to cope with limited functionality and with text editor differences.\nESS is a very powerful and specialized software on its own, its documentation includes 16 detailed topics for its usage. Its use with Emacs can be compared to R Studio alone, although there are significant differences, the ESS team have also work a lot lately on having enough similarities to make R Studio users feel comfortable switching to Emacs.\nI use it particularly for R, it helps me to write R code including syntax highlight and indentation, to send R code to the console, to debug R code and more.\nHow to use R in ESS As we already mentioned, Emacs can be fully configured to our needs and wishes. If you clicked in the links above, you can also see that ESS documentation is quite long and complex. The present post is merely an introduction to its possibilities. Here is a table with the most commonly used key bindings and commands used in ESS.\nKeys Effect C-RET Sends region, line or step to the console C-c C-j Sends line to the console C-c C-p Sends paragraph to the console C-c C-b Sends buffer (whole file) to the console C-c C-f Sends buffer to the console M-x ess-indent-exp Indents expression To use them make sure to have installed and loaded ESS in your Emacs. Then you can simply create an R file, start typing code and run it.\nYou can also use the menu \u0026ldquo;ESS\u0026rdquo; fro within the R buffer to explore more keybindings and commands. One useful section is the \u0026ldquo;Font Lock\u0026rdquo; which defines the Syntax Highlighting for R. I\u0026rsquo;d recommend to have open a relatively long or complex R script and mark/unmark fields to see what happens. But basically, the fields marked in the menu \u0026ldquo;Font Lock\u0026rdquo; are the fields that will be highlighted by Emacs.\nThe ESS debugging tool is also useful and powerful. You can simply type in you R console debug(function) and then run the function called inside debug or a function containing it and Emacs will run step by step and side by side the file each time you type RET in the console. Whenever you don\u0026rsquo;t type RET you can do all sort of stuff locally such as print the state of an argument or even change its value.\nCompany Among all the libraries and Emacs functionalities that can help us writing R code, I think that Company deserves a special mention. It is an auto completion tool that is easy to set up for ESS and intuitive to use. If you followed the quick start you should already have it installed and ready to use.\n1 2 3 4 5 6 7 8 9 (use-package company :config (add-hook \u0026#39;after-init-hook \u0026#39;global-company-mode)) (setq company-selection-wrap-around t company-tooltip-align-annotations t company-idle-delay 0.45 company-minimum-prefix-length 3 company-tooltip-limit 10) The first paragraph is calling the library and creating a hook to activate it globally. You could as well change the hook to have it active only when ESS is running, but in my experience it is quite useful to have it active globally.\nThe second paragraph customize some of its functionality, for example company-idle-delay defines the delay time to show the autocomplete menu, in seconds. You can fin more info about it in the official documentation or simply by typing C-h v RET and the name of the variable (i.e., C-h v RET company-idle-delay).\nIf you followed the quick start you could probably had already noticed that you get code suggestions while typing R code. If not, I recommend you to give it a try. The variable company-minimum-prefix-length is set to 3, which means that you need to type at least 3 characters and wait 0.45 seconds for the menu to pop-up.\nWhat next? - Explore Emacs and its libraries As mentioned before, Emacs has many functionalities that can help boosting your productivity and writing code more easily. Here are some I personally use:\nEmacs Functionalities Purpose org-mode Organization functionality in Emacs using plain text paren-mode Commands for editing with parentheses vc-mode Version Conrol in Emacs csv-mode Visualize and edit CSV files bookmarks and registers Save position in a file, windows configuration or text in keystrokes If you had a look at list-packages you would have noticed that the number of libraries available is huge. Here is a very conservative list of libraries that are particularly useful for working with R, or code in general.\nPackage Use polymode Helps for markdown documents poly-R Polymode for R poly-markdown Polymode for markdown Magit A more user friendly Version control with great visualizations Flyspell Syntax check. Uses lintr for R Swiper The link includes Ivy for auto completion, Counsel for common Emacs commands and Swiper for search Yasnippet Templates system for Emacs Emacs is also an excellent tool for different kinds of professional writting, during my PhD studies I was using AUCTeX for writing papers in LaTeX, supported by bibtex-mode to organize the bibliography and helm-bibtex for queries. Emacs can also run web browsers, games and functionalities for email, among others. I personally don\u0026rsquo;t use these much, but it shows the great possibilities of Emacs.\nIf you would like me to cover some of them in more detail leave a comment and I\u0026rsquo;ll try my best to share my knowledge to help.\n","pubDate":"2022-12-29","title":"Using Emacs for R"},{"link":"http://example.org/es/posts/2022/eda_inegi_datos/","plain":"Introducción El análisis exploratorio de datos (EDA en inglés, \u0026ldquo;Exploratory Data Analysis\u0026rdquo;) es una de las herramientas más útiles en varias áreas de análisis de datos. El concepto de EDA ha sido utilizado popularmente en los últimos años para referirse a los procesos de exploración primaria de un grupo de datos. Por lo tanto, no existe una fórmula o receta para realizar una exploración, sea general o exhaustiva. Una exploración correcta depende de las habilidades del analista tanto para entender los datos como para utilizar las herramientas adecuadas. Este post no pretende ser una explicación detallada de como realizar un EDA, más bien intento compartir una de mis experiencias haciendo haciendo ayuda de la programación funcional.\nLa información que presento aquí son los resultados del primer EDA que realicé cuando decidí cambiar mi carrera hacía el análisis de datos. Es una serie de datos obtenidos del Instituto Nacional de Estadística, Geografía e Informática de México, contiene información sobre la cantidad, expresada en miles de dolares, de las exportaciones por año de cada estado. Me pareció un ejemplo adecuado ya que yo no tengo mucho conocimiento en economía o exportación, por lo tanto este ejemplo no contiene ningún análisis numérico detallado o complicado, si no mas bien una exploración general de los datos obtenidos. Los datos han sido tomados de la pagina oficial de INEGI en formato de excel. El INEGI es una de las bases de datos más importantes de México, su web contiene bases de datos públicas en temas de geografía y estadística. Si estas buscando datos para practicar tus habilidades en R o como analista de datos te recomiendo darle un vistazo. Aquí presento una versión de los datos que yo mismo he arreglado para su uso en R, los cuales pueden ser descargados en formato CSV desde mi repositorio de github INEGI-export.\nEl proceso de EDA resulta útil no sólo para profesionales analistas de datos, si no en un amplio rango de actividades para conocer y entender los datos que se manejan. En muchos casos los análisis de datos incluyen complicadas fórmula matemáticas en grandes series numéricas que no son entendidas, simplemente procesadas y reducidas a pequeños números que representan algo, como medias, rangos, estadísticos, etc. El análisis exploratorio de datos nos permite entender un poco mas que significan esos número, de donde vienen, y que se puede extraer de ellos. Los datos son siempre generados en base a la información, el EDA es una herramienta para entender esa información.\nAnálisis exploratorio (Exploratory Data Analysis, EDA) Vamos a comenzar llamando directamente las librerías o módulos (en R library) que necesitamos para hacer nuestro análisis, y leyendo los archivos CSV en la memoria de R. Esto puede ser realizado conforme se va utilizando, sin embargo es recomendable importar todas las librerías y archivos al inicio de nuestro código o script, para evitar errores o problemas de organización.\n1 2 3 4 5 6 library(tidyverse) library(cowplot) path.to.files \u0026lt;- \u0026#34;https://raw.githubusercontent.com/teotenn/INEGI-export/master/\u0026#34; export.rows \u0026lt;- read_csv(paste0(path.to.files, \u0026#34;exportations_activity_rows.csv\u0026#34;)) export.cols \u0026lt;- read_csv(paste0(path.to.files, \u0026#34;exportations_activity_cols.csv\u0026#34;)) Las librerías son básicamente programas escritos en R que contienen el código necesario para realizar, o más bien llamar ciertas funciones especificas de cada librería. En español son popularmente conocidas como paquetes o módulos. En este caso vamos a utilizar tidyverse y cowplot. La librería cowplot nos va a ayudar a colocar varias gráficas de forma fácil y ordenada en un sólo espacio.\nEn cuanto a la librería tidyverse ofrece enormes ventajas (aunque también pocas desventajas) para el análisis de datos. Al llamar esta librería incluye una serie de librerías que contienen diferentes tipos de herramientas para facilitar y organizar el análisis de datos. En este post vamos a utilizar principalmente:\nggplot2 Que facilita la creación de gráficas con el sistema de capas (The Language of Graphics escrito por Leland Wilkinson, 2000) dplyr que nos ayuda a mandar resultados de un proceso al siguiente utilizando los famosos %\u0026gt;% tibble que facilita la manipulación de tablas, transformando los tradicionales data.frame de R a un formato mas amigable visualmente. Si lo deseas, también podrías llamar estas tres librerías de una por una en lugar de llamar todo el tidyverse de principio. El resultado será el mismo.\nEntre otras desventajas de estos paquetes es que no funcionan muy bien cuando la cantidad de datos es muy grande (miles de millones de filas), en cuyo caso se recomiendan otras herramientas como Data Table que funciona de forma un poco mas similar al tradicional data.frame de R. Más información sobre tidyverse puede ser encontrada en su página oficial, (https://www.tidyverse.org/) o en el e-book R for data science escrito por uno de los creadores de la librería. Un buen libro en español es R para profesionales de los datos.\nOrganizando los datos Lo primero que debemos hacer es organizar los datos a un formato que sea mas amigable con R, y también con nuestras necesidades de análisis. Como ya he mencionado antes, yo manipulé los datos con anterioridad para tenerlos en un formato amigable con R. Por otro lado, algunas variables presentan nombres demasiado largos, por lo que he decididos reducirlos un poco para facilitar mi trabajo.\nEste análisis lo realicé primordialmente en inglés, por lo tanto he decidido mantener el código en inglés por facilidad para mi por un lado, pero también por el beneficio de ser mas amigable con R en general, y de generar nombres mas cortos. Así pues, algunos valores se mantendrán en español y otros han sido traducidos para la manipulación de los datos.\nEl siguiente bloque contiene la traducción de las actividades de exportación, para generar nombres en inglés mas accesibles. Lo primero fue guardar los nombres en español en un vector, para utilizarlos más tarde en la traducción; también generamos un vector del mismo tamaño, con su equivalente en Inglés (en exactamente el mismo orden).\n1 2 ## Nombres en español en un vector colnames(export.cols) \u0026gt; [1] \u0026#34;state\u0026#34; \u0026gt; [2] \u0026#34;year\u0026#34; \u0026gt; [3] \u0026#34;Exportaciones totales\u0026#34; \u0026gt; [4] \u0026#34;Industria alimentaria\u0026#34; \u0026gt; [5] \u0026#34;Industria de las bebidas y el tabaco\u0026#34; \u0026gt; [6] \u0026#34;Fabricación de insumos textiles y acabado de textiles\u0026#34; \u0026gt; [7] \u0026#34;Fabricación de productos textiles, excepto prendas de vestir\u0026#34; \u0026gt; [8] \u0026#34;Fabricación de prendas de vestir\u0026#34; \u0026gt; [9] \u0026#34;Industria del papel\u0026#34; \u0026gt; [10] \u0026#34;Industria química\u0026#34; \u0026gt; [11] \u0026#34;Industria del plástico y del hule\u0026#34; \u0026gt; [12] \u0026#34;Fabricación de productos a base de minerales no metálicos\u0026#34; \u0026gt; [13] \u0026#34;Industrias metálicas básicas\u0026#34; \u0026gt; [14] \u0026#34;Fabricación de productos metálicos\u0026#34; \u0026gt; [15] \u0026#34;Fabricación de maquinaria y equipo\u0026#34; \u0026gt; [16] \u0026#34;Fabricación de equipo de computación, comunicación, medición y de otros equipos, componentes y accesorios electrónicos\u0026#34; \u0026gt; [17] \u0026#34;Fabricación de equipo de transporte\u0026#34; \u0026gt; [18] \u0026#34;Fabricación de muebles, colchones y persianas\u0026#34; \u0026gt; [19] \u0026#34;Otras industrias manufactureras\u0026#34; \u0026gt; [20] \u0026#34;Subsectores no especificados\u0026#34; \u0026gt; [21] \u0026#34;Minería de minerales metálicos y no metálicos, excepto petróleo y gas\u0026#34; \u0026gt; [22] \u0026#34;Curtido y acabado de cuero y piel, y fabricación de productos de cuero, piel y materiales sucedáneos\u0026#34; \u0026gt; [23] \u0026#34;Industria de la madera\u0026#34; \u0026gt; [24] \u0026#34;Impresión e industrias conexas\u0026#34; \u0026gt; [25] \u0026#34;Fabricación de accesorios, aparatos eléctricos y equipo de generación de energía eléctrica\u0026#34; \u0026gt; [26] \u0026#34;Extracción de petróleo y gas\u0026#34; \u0026gt; [27] \u0026#34;Fabricación de productos derivados del petróleo y del carbón\u0026#34; 1 2 3 4 5 6 7 8 9 10 11 12 categorias \u0026lt;- colnames(export.cols)[3:27] ## Equivalentes en inglés activities.en \u0026lt;- c(\u0026#34;Total\u0026#34;, \u0026#34;Food\u0026#34;, \u0026#34;Drinks and tobacco\u0026#34;, \u0026#34;Textiles\u0026#34;, \u0026#34;Textile products\u0026#34;, \u0026#34;Tailoring\u0026#34;, \u0026#34;Paper\u0026#34;, \u0026#34;Chemistry\u0026#34;, \u0026#34;Plastic\u0026#34;, \u0026#34;Minerals based\u0026#34;, \u0026#34;Metal industry\u0026#34;, \u0026#34;Metal products\u0026#34;, \u0026#34;Machinery\u0026#34;, \u0026#34;Electronics\u0026#34;, \u0026#34;Transport equipment\u0026#34;, \u0026#34;Furniture\u0026#34;, \u0026#34;Other manufactures\u0026#34;, \u0026#34;Not specified\u0026#34;, \u0026#34;Mining\u0026#34;, \u0026#34;Leather\u0026#34;, \u0026#34;Wood\u0026#34;, \u0026#34;Printing\u0026#34;, \u0026#34;Electricity\u0026#34;, \u0026#34;Petroleum\u0026#34;, \u0026#34;Petroleum products\u0026#34;) Para cambiar los nombres de las columnas, podemos hacerlo directamente con la función colnames, seleccionando la posición de los valores que queremos cambiar (en este caso, 3 al 27) y colocando ahí los nuevos valores en inglés.\n1 2 ## Cambio de nombres colnames(export.cols)[3:27] \u0026lt;- activities.en Para cambiar los valores en export.rows vamos a necesitar la conversión de las expresiones en español a las mismas en inglés. Aquí he utilizado herramientas de programación basada en funciones (Functional Programming) para generar primero la función principal para traducir translate. Aquí le estoy diciendo a translate exactamente lo que necesito hacer, sin preocuparme si R puede hacerlo o no. Por ejemplo, utilizo la función equivalent, que no existe en R, pero que, basado en mis expectaciones, debe buscar el equivalente en inglés de la frase en español. Así pues, basado en translatete, vamos llenando los huecos, creando la función equivalent que haga exactamente lo que necesito.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 translate \u0026lt;- function(vector.es){ vector.en \u0026lt;- c() for (i in 1:length(vector.es)){ expression.es \u0026lt;- vector.es[i] expression.en \u0026lt;- equivalent(expression.es) ## \u0026#34;equivalent\u0026#34; toma expression.es y regresa el ## equivalente en ingles vector.en \u0026lt;- append(vector.en, expression.en) } vector.en } equivalent \u0026lt;- function(expression.es){ position \u0026lt;- match(expression.es, categorias) expression.en \u0026lt;- activities.en[position] expression.en } ## Probando nuestra nueva función equivalent(\u0026#34;Impresión e industrias conexas\u0026#34;) \u0026gt; [1] \u0026#34;Printing\u0026#34; Como podemos ver, equivalent toma la expresión de nuestro vector en español, y arroja el equivalente que le hemos elegido en inglés.\n1 translate(categorias) \u0026gt; [1] \u0026#34;Total\u0026#34; \u0026#34;Food\u0026#34; \u0026#34;Drinks and tobacco\u0026#34; \u0026gt; [4] \u0026#34;Textiles\u0026#34; \u0026#34;Textile products\u0026#34; \u0026#34;Tailoring\u0026#34; \u0026gt; [7] \u0026#34;Paper\u0026#34; \u0026#34;Chemistry\u0026#34; \u0026#34;Plastic\u0026#34; \u0026gt; [10] \u0026#34;Minerals based\u0026#34; \u0026#34;Metal industry\u0026#34; \u0026#34;Metal products\u0026#34; \u0026gt; [13] \u0026#34;Machinery\u0026#34; \u0026#34;Electronics\u0026#34; \u0026#34;Transport equipment\u0026#34; \u0026gt; [16] \u0026#34;Furniture\u0026#34; \u0026#34;Other manufactures\u0026#34; \u0026#34;Not specified\u0026#34; \u0026gt; [19] \u0026#34;Mining\u0026#34; \u0026#34;Leather\u0026#34; \u0026#34;Wood\u0026#34; \u0026gt; [22] \u0026#34;Printing\u0026#34; \u0026#34;Electricity\u0026#34; \u0026#34;Petroleum\u0026#34; \u0026gt; [25] \u0026#34;Petroleum products\u0026#34; translate toma todos los elementos en el vector, y nos arroja sus equivalentes en inglés. Así pues, para transformar todos los valores en la columna Descripción a su equivalente en inglés he decidido generar una nueva columna, utilizando mi función translate. Esto es muy fácil utilizando mutate\n1 2 (export.rows \u0026lt;- mutate(export.rows, Activity = translate(`Descripción`))) \u0026gt; # A tibble: 5,255 × 6 \u0026gt; Código Descripción state year USD Activity \u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026gt; 1 NA Exportaciones totales Aguascalientes 2007 4389841 Total \u0026gt; 2 NA Exportaciones totales Aguascalientes 2008 4456893 Total \u0026gt; 3 NA Exportaciones totales Aguascalientes 2009 3951108 Total \u0026gt; 4 NA Exportaciones totales Aguascalientes 2010 5647929 Total \u0026gt; 5 NA Exportaciones totales Aguascalientes 2011 6051640 Total \u0026gt; 6 NA Exportaciones totales Aguascalientes 2012 6183782 Total \u0026gt; 7 NA Exportaciones totales Aguascalientes 2013 6726207 Total \u0026gt; 8 NA Exportaciones totales Aguascalientes 2014 8466007 Total \u0026gt; 9 NA Exportaciones totales Aguascalientes 2015 8495445 Total \u0026gt; 10 NA Exportaciones totales Aguascalientes 2016 7870962 Total \u0026gt; # … with 5,245 more rows Exploración visual Ahora para empezar formalmente nuestro EDA, vamos a darle un vistazo a los totales por estado, utilizando nuestra tabla export.cols. Aquí utilizamos los famosos pipe %\u0026gt;% que mandan los resultados de un proceso, al siguiente proceso, por ejemplo, si queremos ver los totales por estado, podemos pedirle a R que haga lo siguiente\ntoma la tabla export.cols %\u0026gt;% agrupa los datos por estado (state) %\u0026gt;% redúcelos a la sumatoria del total, nómbrala total export %\u0026gt;% organiza en forma descendente basado en total export %\u0026gt;% muestra en pantalla todo (n = Inf) La versión en R utilizando el paquete dplyr es:\n1 2 3 4 5 export.cols %\u0026gt;% group_by(state) %\u0026gt;% summarise(`total export` = sum(Total)) %\u0026gt;% arrange(desc(`total export`)) %\u0026gt;% print(n = Inf) \u0026gt; # A tibble: 32 × 2 \u0026gt; state `total export` \u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026gt; 1 Chihuahua 466861927 \u0026gt; 2 Baja California 398935507 \u0026gt; 3 Coahuila de Zaragoza 355638907 \u0026gt; 4 Nuevo León 330267052 \u0026gt; 5 Tamaulipas 284435973 \u0026gt; 6 Campeche 264100465 \u0026gt; 7 Jalisco 213931233 \u0026gt; 8 México 188357470 \u0026gt; 9 Sonora 179661021 \u0026gt; 10 Guanajuato 167191962 \u0026gt; 11 Puebla 127934390 \u0026gt; 12 Tabasco 115797563 \u0026gt; 13 San Luis Potosí 94812554 \u0026gt; 14 Querétaro 88633615 \u0026gt; 15 Aguascalientes 79688240 \u0026gt; 16 Veracruz de Ignacio de la Llave 68556313 \u0026gt; 17 Morelos 37397175 \u0026gt; 18 Zacatecas 34010223 \u0026gt; 19 Ciudad de México 32037661 \u0026gt; 20 Hidalgo 19504479 \u0026gt; 21 Durango 17431796 \u0026gt; 22 Yucatán 14496875 \u0026gt; 23 Michoacán de Ocampo 13411397 \u0026gt; 24 Chiapas 13291536 \u0026gt; 25 Tlaxcala 12987607 \u0026gt; 26 Oaxaca 11023551 \u0026gt; 27 Sinaloa 7825439 \u0026gt; 28 Guerrero 5918438 \u0026gt; 29 Colima 2518028 \u0026gt; 30 Baja California Sur 2303491 \u0026gt; 31 Nayarit 1146388 \u0026gt; 32 Quinta Roo 517674 Gracias a la agrupación de tidyverse, podemos utilizar estas herramientas con muchas otras funciones, entre otras, podemos mandar resultados a un gráfico ggplot\n1 2 3 4 5 6 7 8 9 10 ## Visualización export.cols %\u0026gt;% group_by(state) %\u0026gt;% summarise(`total export` = sum(Total)) %\u0026gt;% ggplot() + geom_bar(aes(y = `total export`, x = reorder(state, `total export`, FUN = abs), fill = `total export`), stat = \u0026#39;identity\u0026#39;) + coord_flip() En el bloque anterior comenzamos con algo similar, y mandamos los resultados a ggplot(), así que ya no es necesario especificar dentro de la función ggplot de donde tomar los datos, por lo tanto esta función se queda vacía. geom_bar genera un gráfico de barras, que de forma típica toma los valores numéricos en el eje Y y los valores categóricos en el eje X. Esto lo especificamos dentro de la función aes (por \u0026ldquo;aestetics\u0026rdquo;, o estética). Otra de las ventajas es que podemos llamar funciones dentro de funciones de gráficos ggplot, por ejemplo, en x utilizo la función reorder para ordenar los resultados por los valores de total export, basado en el valor absoluto (FUN = abs). También, dentro de aes he declarado fill = total export para que llene las barras en base a los valores de total export. Es importante no confundir fill con color, el cual cambia simplemente los contornos de las barras. También es importante especificar fill dentro de aes cuando queremos darle un valor basado en nuestros datos categóricos; o bien, se puede colocar fuera de aes para darle un valor constante. stat = 'identity' y coord_flip() nos ayudan a ordenar las barras, y cambiar el eje de las Y por X, respectivamente.\nAhora podemos hacer lo mismo pero por categoría, usando nuestra otra tabla export.rows\n1 2 3 4 5 6 export.rows %\u0026gt;% filter(Activity != \u0026#34;Total\u0026#34;) %\u0026gt;% group_by(Activity) %\u0026gt;% summarise(Total = sum(USD)) %\u0026gt;% arrange(desc(Total)) %\u0026gt;% print(n = Inf) \u0026gt; # A tibble: 24 × 2 \u0026gt; Activity Total \u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026gt; 1 Transport equipment 1226859499 \u0026gt; 2 Electronics 747959073 \u0026gt; 3 Petroleum 397933968 \u0026gt; 4 Electricity 208582754 \u0026gt; 5 Other manufactures 147915402 \u0026gt; 6 Machinery 136957553 \u0026gt; 7 Chemistry 133570853 \u0026gt; 8 Metal industry 117915995 \u0026gt; 9 Metal products 82889135 \u0026gt; 10 Food 81653585 \u0026gt; 11 Plastic 80126816 \u0026gt; 12 Mining 52953993 \u0026gt; 13 Not specified 51470567 \u0026gt; 14 Tailoring 43913959 \u0026gt; 15 Drinks and tobacco 31059501 \u0026gt; 16 Minerals based 30584505 \u0026gt; 17 Furniture 19883596 \u0026gt; 18 Petroleum products 14565067 \u0026gt; 19 Paper 13876523 \u0026gt; 20 Leather 9863853 \u0026gt; 21 Printing 6915538 \u0026gt; 22 Textiles 6260722 \u0026gt; 23 Textile products 4954252 \u0026gt; 24 Wood 1959275 Para variar un poco y hacerlo mas didáctico, vamos a cambiar algunos detalles, manteniéndolo simple:\nVamos a colocar fill afuera de aes Vamos a cambiar el valor de color para observar la diferencia Vamos a renombrar el eje de las X Vamos a darle un título 1 2 3 4 5 6 7 8 9 10 11 12 13 export.rows %\u0026gt;% filter(Activity != \u0026#34;Total\u0026#34;) %\u0026gt;% group_by(Activity) %\u0026gt;% summarise(Total = sum(USD)) %\u0026gt;% ggplot() + geom_bar(aes(y = Total, x = reorder(Activity, Total, FUN = abs)), fill = \u0026#34;darkblue\u0026#34;, color = \u0026#34;purple\u0026#34;, stat = \u0026#39;identity\u0026#39;) + labs(title = \u0026#34;Exportaciones totales por actividad\u0026#34;, x = \u0026#34;Activity\u0026#34;) + coord_flip() Ahora de manera fácil e intuitiva podemos observar que cambios en el código fueron responsables de que cambios en el gráfico.\nPor último, podemos hacer algo similar con las exportaciones totales por año.\n1 2 3 4 export.cols %\u0026gt;% group_by(year) %\u0026gt;% summarise(`total export` = sum(Total)) %\u0026gt;% print(n = Inf) \u0026gt; # A tibble: 12 × 2 \u0026gt; year `total export` \u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026gt; 1 2007 237809741 \u0026gt; 2 2008 257967777 \u0026gt; 3 2009 198234125 \u0026gt; 4 2010 258504747 \u0026gt; 5 2011 299732519 \u0026gt; 6 2012 320014188 \u0026gt; 7 2013 329562705 \u0026gt; 8 2014 347559680 \u0026gt; 9 2015 337170197 \u0026gt; 10 2016 324901419 \u0026gt; 11 2017 351726063 \u0026gt; 12 2018 387442789 Ahora en lugar de hacer un gráfico de barras, vamos a hacer líneas y puntos. Vamos a cambiar otro detalle: en lugar de especificar aes dentro del geometric, que en este caso tendría que escribirse dos veces exactamente lo mismo, uno dentro de geom_line y otro en geom_point, podemos especificarlo dentro de la función principal del gráfico ggplot(), de esta forma los valores que especifiquemos ahí serán tomados como los valores principales, y no necesitamos darle mas detalles a geom_line ni geom_point.\n1 2 3 4 5 6 7 8 ## Visualization export.rows %\u0026gt;% filter(Activity == \u0026#34;Total\u0026#34;) %\u0026gt;% group_by(year) %\u0026gt;% summarise(Total = sum(USD)) %\u0026gt;% ggplot(aes(x = year, y = Total)) + geom_line() + geom_point() Podemos hacer lo mismo por estado. Aquí, debido a la complejidad de los nombres de algunos estados, he decidido abreviar los nombres de cada estado a sólo 6 letras, usando la función abbreviate\n1 2 3 4 5 6 7 8 ## Por estado export.rows %\u0026gt;% filter(Activity == \u0026#34;Total\u0026#34;) %\u0026gt;% group_by(year, state) %\u0026gt;% summarise(Total = sum(USD)) %\u0026gt;% ggplot(aes(x = year, y = Total)) + geom_line(aes(colour = abbreviate(state, 6)))+ geom_point(aes(colour = abbreviate(state, 6))) Gracias a abbreviate los nombres de los estados se pueden entender, sin embargo, a pesar de los colores y el texto, es difícil apreciar propiamente 32 líneas (número total de estados en el país).\nPor otro lado nos gustaría ver si cada año fue el mismo estado o la misma actividad produciendo la mayor cantidad de dolares en exportaciones, o si esto cambió con el tiempo. Debido a la complejidad de nuestro gráfico anterior, necesitamos un acercamiento diferente:\n1 2 3 4 5 6 ## Principal estado en cada año export.cols %\u0026gt;% group_by(year) %\u0026gt;% filter(Total == max(Total)) %\u0026gt;% select(year, state, Total) %\u0026gt;% arrange(year) \u0026gt; # A tibble: 12 × 3 \u0026gt; # Groups: year [12] \u0026gt; year state Total \u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026gt; 1 2007 Baja California 31858677 \u0026gt; 2 2008 Baja California 32988913 \u0026gt; 3 2009 Baja California 26741828 \u0026gt; 4 2010 Chihuahua 34633881 \u0026gt; 5 2011 Chihuahua 38446014 \u0026gt; 6 2012 Chihuahua 41764861 \u0026gt; 7 2013 Chihuahua 43770979 \u0026gt; 8 2014 Chihuahua 45594451 \u0026gt; 9 2015 Chihuahua 40302945 \u0026gt; 10 2016 Chihuahua 43342067 \u0026gt; 11 2017 Chihuahua 46491551 \u0026gt; 12 2018 Chihuahua 51944047 Los resultados son interesantes: el principal exportador hasta 2009 es Baja California, y después Chihuahua. Sin embargo, si observamos las principales actividades exportadores, tenemos en primer lugar a Campeche hasta 2013 y después es Coahuila. Parece ser que ciertas actividades no tienen mucha diferencia en la cantidad de ingresos entre ellas, y por eso ciertas combinaciones resultan en mayor nivel de exportación para ciertos estados. Por ejemplo, Capeche es el principal exportador de Petroleo, y se mantiene en primer lugar cuando ordenamos por actividad, sin embargo pasa al sexto lugar cuando ordenamos por estado.\n1 2 3 4 5 6 7 ## Activity export.rows %\u0026gt;% filter(Activity != \u0026#34;Total\u0026#34;) %\u0026gt;% group_by(year) %\u0026gt;% filter(USD == max(USD)) %\u0026gt;% arrange(year) %\u0026gt;% select(Activity, state, year) \u0026gt; # A tibble: 12 × 3 \u0026gt; # Groups: year [12] \u0026gt; Activity state year \u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026gt; 1 Petroleum Campeche 2007 \u0026gt; 2 Petroleum Campeche 2008 \u0026gt; 3 Petroleum Campeche 2009 \u0026gt; 4 Petroleum Campeche 2010 \u0026gt; 5 Petroleum Campeche 2011 \u0026gt; 6 Petroleum Campeche 2012 \u0026gt; 7 Petroleum Campeche 2013 \u0026gt; 8 Transport equipment Coahuila de Zaragoza 2014 \u0026gt; 9 Transport equipment Coahuila de Zaragoza 2015 \u0026gt; 10 Transport equipment Coahuila de Zaragoza 2016 \u0026gt; 11 Transport equipment Coahuila de Zaragoza 2017 \u0026gt; 12 Transport equipment Coahuila de Zaragoza 2018 Sería interesante cambiar la manera de analizar los datos y observar los principales exportadores junto con las principales actividades.\nVisualizaciones interactivas utilizando funciones En el área del análisis de datos, el uso de funciones resulta útil en varios casos. Como vimos anteriormente, nuestra función translate nos ayudó a aplicarla en cada elemento de un vector (en este caso, una columna). Este procesos de aplicar una función en todos los elementos de una lista se conoce tradicionalmente en el albur de programación como \u0026ldquo;map\u0026rdquo;. Otra uso importante de funciones personalizadas es para hacer más eficiente el análisis, por ejemplo cuando necesitamos repetir un proceso mas de una vez.\nEn programación se tienen estándares al escribir código sobre no repetirte a ti mismo, y se crean funciones o macros para básicamente cualquier tarea que deba ser repetida al menos una vez. Como analista de datos esto no es estrictamente necesario, sin embargo nos ahorra tiempo y esfuerzo y al mismo tiempo nos ayuda a entender mejor el lenguaje de programación que estamos utilizando para analizar nuestros datos.\nComo ejemplo, supongamos que queremos hacer visualizaciones de las principales actividades por estado, por ejemplo, actividades que generen mas de 5 millones de dolares. Podríamos escribir lo siguiente\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 export.rows %\u0026gt;% filter(Activity != \u0026#34;Total\u0026#34;) %\u0026gt;% group_by(state, Activity) %\u0026gt;% summarise(Total = sum(USD)) %\u0026gt;% filter(state == \u0026#34;Chihuahua\u0026#34; \u0026amp; Total \u0026gt;= 5000000) %\u0026gt;% ggplot() + geom_bar(aes(y = Total, x = reorder(Activity, Total, FUN = abs), fill = Total), stat = \u0026#39;identity\u0026#39;) + coord_flip() + labs(title = \u0026#34;Chihuahua\u0026#34;, y = \u0026#34;Total USD\u0026#34;, x = NULL) + theme(legend.position=\u0026#34;none\u0026#34;) Sin embargo, tendríamos que repetir el mismo bloque de código por cada estado que queremos visualizar, o si queremos cambiar el límite de 5 millones. La mejor opción en este caso es generar una función que nos permita hacer lo mismo cambiando simplemente las variables que queremos. La manera mas fácil es repetir el código anterior dentro de una función, cambiando el nombre \u0026ldquo;Chihuahua\u0026rdquo; por una variable que podamos modificar cada vez que llamemos la función, vamos a llamarla estado. Por otro lado, en lugar de filtrar sólo actividades que producen mas de 5 millones de dolares, vamos a permitir que este filtro también sea interactivo, sin embargo tomando el valor de 5 millones por default.\nVeamos el siguiente bloque para entender mejor.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ## Funcion para ver principal actividad por estado plot_state \u0026lt;- function(estado, USD_min = 5000000){ export.rows %\u0026gt;% filter(Activity != \u0026#34;Total\u0026#34;) %\u0026gt;% group_by(state, Activity) %\u0026gt;% summarise(Total = sum(USD)) %\u0026gt;% filter(state == estado \u0026amp; Total \u0026gt;= USD_min) %\u0026gt;% ggplot() + geom_bar(aes(y = Total, x = reorder(Activity, Total, FUN = abs), fill = Total), stat = \u0026#39;identity\u0026#39;) + coord_flip() + labs(title = estado, y = \u0026#34;Total USD\u0026#34;, x = NULL) + theme(legend.position=\u0026#34;none\u0026#34;) } El nombre de nuestra función es plot_state y lo definimos como cualquier otro objeto en R, utilizando \u0026lt;- y la función function. Dentro de los paréntesis de function debemos colocar nuestras variables, aquellos valores que podrán ser modificados al llamar la función. En este caso definimos estado que nos ayudará a seleccionar el estado a visualizar, y USD_min para definir la cantidad mínima de dolares a visualizar (por ejemplo, si hacemos USD_min = 0 nuestra función graficaría todas las actividades, siempre y cuando produzcan mas de cero). También podemos ver que aquí he definido USD_min = 5000000, esto genera un valor por default, es decir, si llamamos nuestra función plot_state(\u0026quot;Chihuahua\u0026quot;) obtendremos las actividades que producen mas de 5 millones en Chiuahua, sin embargo, si llamamos plot_state(\u0026quot;Chihuahua\u0026quot;, USD_min = 8000) obtendremos todas las actividades que producen mas de 8 mil.\nUna vez definido el nombre y las variables de nuestra función, podemos especificar el cuerpo dentro de corchetes {}, es decir, la función de nuestra función. En este caso podemos observar que el código que forma el cuerpo de la función es exactamente el mismo que utilizamos para visualizar Chihuahua, los únicos cambios son que en el sitio donde habíamos escrito \u0026ldquo;Chihuahua\u0026rdquo; y \u0026ldquo;5000000\u0026rdquo;, ahora están estado y USD_min. Hay dos consideraciones que deben ser tomadas en cuenta al crear una función de este tipo en R: primero que los valores definidos dentro del cuerpo de una función, en este caso estado y USD_min, sólo existen dentro del cuerpo de la función. Si vamos a la consola y tecleamos ls() veremos que estos objetos no existen en la memoria donde estamos trabajando. Otro aspecto importante es que en R, a diferencia de otros lenguajes de programación, una función puede tomar cualquier objeto que exista en la memoria donde es ejecutado. Por ejemplo, en este caso nuestra función utiliza la tabla export.rows. Si esta tabla no existiera (por ejemplo, si no la hemos creado vía read_csv), nuestra función generará un error.\nEs importante entender el proceso de como la ejecución de funciones busca los valores, para no cometer errores. Al ser ejecutada, la función buscará valores de los objetos PRIMERO dentro del cuerpo de la función, y al no encontrarlos, irá a buscarlos a la memoria general o global de R, que es donde estamos trabajando, si tampoco existen aquí, generará un error. Esto significa que si dentro de la función otorgamos un valor diferente a export.rows, la función utilizará su nuevo valor. Veamos un ejemplo:\n1 2 3 4 5 primeros \u0026lt;- function(){ head(export.rows) } primeros() \u0026gt; # A tibble: 6 × 6 \u0026gt; Código Descripción state year USD Activity \u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026gt; 1 NA Exportaciones totales Aguascalientes 2007 4389841 Total \u0026gt; 2 NA Exportaciones totales Aguascalientes 2008 4456893 Total \u0026gt; 3 NA Exportaciones totales Aguascalientes 2009 3951108 Total \u0026gt; 4 NA Exportaciones totales Aguascalientes 2010 5647929 Total \u0026gt; 5 NA Exportaciones totales Aguascalientes 2011 6051640 Total \u0026gt; 6 NA Exportaciones totales Aguascalientes 2012 6183782 Total Generamos una función sin variables, que nos devuelve los primeros valores en export.rows. En este caso, export.rows no existe dentro del cuerpo de la función, por lo tanto R lo busca en la memoria general, encuentra nuestra tabla, y la utiliza. Sin embargo esto podría cambiar, veamos:\n1 2 3 4 5 6 primeros \u0026lt;- function(){ export.rows \u0026lt;- c(1:100) head(export.rows) } primeros() \u0026gt; [1] 1 2 3 4 5 6 Ahora que le hemos dado un valor a export.rows dentro del cuerpo de la función, el resultado es diferente. Sin embargo, el objeto export.rows en la memoria general no cambió\n1 head(export.rows) \u0026gt; # A tibble: 6 × 6 \u0026gt; Código Descripción state year USD Activity \u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026gt; 1 NA Exportaciones totales Aguascalientes 2007 4389841 Total \u0026gt; 2 NA Exportaciones totales Aguascalientes 2008 4456893 Total \u0026gt; 3 NA Exportaciones totales Aguascalientes 2009 3951108 Total \u0026gt; 4 NA Exportaciones totales Aguascalientes 2010 5647929 Total \u0026gt; 5 NA Exportaciones totales Aguascalientes 2011 6051640 Total \u0026gt; 6 NA Exportaciones totales Aguascalientes 2012 6183782 Total En este ejemplo perecería estúpido, sin embargo al generar funciones muy largas, que utilizan objetos que tenemos creados en la memoria, es fácil cometer errores y otorgarle un valor a un objeto que ya existe y que necesitamos dentro de la función. Diferentes lenguajes de programación protegen esto de diferentes maneras, por ejemplo en python, para llamar un objeto de la memoria general dentro de una función, es necesario utilizar el comando global, lo cual le indica que debe buscar este objeto en el ambiente global, y resulta más fácil para nosotros el notar que objetos estamos utilizando desde el ambiente global. En R es importante ser conscientes de nuestros objetos globales y locales.\nContinuando con nuestro EDA, podemos ver que ahora nuestra función facilita la visualización por estado:\n1 plot_state(\u0026#34;Chihuahua\u0026#34;) Podemos utilizar el paquete cowplot para observar varios estados juntos en un sólo gráfico.\n1 2 3 4 5 6 7 8 plot_grid( plot_state(\u0026#34;Chihuahua\u0026#34;) , plot_state(\u0026#34;Baja California\u0026#34;), plot_state(\u0026#34;Coahuila de Zaragoza\u0026#34;), plot_state(\u0026#34;Nuevo León\u0026#34;), plot_state(\u0026#34;Tamaulipas\u0026#34;), plot_state(\u0026#34;Campeche\u0026#34;, USD_min = 10000), ncol = 2) La función plot_grid resulta útil y conveniente, organiza varios gráficos de forma simétrica, podemos especificar el número de columnas ncol o número de filas nrow en las que nuestros gráficos deben ser visualizados.\nA pesar de que cada estado obtiene sus principales ingresos en exportaciones a partir de diferentes actividades, podemos observar que en general, electrodomésticos (Electronics) y Equipo de Transporte (Transport equipment) son las principales actividades. Otras actividades como Maquinaria (Machinery) y metalúrgica (Metal products) también tienen la tendencia de estar entre los primeros lugares. Así pues, es claro que hay una tendencia entre los 5 principales exportadores con el tipo de actividades exportadoras. Solo para el caso de Campeche, en el sexto lugar es diferente: su principal actividad de exportación es Petroleo, la cual no aparece en las otras gráficas entre las principales actividades de exportación. Sin embargo, si observamos las principales actividades a lo largo del tiempo, exportación de petroleo se encuentra en el tercer lugar:\n1 2 3 4 5 6 7 8 9 export.rows %\u0026gt;% filter(Activity == \u0026#34;Electronics\u0026#34; | Activity == \u0026#34;Transport equipment\u0026#34; | Activity == \u0026#34;Petroleum\u0026#34;) %\u0026gt;% group_by(year, Activity) %\u0026gt;% summarise(`Total per activity` = sum(USD)) %\u0026gt;% ggplot(aes(x = year, y = `Total per activity`)) + geom_line(aes(colour = Activity)) + geom_point(aes(colour = Activity)) Al menos desde 2007, exportación de petroleo genera menos ingresos que exportación de electrodomésticos y equipo de transporte. Otro detalle interesante que es claro en nuestra última gráfica es que a partir de 2009, la exportación en equipo de transporte ha incrementado año con año. Esto explica por que estados donde la principal actividad de exportación es equipo de transporte están en los primeros lugares como exportadores.\nPodemos generar otra función similar a plot_state pero por actividad, plot_activity para observar los principales estados exportadores de petroleo.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ## Funcion para ver principal estado por actividad plot_activity \u0026lt;- function(activity, USD_min = 5000000){ export.cols %\u0026gt;% select(state, year, activity) %\u0026gt;% group_by(state) %\u0026gt;% summarise(Total = sum(!!sym(activity))) %\u0026gt;% filter(Total \u0026gt;= USD_min) %\u0026gt;% ggplot() + geom_bar(aes(y = Total, x = reorder(state, Total, FUN = abs), fill = Total), stat = \u0026#39;identity\u0026#39;) + coord_flip() + labs(title = activity, y = \u0026#34;Total USD\u0026#34;, x = NULL) + theme(legend.position=\u0026#34;none\u0026#34;) } plot_activity(\u0026#34;Petroleum\u0026#34;) Sólo 4 estados exportaron más de 5,000 millones de USD en petroleo.\n1 2 3 4 5 plot_grid( plot_state(\u0026#34;Campeche\u0026#34;, USD_min = 1000000), plot_state(\u0026#34;Tabasco\u0026#34;, USD_min = 1000000), plot_state(\u0026#34;Veracruz de Ignacio de la Llave\u0026#34;), plot_state(\u0026#34;Chiapas\u0026#34;, USD_min = 1000000)) Parece ser que la economía de Tabasco, Campeche y Chiapas dependen en alto grado de la extracción de petroleo, diferente a Veracruz, que tiene otras actividades mas fuertes como productos químicos, metalurgia y alimentación.\n","pubDate":"2022-11-29","title":"EDA de datos de INEGI"},{"link":"http://example.org/posts/2022/map_any_region_with_ggplot2_part_ii/","plain":"You can find all the posts on this series under the tag maps-app (including the Spanish versions).\nYou can also find the current state of the project under my GitHub repo mapic.\nScope of this post This is the second part of the series to create a map of any region of the world with R.\nWe are creating maps of data showing changes over a span of time for different countries and pointing at all kinds of cities. That basically means that we need to map any region of the world with R. Today there are all kinds of packages and techniques to do that. I will share the strategy I used with ggplot2 and maps packages, using support of Open Street Map to obtain the coordinates of cities and finally making it interactive with shiny.\nThis series of posts share my path towards the creation of the Shiny app. It is a live project and I decided to share my path and experiences along the creation process. The posts are not only about the Shiny app, but the package I created behind it, including topics of functions crafting, creation of the maps, classes of objects, etc., as well as any interesting issue that appear on the way. It is my way to contribute to the R community and at the same time keeping the project documented for myself.\nThis post is about Web scrapping with nominatim open street maps\nI hope you all enjoy it. Feel free to leave any kind of comment and/or question at the end.\nOpen Street Maps and Nominatim A simple query\n1 2 3 4 library(\u0026#39;RJSONIO\u0026#39;) site \u0026lt;- (\u0026#34;http://nominatim.openstreetmap.org/search?city=Texcoco\u0026amp;limit=9\u0026amp;format=json\u0026#34;) (result \u0026lt;- fromJSON(site)) \u0026gt; [[1]] \u0026gt; [[1]]$place_id \u0026gt; [1] 1177116 \u0026gt; \u0026gt; [[1]]$licence \u0026gt; [1] \u0026#34;Data © OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\u0026#34; \u0026gt; \u0026gt; [[1]]$osm_type \u0026gt; [1] \u0026#34;node\u0026#34; \u0026gt; \u0026gt; [[1]]$osm_id \u0026gt; [1] 336169214 \u0026gt; \u0026gt; [[1]]$boundingbox \u0026gt; [1] \u0026#34;29.619\u0026#34; \u0026#34;29.659\u0026#34; \u0026#34;-111.0786667\u0026#34; \u0026#34;-111.0386667\u0026#34; \u0026gt; \u0026gt; [[1]]$lat \u0026gt; [1] \u0026#34;29.639\u0026#34; \u0026gt; \u0026gt; [[1]]$lon \u0026gt; [1] \u0026#34;-111.0586667\u0026#34; \u0026gt; \u0026gt; [[1]]$display_name \u0026gt; [1] \u0026#34;Texcoco, Carbó, Sonora, México\u0026#34; \u0026gt; \u0026gt; [[1]]$class \u0026gt; [1] \u0026#34;place\u0026#34; \u0026gt; \u0026gt; [[1]]$type \u0026gt; [1] \u0026#34;village\u0026#34; \u0026gt; \u0026gt; [[1]]$importance \u0026gt; [1] 0.385 \u0026gt; \u0026gt; [[1]]$icon \u0026gt; [1] \u0026#34;https://nominatim.openstreetmap.org/ui/mapicons/poi_place_village.p.20.png\u0026#34; \u0026gt; \u0026gt; \u0026gt; [[2]] \u0026gt; [[2]]$place_id \u0026gt; [1] 3448536 \u0026gt; \u0026gt; [[2]]$licence \u0026gt; [1] \u0026#34;Data © OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\u0026#34; \u0026gt; \u0026gt; [[2]]$osm_type \u0026gt; [1] \u0026#34;node\u0026#34; \u0026gt; \u0026gt; [[2]]$osm_id \u0026gt; [1] 458633446 \u0026gt; \u0026gt; [[2]]$boundingbox \u0026gt; [1] \u0026#34;16.551667\u0026#34; \u0026#34;16.591667\u0026#34; \u0026#34;-97.053333\u0026#34; \u0026#34;-97.013333\u0026#34; \u0026gt; \u0026gt; [[2]]$lat \u0026gt; [1] \u0026#34;16.571667\u0026#34; \u0026gt; \u0026gt; [[2]]$lon \u0026gt; [1] \u0026#34;-97.033333\u0026#34; \u0026gt; \u0026gt; [[2]]$display_name \u0026gt; [1] \u0026#34;Texcoco, Santa María Sola, Oaxaca, México\u0026#34; \u0026gt; \u0026gt; [[2]]$class \u0026gt; [1] \u0026#34;place\u0026#34; \u0026gt; \u0026gt; [[2]]$type \u0026gt; [1] \u0026#34;hamlet\u0026#34; \u0026gt; \u0026gt; [[2]]$importance \u0026gt; [1] 0.36 \u0026gt; \u0026gt; [[2]]$icon \u0026gt; [1] \u0026#34;https://nominatim.openstreetmap.org/ui/mapicons/poi_place_village.p.20.png\u0026#34; We start with Open Street Map and its API nominatim. In the piece of code above we can see how to perform a simple query for one city. It is basically one long string containing first the url of nominatim and at the end the search details: here we start the search with city using ?city=Texcoco, in this case I aimed for a city with only a few results. Next we are limiting the amount of results to 9 with \u0026amp;limit=9 and finally requesting the results in format JSON.\nWe could basically copy the string that we are passing to site and paste it in the web browser to see the results directly there. Feel free to change the city Texcoco to any other city, and play a bit more with the rest of the parameters. Particularly have a look at what happens when you remove the \u0026amp;format=json part or when you exchange json for any other abstract string like csv or other non-recognized format.\nA more specific query\n1 2 3 4 5 6 7 8 city \u0026lt;- \u0026#39;San%20Francisco\u0026#39; state \u0026lt;- \u0026#39;\u0026amp;state=California\u0026#39; country \u0026lt;- \u0026#39;\u0026amp;countrycodes=US\u0026#39; start.nominatim \u0026lt;- \u0026#34;http://nominatim.openstreetmap.org/search?city=\u0026#34; end.nominatim \u0026lt;- \u0026#34;\u0026amp;format=json\u0026#34; site \u0026lt;- paste0(start.nominatim, city, country, state, end.nominatim) (result \u0026lt;- fromJSON(site)) \u0026gt; [[1]] \u0026gt; [[1]]$place_id \u0026gt; [1] 297054975 \u0026gt; \u0026gt; [[1]]$licence \u0026gt; [1] \u0026#34;Data © OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\u0026#34; \u0026gt; \u0026gt; [[1]]$osm_type \u0026gt; [1] \u0026#34;relation\u0026#34; \u0026gt; \u0026gt; [[1]]$osm_id \u0026gt; [1] 111968 \u0026gt; \u0026gt; [[1]]$boundingbox \u0026gt; [1] \u0026#34;37.6403143\u0026#34; \u0026#34;37.929811\u0026#34; \u0026#34;-123.173825\u0026#34; \u0026#34;-122.281479\u0026#34; \u0026gt; \u0026gt; [[1]]$lat \u0026gt; [1] \u0026#34;37.7790262\u0026#34; \u0026gt; \u0026gt; [[1]]$lon \u0026gt; [1] \u0026#34;-122.419906\u0026#34; \u0026gt; \u0026gt; [[1]]$display_name \u0026gt; [1] \u0026#34;San Francisco, CAL Fire Northern Region, California, United States\u0026#34; \u0026gt; \u0026gt; [[1]]$class \u0026gt; [1] \u0026#34;boundary\u0026#34; \u0026gt; \u0026gt; [[1]]$type \u0026gt; [1] \u0026#34;administrative\u0026#34; \u0026gt; \u0026gt; [[1]]$importance \u0026gt; [1] 1.035131 \u0026gt; \u0026gt; [[1]]$icon \u0026gt; [1] \u0026#34;https://nominatim.openstreetmap.org/ui/mapicons/poi_boundary_administrative.p.20.png\u0026#34; If you explore OSM and nominatim a bit you will see that we can add search arguments using \u0026amp; followed by the argument we want (i.e., state), the symbol equal = and the argument. In my example above you can see how we are specifying the State and Country of our query. Additionally it is important to know how to pass spaces in a name, for example, San Francisco will be passed as San%20Francisco.\nWith this basic information in mind and knowing that the package RJSONIO helps us to retrieve the data from the JSON api into an R-friendly format, we can easily prepare a function to search for any city quickly, provided a few extra details like a region, state or county, and especially important, the country (try searching for cities like London or Prague without providing a country, you might be surprised of how many cities exist in the world with such names).\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 coords_from_city \u0026lt;- function(City, CountryTwoLetter, Region = NULL, State = NULL, County = NULL){ require(\u0026#39;RJSONIO\u0026#39;) CityCoded \u0026lt;- gsub(\u0026#39; \u0026#39;,\u0026#39;%20\u0026#39;,City) #remove space for URLs CountryCoded \u0026lt;- paste(\u0026#34;\u0026amp;countrycodes=\u0026#34;, CountryTwoLetter, sep = \u0026#39;\u0026#39;) extras \u0026lt;- c(state = State, region = Region, county = County) extrasCoded \u0026lt;- \u0026#39;\u0026#39; if(!is.null(extras)) { for(i in 1:length(extras)){ if(extras[i] != \u0026#39;\u0026#39; \u0026amp;\u0026amp; !is.na(extras[i]) \u0026amp;\u0026amp; !grepl(\u0026#34;^\\\\s*$\u0026#34;, extras[i])){ valCoded \u0026lt;- gsub(\u0026#39; \u0026#39;, \u0026#39;%20\u0026#39;, extras[i]) extrasCoded \u0026lt;- paste0(extrasCoded, \u0026#39;\u0026amp;\u0026#39;, names(extras)[i], \u0026#39;=\u0026#39;, valCoded) } } } ## get data url \u0026lt;- paste( \u0026#34;http://nominatim.openstreetmap.org/search?city=\u0026#34; , CityCoded , CountryCoded , extrasCoded , \u0026#34;\u0026amp;format=json\u0026#34; , sep=\u0026#34;\u0026#34;) x \u0026lt;- fromJSON(url) ## retrieve coords if(is.vector(x)){ message(paste(\u0026#39;Found\u0026#39;, x[[1]]$display_name)) lon \u0026lt;- x[[1]]$lon lat \u0026lt;- x[[1]]$lat osm_name \u0026lt;- x[[1]]$display_name coords \u0026lt;- data.frame(\u0026#39;lon\u0026#39; = lon, \u0026#39;lat\u0026#39; = lat, \u0026#39;osm_name\u0026#39; = osm_name) } ## When x is not a vector else{ message(paste(\u0026#39;No results found for\u0026#39;, City, CountryTwoLetter)) coords \u0026lt;- data.frame(\u0026#39;lon\u0026#39; = NA, \u0026#39;lat\u0026#39; = NA) } ## return a df coords } An important detail to know is that often, providing values to either state or region parameters returns similar results, this is particularly useful in countries where no states are used or other forms of organization are present. However, when the country has \u0026ldquo;States\u0026rdquo;, you cannot pass the name of a State to the parameter Region.\nThe function returns a data frame that we will use later to create a table with all of our results. Since we are interested in creating maps, we only need the coordinates expressed in latitude and longitude parameters. In case the query is not found, it fills the values with NA\u0026rsquo;s, which later we\u0026rsquo;ll use to keep track of what was found and what wasn\u0026rsquo;t. We are also keeping the values inside osm_name which provides enough information to tell the user useful details regarding the search results, including the country of the city found, and other details like state or region.\nAn important point to consider in coords_from_city is that it will return only the top result from the query. It means that the more information you provide, the more accurate your result will be. For our project it worked well because for big countries we were always collecting enough info about regions and states, while for smaller countries often the options were too small. But if you use the function it is important to know that if you provide a city name like Springfield, Country = 'US' and give no info about State and County, the function will retrieve only the top result from the search and discard the remaining options.\nKeeping the info in a database The function coords_from_city could be enough if we need to retrieve info about a few cities; we could make a for loop, retrieve all the coords we need and sore them in a data frame to later save as csv, Rdata or any format we choose. The same is true when we are searching for hundreds or thousands of cities but with data increasing the searching time also increases. If, for any reason, the R session breaks, the information would be lost and we will have to start all over again from row 1. Therefore, we are going to send every single result to a database. In that way, no matter when we stop the process or how this happens, the data is safely stored outside of R.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 webscrap_to_sqlite \u0026lt;- function(db.name, dat, col.city = \u0026#39;City\u0026#39;, col.country = \u0026#39;Country\u0026#39;, region = NULL, state = NULL, county = NULL) { require(RSQLite) df_len \u0026lt;- nrow(dat) ## Connect to db and table con \u0026lt;- dbConnect(drv=SQLite(), dbname=db.name) dbExecute(conn = con, \u0026#34;CREATE TABLE IF NOT EXISTS orgs (ID INTEGER UNIQUE, City TEXT, osm_name TEXT, lon REAL,lat REAL)\u0026#34;) ## -- Iteration to web-scrap data -- ## ccount \u0026lt;- 0 ## For loop to webscrapping for(i in 1:df_len){ rg \u0026lt;- ifelse(is.null(region), \u0026#39;\u0026#39;, dat[[region]][i]) st \u0026lt;- ifelse(is.null(state), \u0026#39;\u0026#39;, dat[[state]][i]) ct \u0026lt;- ifelse(is.null(county), \u0026#39;\u0026#39;, dat[[county]][i]) print(paste(\u0026#39;Entry\u0026#39;, i)) ## Do the webscrap coords \u0026lt;- coords_from_city(dat[[col.city]][i], dat[[col.country]][i], Region = rg, State = st, County = ct) ## DB send query ONLY if coords were found if(is.na(coords$lon[1])){ ccount \u0026lt;- ccount + 1 } else{ sq \u0026lt;- dbExecute(con, \u0026#39;INSERT OR IGNORE INTO orgs (ID, City, osm_name, lon, lat) VALUES (?, ?, ?, ?, ?);\u0026#39;, list(dat[[\u0026#39;ID\u0026#39;]][i], dat[[col.city]][i], coords$osm_name, coords$lon[1], coords$lat[1])) } print(paste(\u0026#39;Completed\u0026#39;, (i/df_len)*100, \u0026#39;%\u0026#39;)) } ## Close db dbDisconnect(con) message(paste(\u0026#34;WEB SCRAP FOR COORDINATES SEARCH FINISHED.\u0026#34;, ccount, \u0026#34;ENTRIES NOT FOUND\u0026#34;)) } For storing the data I have chosen to use SQLite through the R package RSQLite. If you are not familiar with SQL databases I recommend you to start with a general google search and then come back to the documentation of SQLite and the R package. I chose SQLite because we needed to have something light and portable that would allow us to move the information easily from country to country rather than a centralized database where we could store everything, but a very similar approach can be applied using other types of SQL databases.\nThe function dbConnect() generates the SQLite file if it does not exist yet. Then we give SQLite the order to create the table orgs if doesn\u0026rsquo;t exist yet, and the structure for such table. Next we search for the coordinates of the entries one by one using coords_from_city() and finally we send it to the database. In that way we could stop the process at any time and continue later by simply retrieving the table orgs from the database, compare it with our original data and move forward from what is missing. For that, the column ID is critical, it is the column that allows us to link an entry between the original data, the R data.frame and the SQL table.\nOur function also has a variable ccount that counts each time an entry was not found. In that way, once the query is finished it will print the amount of entries that were not found. The reasons for not finding an entry can be many, among the most common ones that I encountered are the following:\nWrong spelling of the City name or excess of info (i.e., value \u0026ldquo;Prague, District 3\u0026rdquo; when the city name is simply \u0026ldquo;Prague\u0026rdquo;). Wrong spelling of the State, Region and/or County name. The given City is simply not in the database of Open Street Maps (it happened specially for very small villages). Breaks of the internet connection. This one is particularly important because sometimes running the query a second or third time would find cities that were not found the first time. To read the data back to R from SQL we simply need to make a connection to the database, read the table, and close the connection. The function combine_df_sql takes care of that and at the same time joins our original data to the data stored in the database by the ID and the city name. This was important for the project because we wanted to keep the coordinates of the cities separated from the rest of the information due to some internal practical reasons. But I think that keeping all the data in SQL at once can facilitate many things. Among others, you could identify when a particular city was already found in the past and retrieve the coordinates from the database directly rather than making a connection to nominatim. I did that for a few countries and it reduces the querying time considerably. For the present post I decided to show the separated version of data in order to provide more tools to the reader.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 combine_df_sql \u0026lt;- function(db.file, original.data){ require(dplyr) require(RSQLite) if(is.character(original.data)){ if(grepl(\u0026#39;.csv\u0026#39;, original.data, fixed = T)){ df \u0026lt;- read.csv(original.data) } else{ stop(\u0026#34;Incorrect file format for data\u0026#34;) } } else if(is.data.frame(original.data)){ df \u0026lt;- original.data } else{ stop(\u0026#34;Incorrect data format\u0026#34;) } con \u0026lt;- dbConnect(drv=RSQLite::SQLite(), dbname = db.file) db \u0026lt;- dbReadTable(con, \u0026#34;orgs\u0026#34;) dbDisconnect(con) result \u0026lt;- left_join(df, db, by = c(\u0026#39;ID\u0026#39;, \u0026#39;City\u0026#39;)) return(result) } Another detail of our function is the ability to read either from the csv file or from a data.frame. Since we were working mainly with csv files and I used data frames for the unit tests, these 2 formats were enough. Feel free to modify or extend the function for the data formats that you might need.\nMissing data As mentioned above, sometimes the results from the query would be incomplete and a second or third run were necessary but with a fewer rows. Some others I just needed to stop the query and continue later from where we left. And yet some other times the data was incomplete or wrong and this could be solved later with the data owner. The 3 scenarios required me to read the csv file to R, then the table from the database and compare them to filter the missing values. So I crafted the function compare_db_data to compare the database (db) to the original data.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 compare_db_data \u0026lt;- function(db.file, dat){ require(dplyr) require(RSQLite) if(is.character(dat)){ if(grepl(\u0026#39;.csv\u0026#39;, dat, fixed = T)){ df \u0026lt;- read.csv(dat) } else{ stop(\u0026#34;Incorrect file format for data\u0026#34;) } } else if(is.data.frame(dat)){ df \u0026lt;- dat } else{ stop(\u0026#34;Incorrect data format\u0026#34;) } con \u0026lt;- dbConnect(drv=RSQLite::SQLite(), dbname = db.file) db \u0026lt;- dbReadTable(con, \u0026#34;orgs\u0026#34;) dbDisconnect(con) filtered \u0026lt;- filter(df, !(as.character(ID) %in% as.character(db$ID))) filtered } As mentioned earlier, sometimes Open Street Maps would simply not have registered certain \u0026ldquo;cities\u0026rdquo; (in fact it happened only with really small villages or populations). For that the function add_coords_manually would take a csv file with a particular structure to add the missing data. The csv file must have the following columns:\nID column named exactly like that and containing the same ID as the original data. A column containing the name of the city Columns containing the Latitude and Longitude were we want to point at the city A value for osm_name. This could be left empty or we can provide the value we want in this slot. What is important is to have the column present in the csv file. Then, as in previous function, we pass to add_coords_manually the name of the csv file with the complementary information, the name of the SQLite database and the names of the columns where we have the values for city names, osm_name, lat and long, all as strings. The rest of the function is self descriptive, provided basic knowledge of SQL syntax.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 add_coords_manually \u0026lt;- function(csv_file, db.name, city, osm_name, lat, lon){ require(tidyverse) require(RSQLite) csv_dat \u0026lt;- read_csv(csv_file) csv_len \u0026lt;- length(csv_dat$ID) con \u0026lt;- dbConnect(drv=RSQLite::SQLite(), dbname=db.name) for(i in 1:csv_len){ dbSendQuery(con, \u0026#39;INSERT OR IGNORE INTO orgs (ID, City, osm_name, lon, lat) VALUES (?, ?, ?, ?, ?);\u0026#39;, list(csv_dat[[\u0026#39;ID\u0026#39;]][i], csv_dat[[city]][i], csv_dat[[osm_name]][i], csv_dat[[lat]][i], csv_dat[[lon]][i])) } dbDisconnect(con) print(paste(csv_len, \u0026#39;inserted\u0026#39;)) } Next steps If you are new to R you could probably already had noticed that one of the strengths of R that I\u0026rsquo;m using a lot here is its use of functions. The first maps that we created were done writing scripts with a few hundreds of lines. Those gave us the basis to craft the necessary functions and so, the rest of the maps were possible using just a few lines. Some of the scripts for the web scrapping of the coordinates consist of less than 10 lines of code. That is possible using the functions above and a few others created for special or particular cases. I will not share absolutely everything but I want to give an idea of how to make the process more efficient. You can always create more functions for your particular cases or modify my proposed functions to adapt to your particular situation.\nAnd speaking of extensibility, just while writting this blog I found out about the package tmaptools which contains the function geocode_OSM which uses nominatim to retrieve the coordinates of the searched point. The function has a more user friendly searching format and more possibilities for the return value, while my coords_from_city() option stays quite stiff and still with the original format that it was envisioned a few years ago when I created it. If you are truly interested in the topic I invite you to check the package. Myself I have been busy maintaining the code and creating maps that I found little time to do any improvements to the original project. But that\u0026rsquo;s exactly my main task right now so, if I do any changes to the functions presented here using the tmaptools package you can be sure that I will create a short post to share it as well.\nThen, once we got the coordinates of our target cities and we know how to make the basic map, the next step is to add the cities to the base map. In the next post I will show you how I did that and a function to make the process faster and efficient.\n","pubDate":"2022-11-04","title":"Map any region in the world with R - Part II: Obtaining the coordinates"},{"link":"http://example.org/es/posts/2022/map_any_region_with_ggplot2_part_ii/","plain":"Pueden encontrar todas las publicaciones en este tema bajo la etiqueta maps-app (incluyendo las versiones en inglés).\nTambién pueden encontrar el estado actual del proyecto en mi GitHub repo mapic.\nSobre este post Esta es la segunda parte de las series de cómo crear mapas de cualquier región del mundo con R. De antemano me disculpo por detalles que puedan encontrar en la traducción, el post original lo creé en Inglés y el trabajo de traducción puede ser excesivo si voy a cada detalle. Por otro lado, recomiendo un conocimiento al menos básico del idioma Inglés si se quiere tener éxito en R o programación en general. Ayuda mucho a entender la sintaxis.\nEstamos creando mapas de datos que muestran los cambios durante un período de tiempo para diferentes países y orientado a todo tipo de ciudades. Esto básicamente significa que necesitamos mapear cualquier región del mundo con R. Hoy en día existen todo tipo de paquetes y técnicas para hacerlo. Quiero compartir la estrategia que utilicé con ggplot2 y maps, utilizando el soporte de Open Street Map para obtener las coordenadas de las ciudades y finalmente hacerlo interactivo con shiny.\nEstas publicaciones comparten mi camino en la creación de la aplicación Shiny. Es un proyecto vivo en el que estoy trabajando actualmente y decidí compartir mis experiencias durante el proceso de creación. Estas publicaciones no son sólo acerca de Shiny apps, si no más bien sobre la creación del paquete detrás, incluyendo temas sobre la generación de funciones, creación de los mapas, clases de objetos, entre otros, incluyendo cualquier tema interesante que aparezca en el camino. Es mi manera de contribuir a la comunidad de R y al mismo tiempo documentar el proyecto en si mismo.\nEspero que lo disfruten. Siéntanse libres de dejar cualquier tipo de comentario y/o pregunta al final.\nOpen Street Maps y Nominatim Una búsqueda sencilla\n1 2 3 4 library(\u0026#39;RJSONIO\u0026#39;) site \u0026lt;- (\u0026#34;http://nominatim.openstreetmap.org/search?city=Texcoco\u0026amp;limit=9\u0026amp;format=json\u0026#34;) (result \u0026lt;- fromJSON(site)) \u0026gt; [[1]] \u0026gt; [[1]]$place_id \u0026gt; [1] 1177116 \u0026gt; \u0026gt; [[1]]$licence \u0026gt; [1] \u0026#34;Data © OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\u0026#34; \u0026gt; \u0026gt; [[1]]$osm_type \u0026gt; [1] \u0026#34;node\u0026#34; \u0026gt; \u0026gt; [[1]]$osm_id \u0026gt; [1] 336169214 \u0026gt; \u0026gt; [[1]]$boundingbox \u0026gt; [1] \u0026#34;29.619\u0026#34; \u0026#34;29.659\u0026#34; \u0026#34;-111.0786667\u0026#34; \u0026#34;-111.0386667\u0026#34; \u0026gt; \u0026gt; [[1]]$lat \u0026gt; [1] \u0026#34;29.639\u0026#34; \u0026gt; \u0026gt; [[1]]$lon \u0026gt; [1] \u0026#34;-111.0586667\u0026#34; \u0026gt; \u0026gt; [[1]]$display_name \u0026gt; [1] \u0026#34;Texcoco, Carbó, Sonora, México\u0026#34; \u0026gt; \u0026gt; [[1]]$class \u0026gt; [1] \u0026#34;place\u0026#34; \u0026gt; \u0026gt; [[1]]$type \u0026gt; [1] \u0026#34;village\u0026#34; \u0026gt; \u0026gt; [[1]]$importance \u0026gt; [1] 0.385 \u0026gt; \u0026gt; [[1]]$icon \u0026gt; [1] \u0026#34;https://nominatim.openstreetmap.org/ui/mapicons/poi_place_village.p.20.png\u0026#34; \u0026gt; \u0026gt; \u0026gt; [[2]] \u0026gt; [[2]]$place_id \u0026gt; [1] 3448536 \u0026gt; \u0026gt; [[2]]$licence \u0026gt; [1] \u0026#34;Data © OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\u0026#34; \u0026gt; \u0026gt; [[2]]$osm_type \u0026gt; [1] \u0026#34;node\u0026#34; \u0026gt; \u0026gt; [[2]]$osm_id \u0026gt; [1] 458633446 \u0026gt; \u0026gt; [[2]]$boundingbox \u0026gt; [1] \u0026#34;16.551667\u0026#34; \u0026#34;16.591667\u0026#34; \u0026#34;-97.053333\u0026#34; \u0026#34;-97.013333\u0026#34; \u0026gt; \u0026gt; [[2]]$lat \u0026gt; [1] \u0026#34;16.571667\u0026#34; \u0026gt; \u0026gt; [[2]]$lon \u0026gt; [1] \u0026#34;-97.033333\u0026#34; \u0026gt; \u0026gt; [[2]]$display_name \u0026gt; [1] \u0026#34;Texcoco, Santa María Sola, Oaxaca, México\u0026#34; \u0026gt; \u0026gt; [[2]]$class \u0026gt; [1] \u0026#34;place\u0026#34; \u0026gt; \u0026gt; [[2]]$type \u0026gt; [1] \u0026#34;hamlet\u0026#34; \u0026gt; \u0026gt; [[2]]$importance \u0026gt; [1] 0.36 \u0026gt; \u0026gt; [[2]]$icon \u0026gt; [1] \u0026#34;https://nominatim.openstreetmap.org/ui/mapicons/poi_place_village.p.20.png\u0026#34; Comenzamos con Open Street Map y su API nominatim. En el código anterior podemos ver cómo realizar una consulta simple para una ciudad. Es básicamente un string (en R, \u0026ldquo;string\u0026rdquo; se utiliza para referirse a texto) largo que contiene primero la url de nominatim y al final los detalles de la búsqueda: aquí comenzamos la búsqueda de la ciudad, usando ?city=Texcoco que en este caso apunta a una ciudad con solo unos pocos resultados. A continuación, limitamos la cantidad de resultados a 9 con \u0026amp;limit=9 y finalmente solicitamos los resultados en formato JSON.\nBásicamente, podríamos copiar el string que estamos pasando a la variable site y pegarla en el navegador web para ver los resultados directamente ahí. Siéntete libre de cambiar la ciudad Texcoco a cualquier otra ciudad, y juega un poco más con el resto de los parámetros. En particular, eche un vistazo a lo que sucede cuando elimina la parte \u0026amp;format=json o cuando cambia json por cualquier otra cadena abstracta como csv u otro formato no reconocido.\nUna búsqueda más sencilla\n1 2 3 4 5 6 7 8 city \u0026lt;- \u0026#39;San%20Francisco\u0026#39; state \u0026lt;- \u0026#39;\u0026amp;state=California\u0026#39; country \u0026lt;- \u0026#39;\u0026amp;countrycodes=US\u0026#39; start.nominatim \u0026lt;- \u0026#34;http://nominatim.openstreetmap.org/search?city=\u0026#34; end.nominatim \u0026lt;- \u0026#34;\u0026amp;format=json\u0026#34; site \u0026lt;- paste0(start.nominatim, city, country, state, end.nominatim) (result \u0026lt;- fromJSON(site)) \u0026gt; [[1]] \u0026gt; [[1]]$place_id \u0026gt; [1] 297054975 \u0026gt; \u0026gt; [[1]]$licence \u0026gt; [1] \u0026#34;Data © OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright\u0026#34; \u0026gt; \u0026gt; [[1]]$osm_type \u0026gt; [1] \u0026#34;relation\u0026#34; \u0026gt; \u0026gt; [[1]]$osm_id \u0026gt; [1] 111968 \u0026gt; \u0026gt; [[1]]$boundingbox \u0026gt; [1] \u0026#34;37.6403143\u0026#34; \u0026#34;37.929811\u0026#34; \u0026#34;-123.173825\u0026#34; \u0026#34;-122.281479\u0026#34; \u0026gt; \u0026gt; [[1]]$lat \u0026gt; [1] \u0026#34;37.7790262\u0026#34; \u0026gt; \u0026gt; [[1]]$lon \u0026gt; [1] \u0026#34;-122.419906\u0026#34; \u0026gt; \u0026gt; [[1]]$display_name \u0026gt; [1] \u0026#34;San Francisco, CAL Fire Northern Region, California, United States\u0026#34; \u0026gt; \u0026gt; [[1]]$class \u0026gt; [1] \u0026#34;boundary\u0026#34; \u0026gt; \u0026gt; [[1]]$type \u0026gt; [1] \u0026#34;administrative\u0026#34; \u0026gt; \u0026gt; [[1]]$importance \u0026gt; [1] 1.035131 \u0026gt; \u0026gt; [[1]]$icon \u0026gt; [1] \u0026#34;https://nominatim.openstreetmap.org/ui/mapicons/poi_boundary_administrative.p.20.png\u0026#34; Si exploramos OSM y nominatim un poco, veremos que podemos agregar argumentos de búsqueda usando \u0026amp; seguido del argumento que queremos (es decir, state), el símbolo igual (=) y el argumento. En mi ejemplo anterior, puede verse cómo especificamos el estado y el país de nuestra consulta. Además, es importante saber cómo pasar espacios en un nombre, por ejemplo, San Francisco pasaría como San%20Francisco.\nCon esta información básica en mente y sabiendo que el paquete RJSONIO nos ayuda a recuperar los datos de la API JSON en un formato tabular compatible con R, podemos preparar fácilmente una función para buscar cualquier ciudad rápidamente, siempre que se proporcionen algunos detalles adicionales como una región, estado o condado, y especialmente importante, el país (intenta buscar ciudades como Londres o Praga sin proporcionar un país, te sorprenderá la cantidad de ciudades que existen en el mundo con esos nombres).\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 coords_from_city \u0026lt;- function(City, CountryTwoLetter, Region = NULL, State = NULL, County = NULL){ require(\u0026#39;RJSONIO\u0026#39;) CityCoded \u0026lt;- gsub(\u0026#39; \u0026#39;,\u0026#39;%20\u0026#39;,City) #remover espacios de URLs CountryCoded \u0026lt;- paste(\u0026#34;\u0026amp;countrycodes=\u0026#34;, CountryTwoLetter, sep = \u0026#39;\u0026#39;) extras \u0026lt;- c(state = State, region = Region, county = County) extrasCoded \u0026lt;- \u0026#39;\u0026#39; if(!is.null(extras)) { for(i in 1:length(extras)){ if(extras[i] != \u0026#39;\u0026#39; \u0026amp;\u0026amp; !is.na(extras[i]) \u0026amp;\u0026amp; !grepl(\u0026#34;^\\\\s*$\u0026#34;, extras[i])){ valCoded \u0026lt;- gsub(\u0026#39; \u0026#39;, \u0026#39;%20\u0026#39;, extras[i]) extrasCoded \u0026lt;- paste0(extrasCoded, \u0026#39;\u0026amp;\u0026#39;, names(extras)[i], \u0026#39;=\u0026#39;, valCoded) } } } ## obtener los datos url \u0026lt;- paste( \u0026#34;http://nominatim.openstreetmap.org/search?city=\u0026#34; , CityCoded , CountryCoded , extrasCoded , \u0026#34;\u0026amp;format=json\u0026#34; , sep=\u0026#34;\u0026#34;) x \u0026lt;- fromJSON(url) ## obtener las coordenadas if(is.vector(x)){ message(paste(\u0026#39;Found\u0026#39;, x[[1]]$display_name)) lon \u0026lt;- x[[1]]$lon lat \u0026lt;- x[[1]]$lat osm_name \u0026lt;- x[[1]]$display_name coords \u0026lt;- data.frame(\u0026#39;lon\u0026#39; = lon, \u0026#39;lat\u0026#39; = lat, \u0026#39;osm_name\u0026#39; = osm_name) } ## Si x no es un vector else{ message(paste(\u0026#39;No results found for\u0026#39;, City, CountryTwoLetter)) coords \u0026lt;- data.frame(\u0026#39;lon\u0026#39; = NA, \u0026#39;lat\u0026#39; = NA) } ## regresa un df coords } Un detalle importante que debe saber es que, a menudo, proporcionar valores a los parámetros \u0026ldquo;state\u0026rdquo; o \u0026ldquo;region\u0026rdquo; arroja resultados similares, esto es particularmente útil en países donde no se usan estados o hay otras formas de organización presentes. Sin embargo, cuando el país tiene estrictamente estados, no puedes pasar el nombre de un Estado al parámetro Region.\nLa función devuelve un data frame que usaremos más adelante para crear una tabla con todos nuestros resultados. Como estamos interesados en crear mapas, solo necesitamos las coordenadas expresadas en latitud y longitud. En caso de que no se encuentre la consulta, la función completa los valores con NA, que luego usaremos para realizar un seguimiento de lo que se encontró y lo que no. También mantenemos los valores dentro de osm_name, que brinda suficiente información para brindarle al usuario detalles útiles sobre los resultados de la búsqueda, incluido el país de la ciudad encontrada y otros detalles como el estado o la región.\nUn punto importante a considerar en coords_from_city es que devuelve solo el resultado superior de la consulta. Esto significa que cuanto más información se proporcione, más preciso será su resultado. Para nuestro proyecto funciona bien porque para los países grandes siempre recopilamos suficiente información sobre regiones y estados, mientras que para los países más pequeños, las opciones a menudo son demasiado pequeñas. Pero si usamos la función, es importante saber que si se proporciona un nombre de ciudad como Springfield, country = 'US' y no proporciona información sobre el estado y el condado, la función recuperara solo el primer resultado de la búsqueda, y descarta las opciones restantes.\nMantener la información en una base de datos La función coords_from_city podría ser suficiente si necesitamos obtener información unas pocas ciudades; Podríamos utilizar la iteración de for para recuperar todas las coordenadas que necesitamos y almacenarlas en un data frame para luego guardarlas en formato csv, Rdata o cualquier formato que elijamos. Lo mismo ocurre cuando buscamos cientos o miles de ciudades, pero con el aumento del tamaño, el tiempo de búsqueda también aumenta. Si, por alguna razón, la sesión de R se interrumpe, la información se perdería y tendremos que comenzar de nuevo desde la fila 1. Por lo tanto, enviaremos todos los resultados a una base de datos. De esa forma, no importa cuándo detengamos el proceso o cómo suceda, los datos se almacenan de forma segura fuera de R.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 webscrap_to_sqlite \u0026lt;- function(db.name, dat, col.city = \u0026#39;City\u0026#39;, col.country = \u0026#39;Country\u0026#39;, region = NULL, state = NULL, county = NULL) { require(RSQLite) df_len \u0026lt;- nrow(dat) ## Conexion a la db y la tabla con \u0026lt;- dbConnect(drv=SQLite(), dbname=db.name) dbExecute(conn = con, \u0026#34;CREATE TABLE IF NOT EXISTS orgs (ID INTEGER UNIQUE, City TEXT, osm_name TEXT, lon REAL,lat REAL)\u0026#34;) ## -- Iteraciones para el webscrap -- ## ccount \u0026lt;- 0 ## For loop para el webscrapping for(i in 1:df_len){ rg \u0026lt;- ifelse(is.null(region), \u0026#39;\u0026#39;, dat[[region]][i]) st \u0026lt;- ifelse(is.null(state), \u0026#39;\u0026#39;, dat[[state]][i]) ct \u0026lt;- ifelse(is.null(county), \u0026#39;\u0026#39;, dat[[county]][i]) print(paste(\u0026#39;Entry\u0026#39;, i)) ## Haz el webscrap coords \u0026lt;- coords_from_city(dat[[col.city]][i], dat[[col.country]][i], Region = rg, State = st, County = ct) ## Enviar resultados a DB sólo si se encontró algo if(is.na(coords$lon[1])){ ccount \u0026lt;- ccount + 1 } else{ sq \u0026lt;- dbExecute(con, \u0026#39;INSERT OR IGNORE INTO orgs (ID, City, osm_name, lon, lat) VALUES (?, ?, ?, ?, ?);\u0026#39;, list(dat[[\u0026#39;ID\u0026#39;]][i], dat[[col.city]][i], coords$osm_name, coords$lon[1], coords$lat[1])) } print(paste(\u0026#39;Completed\u0026#39;, (i/df_len)*100, \u0026#39;%\u0026#39;)) } ## Cerrar la conexión dbDisconnect(con) message(paste(\u0026#34;WEB SCRAP FOR COORDINATES SEARCH FINISHED.\u0026#34;, ccount, \u0026#34;ENTRIES NOT FOUND\u0026#34;)) } Para almacenar los datos elegí usar SQLite a través del paquete R RSQLite. Si no estas familiarizado con las bases de datos SQL te recomiendo que comiences con una búsqueda general en Google y luego regresar a la documentación de SQLite y el paquete R. Elegí SQLite porque necesitaba tener algo ligero y portátil que nos permitiera mover la información fácilmente de un país a otro en lugar de una base de datos centralizada donde pudiéramos almacenar todo, pero se puede aplicar un enfoque muy similar usando otros tipos de bases de datos SQL.\nLa función dbConnect() genera el archivo SQLite si aún no existe. Luego le damos a SQLite la orden de crear la tabla orgs si aún no existe, y la estructura para dicha tabla. A continuación buscamos las coordenadas de las entradas una a una usando coords_from_city() y finalmente lo enviamos a la base de datos. De esa manera podríamos detener el proceso en cualquier momento y continuar más tarde simplemente recuperando la tabla orgs de la base de datos, comparándola con nuestros datos originales y avanzando desde lo que falta. Para eso, la columna ID es fundamental, es la columna que nos permite vincular una entrada entre los datos originales, el data frame de R y la tabla SQL.\nNuestra función también tiene una variable ccount que cuenta cada vez que no se encuentra una entrada. De esa forma, una vez finalizada la consulta, imprimirá la cantidad de entradas que no fueron encontradas. Las razones para no encontrar una entrada pueden ser muchas, entre las más comunes que encontré están las siguientes:\nError en la ortografía del nombre de la ciudad o exceso de información (es decir, valor \u0026ldquo;Praga, Distrito 3\u0026rdquo; cuando el nombre de la ciudad es simplemente \u0026ldquo;Praga\u0026rdquo;). La ortografía incorrecta del nombre del Estado, Región y/o Condado. La ciudad buscada simplemente no está en la base de datos de Open Street Maps (sucedió especialmente para pueblos muy pequeños). Interrupciones de la conexión a internet. Esta es particularmente importante porque, a veces, ejecutar la consulta por segunda o tercera vez encontraría ciudades que no se encontraron la primera vez. Para volver a leer los datos a R desde SQL, simplemente necesitamos hacer una conexión a la base de datos, leer la tabla y cerrar la conexión. La función combine_df_sql se encarga de eso y al mismo tiempo une nuestros datos originales con los datos almacenados en la base de datos por el ID y el nombre de la ciudad. Esto fue importante para el proyecto porque queríamos mantener las coordenadas de las ciudades separadas del resto de la información debido a algunas razones prácticas internas. Pero creo que mantener todos los datos en SQL a la vez puede facilitar muchas cosas. Entre otros, podría identificar cuándo se encontró una ciudad en particular en el pasado y recuperar las coordenadas de la base de datos directamente en lugar de hacer una conexión con nominatim. Lo hice para algunos países y reduce considerablemente el tiempo de consulta. Para la presente publicación, decidí mostrar la versión separada de los datos para brindar más herramientas al lector.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 combine_df_sql \u0026lt;- function(db.file, original.data){ require(dplyr) require(RSQLite) if(is.character(original.data)){ if(grepl(\u0026#39;.csv\u0026#39;, original.data, fixed = T)){ df \u0026lt;- read.csv(original.data) } else{ stop(\u0026#34;Incorrect file format for data\u0026#34;) } } else if(is.data.frame(original.data)){ df \u0026lt;- original.data } else{ stop(\u0026#34;Incorrect data format\u0026#34;) } con \u0026lt;- dbConnect(drv=RSQLite::SQLite(), dbname = db.file) db \u0026lt;- dbReadTable(con, \u0026#34;orgs\u0026#34;) dbDisconnect(con) result \u0026lt;- left_join(df, db, by = c(\u0026#39;ID\u0026#39;, \u0026#39;City\u0026#39;)) return(result) } Otro detalle de nuestra función es la capacidad de leer desde el archivo csv o desde un data.frame. Dado que estábamos trabajando principalmente con archivos csv y usé data frames para los pruebas unitarias, estos 2 formatos fueron suficientes. Siéntanse libres de modificar o ampliar la función para los formatos de datos que puedan necesitarse.\nDatos faltantes Como se mencionó anteriormente, a veces los resultados de la consulta estaban incompletos y era necesaria una segunda o tercera ejecución, pero con menos filas. Algunas otras veces sólo necesitaba parar la consulta y continuar mas tarde desde donde la dejamos. Sin embargo, otras veces los datos estaban incompletos o incorrectos y esto se podía solucionar más tarde con el responsable de los datos. Los 3 escenarios me forzaban a leer el archivo csv a R, luego la tabla de la base de datos y compararlos para filtrar los valores faltantes. Así que creé la función compare_db_data para comparar la base de datos (db) con los datos originales.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 compare_db_data \u0026lt;- function(db.file, dat){ require(dplyr) require(RSQLite) if(is.character(dat)){ if(grepl(\u0026#39;.csv\u0026#39;, dat, fixed = T)){ df \u0026lt;- read.csv(dat) } else{ stop(\u0026#34;Incorrect file format for data\u0026#34;) } } else if(is.data.frame(dat)){ df \u0026lt;- dat } else{ stop(\u0026#34;Incorrect data format\u0026#34;) } con \u0026lt;- dbConnect(drv=RSQLite::SQLite(), dbname = db.file) db \u0026lt;- dbReadTable(con, \u0026#34;orgs\u0026#34;) dbDisconnect(con) filtered \u0026lt;- filter(df, !(as.character(ID) %in% as.character(db$ID))) filtered } Como se mencionó anteriormente, a veces Open Street Maps simplemente no tiene registro de ciertas \u0026ldquo;ciudades\u0026rdquo; (de hecho, sucedió solo con pueblos o poblaciones realmente pequeñas). Para solucionar eso, la función add_coords_manually toma un archivo csv con una estructura particular para agregar los datos que faltan. El archivo csv debe tener las siguientes columnas: - Columna ID nombrada exactamente así y que contiene la misma ID que los datos originales. - Una columna que contiene el nombre de la ciudad - Columnas que contienen la Latitud y Longitud donde queremos señalar la ciudad - Un valor para osm_name. Esto podría dejarse vacío o podemos proporcionar el valor que queremos en esta punto. Lo importante es tener la columna presente en el archivo csv.\nLuego, como en la función anterior, le pasamos a add_coords_manualmente el nombre del archivo csv con la información complementaria, el nombre de la base de datos SQLite y los nombres de las columnas donde tenemos los valores para los nombres de city, osm_name , lat y long, todos con formato de string. El resto de la función es autodescriptiva, siempre que se tengan conocimientos básicos de sintaxis SQL.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 add_coords_manually \u0026lt;- function(csv_file, db.name, city, osm_name, lat, lon){ require(tidyverse) require(RSQLite) csv_dat \u0026lt;- read_csv(csv_file) csv_len \u0026lt;- length(csv_dat$ID) con \u0026lt;- dbConnect(drv=RSQLite::SQLite(), dbname=db.name) for(i in 1:csv_len){ dbSendQuery(con, \u0026#39;INSERT OR IGNORE INTO orgs (ID, City, osm_name, lon, lat) VALUES (?, ?, ?, ?, ?);\u0026#39;, list(csv_dat[[\u0026#39;ID\u0026#39;]][i], csv_dat[[city]][i], csv_dat[[osm_name]][i], csv_dat[[lat]][i], csv_dat[[lon]][i])) } dbDisconnect(con) print(paste(csv_len, \u0026#39;inserted\u0026#39;)) } Siguientes pasos Si eres nuevo en R, probablemente habrás notado que uno de los puntos fuertes de R que estoy usando mucho aquí es el uso de funciones. Los primeros mapas que creamos en el proyecto los hicimos escribiendo scripts con unos pocos cientos de líneas. Eso nos dio la base para crear las funciones necesarias y, por lo tanto, el resto de los mapas fueron posibles usando solo unas pocas líneas. Algunos de los scripts para el web scrapping de las coordenadas constan de menos de 10 líneas de código. Eso es posible usando las funciones anteriores y algunas otras creadas para casos especiales o particulares. No compartiré absolutamente todo, pero quiero dar una idea de cómo hacer que el proceso sea más eficiente. Siempre puedes crear más funciones para tus casos particulares o modificar mis funciones propuestas para adaptarlas a tu situación particular.\nY hablando de extensibilidad, mientras escribía este blog descubrí una librería que no conocía, tmaptools que contiene la función [geocode_OSM](https://www.rdocumentation. org/packages/tmap/versions/1.6-1/topics/geocode_OSM) que usa nominatim para recuperar las coordenadas del punto buscado. La función tiene un formato de búsqueda más fácil de usar y más posibilidades para el valor de retorno, mientras que mi opción coords_from_city() se mantiene bastante rígida y aún con el formato original que se imaginó hace unos años cuando la creé. Si realmente te interesa el tema te invito a revisar el paquete. Yo mismo he estado ocupado manteniendo el código y creando mapas, por lo que tengo muy poco tiempo para hacer mejoras al proyecto original. Pero esa es exactamente mi tarea principal en este momento, así que si hago algún cambio en las funciones presentadas aquí usando el paquete tmaptools, puedes estar seguro de que crearé un breve publicación para compartirlo.\nLuego, una vez que tenemos las coordenadas de nuestras ciudades objetivo y sabemos cómo hacer el mapa básico, el siguiente paso es agregar las ciudades al mapa base. En la próxima publicación, les mostraré cómo lo hice y una función para que el proceso sea más rápido y eficiente.\n","pubDate":"2022-11-04","title":"Mapa de cualquier región del mundo con R - Parte II: obteniendo las coordenadas."},{"link":"http://example.org/posts/2022/comparison_dplyr_vs_base_r/","plain":"A couple of years ago I was interested in the efficiency of R when it comes to time processing and management of memory and I read a few blog posts about this topic, particularly pointing at the fact that R hasn\u0026rsquo;t been designed to be a very efficient language, especially when it comes to big data processing, and this could be its doom at some point in the future. By that time I also read a great article or blog post regarding the complexity of using the tidyverse family of packages in R, especially with the task of teaching R to beginners. The text made excellent points discussing how the syntax of tidyverse packages is so different from the base R functions that it might confuse the people trying to learn R from scratch. Thus, the narration continued towards the use of the packages data.table instead, which maintains a syntax closer to that of base R. And from there, the author also took the opportunity to discuss efficiency of both packages. I apologize for the lack of sources but I could not find the link to the post(s) I\u0026rsquo;m referring to, if any of you knows the post I\u0026rsquo;m talking about please, share the link with me, I\u0026rsquo;d be greatly thankful.\nRegardless of that line of thinking, I believe that we can all feel lucky to have packages such as tidyverse and data.table which make time processing of big data easier, among other advantages. And these are only the beginning to the list of packages. Although I was interested in the topic myself, I never run some \u0026ldquo;formal tests\u0026rdquo; to compare the efficiency of this or other packages (although I was comparing a few languages including Julia, Common Lisp and of course, Python, similarly to niklas-heer in his speed-comparison repo, to whom I also thank for my head image). Nevertheless, in the last couple of weeks I had to do such tests due to the nature of my current job.\nI recently joined a project where the team has been developing a mapper and wrapper of data using R, where the input data can vary from 2 rows to a few millions. The whole process runs through couple of servers to import the data into R, process it accordingly and send it out to a data base from where is served into some other software. The whole process per-se is quite complex and due to the use of servers and Internet connections it can become quite slow. Thus, it is critical that the time processing in R is efficient.\nAs mentioned before, a team has been working on this project for a while and they were using the tidyverse family of packages a lot. Myself I prefer to stick to base R functions when it comes to development. I think it makes the work neat, simple and easier, keeps the dependencies to the minimum and, since I know R for more than 10 years, it\u0026rsquo;s easier for me to write code in base R. And please, don\u0026rsquo;t misunderstand me, I like the tidyverse functions but I rather use them when it comes to data analysis: it is great to clean data, prepare it to fit models, explore it, and of course, to make visualizations with the wonderful ggplot preceded by the %\u0026gt;% sequence to provide exactly what is needed. But for me, developing a software in base R is just more straight forward.\nHowever, as I said, efficiency is critical in this project and thus, I\u0026rsquo;ve been tasked to test it in a few functions already. The most recent was a function to import JSON files line by line using dplyr functions which I could reduce by half the time using data.table functions, but that\u0026rsquo;s a topic for another time. One of the first tasks I was given as a new member was to map a process, very similar to another one but with different input parameters. I could had simply copied the code from the previous mapping process into my own script and just change the parameters, since the mapping logic is exactly the same. However, I decided to create my own code using base R, trusting that is more straight forward and efficient, and at the same time taking the opportunity to show up my skills to my new team. Therefore, I ended up comparing the efficiency of the functions using Monte Carlo simulations and thus, creating the present post. I hope it can be useful for some of you.\nImage 1. Credits - https://github.com/niklas-heer/speed-comparison The task The general idea is to map a RESPONSE based on the contents of one column, in this case CODE1: all values get the response \u0026ldquo;BATCH\u0026rdquo;, but only when CODE1 is empty, they also get the response \u0026ldquo;GETTING\u0026rdquo;. Rows with value \u0026ldquo;BATCH\u0026rdquo; get renamed the columns NAME, DAY and TIME into TEAM, RESPONSETD and RESPONSESTT respectively, while rows with response \u0026ldquo;GETTING\u0026rdquo; only get one more column: NAME into newly named column TEAM.\n1 2 3 4 (test.df \u0026lt;- data.frame(NAME = as.character(c(1:10)), DAY = format(Sys.time(), \u0026#34;%d-%m-%y\u0026#34;), TIME = format(Sys.time(), \u0026#34;%T\u0026#34;), CODE1 = c(\u0026#34;Code\u0026#34;, NA))) \u0026gt; NAME DAY TIME CODE1 \u0026gt; 1 1 20-10-22 18:37:23 Code \u0026gt; 2 2 20-10-22 18:37:23 \u0026lt;NA\u0026gt; \u0026gt; 3 3 20-10-22 18:37:23 Code \u0026gt; 4 4 20-10-22 18:37:23 \u0026lt;NA\u0026gt; \u0026gt; 5 5 20-10-22 18:37:23 Code \u0026gt; 6 6 20-10-22 18:37:23 \u0026lt;NA\u0026gt; \u0026gt; 7 7 20-10-22 18:37:23 Code \u0026gt; 8 8 20-10-22 18:37:23 \u0026lt;NA\u0026gt; \u0026gt; 9 9 20-10-22 18:37:23 Code \u0026gt; 10 10 20-10-22 18:37:23 \u0026lt;NA\u0026gt; The whole general idea is to create a new table with response values, which follows and is followed by a series of adjustments to the data. For the post I have created a test data frame with simple values, in case somebody would like to reproduce the code execution.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 rename_nCols \u0026lt;- function(samples, cols_to_rename, rename = FALSE, ignore_missing = TRUE){ for(i in 1:length(cols_to_rename)){ old_name \u0026lt;- cols_to_rename[[i]][1] ## Old in position 1 of vector SYS_name \u0026lt;- cols_to_rename[[i]][2] ## New in position 2 of vector ## WHEN NOT PRESENT if(!old_name %in% names(samples)) { warning(paste(\u0026#34;Column\u0026#34;, old_name, \u0026#34;not found.\u0026#34;)) if(!ignore_missing){ samples[,SYS_name] \u0026lt;- as.character(NA) } } ## RENAMING else if(rename){ names(samples)[names(samples) == old_name] \u0026lt;- SYS_name } ## ADDING else { samples[,SYS_name] \u0026lt;- samples[,old_name] } } return(samples) } create_cols_base \u0026lt;- function(samples){ require(dplyr) ## First BATCH assay \u0026lt;- cbind(samples, RESPONSE = \u0026#34;BATCH\u0026#34;) cols_to_rename \u0026lt;- list(c(\u0026#39;NAME\u0026#39;, \u0026#39;TEAM\u0026#39;), c(\u0026#39;DAY\u0026#39;, \u0026#39;RESPONSETD\u0026#39;), c(\u0026#39;TIME\u0026#39;, \u0026#39;RESPONSESTT\u0026#39;)) assay \u0026lt;- rename_nCols(assay, cols_to_rename) ## then GETTING if(\u0026#34;CODE1\u0026#34; %in% names(samples)){ if(nrow(samples[is.na(samples$CODE1),]) != 0){ receiving \u0026lt;- cbind(samples[is.na(samples$CODE1),], RESPONSE = \u0026#34;GETTING\u0026#34;) } else receiving \u0026lt;- samples[is.na(samples$CODE1),] } else{ receiving \u0026lt;- cbind(samples, RESPONSE = \u0026#34;GETTING\u0026#34;) } receiving \u0026lt;- rename_nCols(receiving, list(c(\u0026#39;NAME\u0026#39;, \u0026#39;TEAM\u0026#39;))) responses \u0026lt;- full_join(assay, receiving) return(responses) } My strategy using base R (function create_cols_base()) was to create two data frames, one per each response, and then join them using full_join() from dplyr. I want to stress that the idea was never to use only base R but rather to follow my own logic and my knowledge of R and then compare it with that of my colleagues. To support my create_cols_base() I created a function rename_nCols which is a great asset to the project since we are constantly renaming columns or creating new ones based on old ones.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 create_cols_tidy \u0026lt;- function(samples, responsesToCreate = c(\u0026#34;BATCH\u0026#34;, \u0026#34;GETTING\u0026#34;)){ require(dplyr) require(tidyr) responses \u0026lt;- samples %\u0026gt;% mutate( RESPONSE = case_when( is.na(get0(\u0026#39;CODE1\u0026#39;, ifnotfound = as.character(NA))) | get0(\u0026#39;CODE1\u0026#39;, ifnotfound = as.character(NA)) == \u0026#34;\u0026#34; ~ list(Reduce(intersect,list(responsesToCreate,c(\u0026#34;BATCH\u0026#34;, \u0026#34;GETTING\u0026#34;)))), TRUE ~ list(Reduce(intersect,list(responsesToCreate,c(\u0026#34;BATCH\u0026#34;)))) ) ) %\u0026gt;% unnest(cols = c(RESPONSE))%\u0026gt;% subset(!is.na(RESPONSE)) %\u0026gt;% mutate(TEAM = get0(\u0026#39;NAME\u0026#39;, ifnotfound = as.character(NA)), RESPONSESTD = case_when( (RESPONSE == \u0026#34;BATCH\u0026#34;) ~ get0(\u0026#39;DAY\u0026#39;, ifnotfound = as.character(NA)), TRUE ~ as.character(NA)), RESPONSESTTM = case_when( (RESPONSE == \u0026#34;BATCH\u0026#34;) ~ get0(\u0026#39;TIME\u0026#39;, ifnotfound = as.character(NA)), TRUE ~ as.character(NA))) return(responses) } As you can see in the code chunk above, my colleagues decided to use a completely different approach, with the function case_when() as the protagonist. An excellent call in my opinion, but one I\u0026rsquo;m not so familiar with in R. They also made use of the strength of mutate() to reduce generation of excessive data frames, as it was my case.\nThe test Image 2. Results of the comparisons using Monte Carlo Simulations. Strong lines represent the median, long and short dotted lines the maximum and minimum values, respectively. To test the time efficiency of each function I iterated each of them a thousand times using datasets of different sizes, going from 1 thousand to 5 million, measuring the time at the beginning and end of the mapping process, and extracting the difference. The graphics presented here are the Minimum, Maximum and Median values of the thousand repetitions per each function. You can see the amount of rows in the data frame plotted against the time that each function took, in seconds.\nThe results, as expected, show a direct correlation between time and amount of rows processed. What is interesting is that up to one million rows, the increase is very slow and the difference between methods is almost not noticeable. In the image 3 we can see that differences are smaller than 1 second. However, as the amount of rows increases above a million, the differences between methods are bigger, to a point where they even double the time.\nImage 3. Results of the comparisons up to a million rows Strong lines represent the median, long and short dotted lines the maximum and minimum values, respectively. Conclusions We are not using datasets above 5 million rows in the project, and even rarely above a million so, we can afford the process to take up to 12 seconds from time to time. However, there was a nice lesson to learn, especially for me: my method using base r functions is twice as slow than a method using tidyverse group of functions. That shows the commitment of R studio of making not only more human-readable functions, but also more efficient.\nThis is also true for a series of new packages appearing in the last years that are helping R to cope better with big data. As I mentioned at the beginning of my post, I consider myself lucky to see how R is evolving and adapting to the challenges of our times when we have the needs to process big amounts of data relatively fast. Rather than see its slow time processing as its future doom, I see it as the potential where developers are focusing to create packages that can make our job easier and be up to the challenge. And for that, I thank them!.\n","pubDate":"2022-10-20","title":"Efficiency comparison of dplyr and tidyr functions vs base R"},{"link":"http://example.org/posts/2022/map_any_region_with_ggplot2_part_i/","plain":"You can find all the posts on this series under the tag maps-app.\nYou can also find the current state of the project under my GitHub repo mapic (including the Spanish versions).\nScope of this post When you prepare for a job interview one of the questions they always tell you to prepare is \u0026ldquo;What are you most proud of?\u0026rdquo;. Personally I\u0026rsquo;ve never been asked that question in a job interview but it kept me thinking. Some years ago I developed the R code for the creation of maps of infrastructure for a Political Sciences project, and I can say that this is one of the projects I\u0026rsquo;m most proud of. However, it is also true what they say to developers, that nobody cares about how you did it. The final user only cared about what was done, while the research team about what are the possibilities.\nThe project taught me so much in terms of technical skills that I have decided to share the how in case it can help somebody else. It is also my way to contribute to the R community since I myself learned R and programming thanks to the kind people who post their experience on the web (and to the ones who have the patience to answer questions in StackOverflow too). Due to the confidentiality agreement of the client, I also cannot share a git repository.\nWe created maps of data showing changes over a span of time for different countries and pointing at all kinds of cities. That basically means that we need to map any region of the world with R. Today there are all kinds of packages and techniques to do that. I will share the strategy I used with ggplot2 and maps packages, using support of Open Street Map to obtain the coordinates of cities and finally making it interactive with shiny.\nThe project itself is quite long for a single post, and just recently I managed to extract the base code I created and make it public, without compromising any privacy issues. On the other hand, it is a live project that I am currently working on. Therefore, I decided to share my path and experiences along the creation process of the Shiny app. The posts are not only about the Shiny app, but the package I created behind it. I will touch topics of functions crafting, creation of the maps, classes of objects, etc., as well as any interesting issue that appear on the way. It is my way to contribute to the R community and at the same time keeping the project documented for myself.\nThis first post is asbout the creation of The basic map\nI hope you all enjoy it. Feel free to leave any kind of comment and/or question at the end.\nBackground When I joined the team all what they knew is that the wanted to make maps of infrastructure (say hospitals, cafes, churches, public offices, etc., but the project can basically be applied to anything countable per city). The maps should change in time according to the data (usually growth) and it should be possible to apply it for any country and thus, any kind of city of that particular country can be listed there. This last point represents a challenge because to make a map you need the coordinates of a particular point to map, but instead we got address in the best scenario, or only city name in the worst. Therefore, we left it to the level of city and decided to work with that.\nMost R packages to make maps have granularity up to some regions and major cities per country, and we are talking about countries where somebody has develop some R package for that. However, even the best packages would miss some cities or some countries some times. We needed to standardize everything without the need of changing packages according to the particular country. Before I joined, the team attempted to use Google Maps and excel, but the amount of data became messy and the flexibility to edit the maps was pretty limited. And they didn\u0026rsquo;t want to add copyright issues to the list of limitations. Therefore I proposed to use R. Of course, nobody in the team had ever heard about it before. We could had used any other tool, I learned that both, Python and JavaScript have some decent possibilities. But R is what I have been using for the last 10 years and is what I wanted to use for this project. And so I started to code.\nThe first couple of maps were custom code for a particular country with decent styles. But it quickly evolved into a set of functions and arguments to maintain the same standards for each map. The support of graphic designers also took the styles to a very professional level. After a few months we had very professional maps that could be done in couple of hrs (or less) with a couple of lines of code. Each map per each country with the desired span of years to be printed.\nI don\u0026rsquo;t think I will share every single detail of it, but at least I want to show how we went from the basic map to its dynamic form mapping over a span of time, and how I wrapped it all together in a couple of functions to make it quickly replicable for any given data set. Let me know what you think.\nHow to create a map of any country in R using the library maps The first step is to create the basic map of a country. Here is the function to achieve exactly that.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 library(maps) library(ggplot2) ## make a df with only the country to overlap map_data_es \u0026lt;- map_data(\u0026#39;world\u0026#39;)[map_data(\u0026#39;world\u0026#39;)$region == \u0026#34;Spain\u0026#34;,] ## The map (maps + ggplot2 ) ggplot() + ## First layer: worldwide map geom_polygon(data = map_data(\u0026#34;world\u0026#34;), aes(x=long, y=lat, group = group), color = \u0026#39;#9c9c9c\u0026#39;, fill = \u0026#39;#f3f3f3\u0026#39;) + ## Second layer: Country map geom_polygon(data = map_data_es, aes(x=long, y=lat, group = group), color = \u0026#39;red\u0026#39;, fill = \u0026#39;pink\u0026#39;) + coord_map() + coord_fixed(1.3, xlim = c(-13.5, 8.5), ylim = c(34, 45)) + ggtitle(\u0026#34;A map of Spain\u0026#34;) + theme(panel.background =element_rect(fill = \u0026#39;blue\u0026#39;)) We are using the library maps in combination with ggplot2. The maps package contains coordinates system for a map of the whole world separated by countries (although political borders might not be fully up to date). It can as well do the maps, but for that we are making use of ggplot2 support here.\nWe start by extracting the data relevant to the country we want to map, in this case Spain. It is of course important to pass the name of the country in the same way that it is written in map_data('world')$region. You can use the function unique() to find the exact names of all the countries included in the packages (unique(map_data('world')$region) gives 252 countries at the moment of writing this post).\nOnce we have the data for the one particular country, we could simply map it directly using geom_polygon() however, that would map Spain surrounded by empty space around it. To place it in the context of its neighborhood, we apply two layers of geom_polygon(): first one with the map of the whole world and secondly the map of the country only.\nThen we need to tell ggplot to use a coordinates system to create maps instead of just polygons. For that we use coord_map() function and then we pass the details of the map ratio, and limits in X and Y to the function coord_fixed().\nUp to here we can have our map. ggplot is basically plotting what we are specifying inside the coordinates system, everything around it (the oceans) will be just empty and it will be filled in by the default grids and gray colors of ggplot(). Thus, we need to define the color of the Oceans as the background color for the whole plot. That\u0026rsquo;s what the last line of code does.\nOf course there are a lot of improvements to do. So far I have given exaggerated colors to make obvious for the reader which piece of code controls what. In that sense you can see that you can simply pass the names of the colors, which applies the defaults, or you can be more specific and provide the html notation of the color (i.e., '#9c9c9c'). So, let\u0026rsquo;s now improve the visuals and at the same time create a function to plot any country we want to.\nFunction to create the basic map in R 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 map_country \u0026lt;- function(country, x_limits = NULL, y_limits = NULL){ ## Verifying the arguments passed to the function if(!is.character(country)) stop(\u0026#34;Name of the country should be character\u0026#34;) if(length(country) != 1) stop(\u0026#34;Function supports only one country per map\u0026#34;) ## Load libraries require(maps) require(ggplot2) if(!country %in% map_data(\u0026#39;world\u0026#39;)$region) stop(\u0026#39;Country name not recognized\\nTo see a list of recognized countries run \u0026lt;unique(maps::map_data(\u0026#34;world\u0026#34;)$region)\u0026gt;\u0026#39;) ## If coords limits missing, print worldwide map with coordinates system to allow ## User observe coords for reference if(missing(x_limits) || missing(y_limits)) { warning(\u0026#34;X and/or Y limits not provided.\\nPrinting worldwide map.\u0026#34;) map_country_theme \u0026lt;- theme(panel.background = element_rect(fill = \u0026#39;#4e91d2\u0026#39;)) } else { if(length(x_limits) != 2 || length(y_limits) != 2 || !all(grepl(\u0026#39;^-?[0-9.]+$\u0026#39;, c(x_limits, y_limits)))){ stop(\u0026#34;Limits for X and Y coords should be provided as vectors with two numeric values\u0026#34;) } else { ## All the received inputs are correct. ## Let\u0026#39;s define our custom theme for the final map map_country_theme \u0026lt;- theme_bw() + theme(panel.background = element_rect(fill = \u0026#39;#4e91d2\u0026#39;), legend.position = \u0026#39;none\u0026#39;, panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = \u0026#34;black\u0026#34;), axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) } } ## make a df with only the country to overlap map_data_country \u0026lt;- map_data(\u0026#39;world\u0026#39;)[map_data(\u0026#39;world\u0026#39;)$region == country,] ## The map (maps + ggplot2 ) ggplot() + ## First layer: worldwide map geom_polygon(data = map_data(\u0026#34;world\u0026#34;), aes(x=long, y=lat, group = group), color = \u0026#39;#9c9c9c\u0026#39;, fill = \u0026#39;#f3f3f3\u0026#39;) + ## Second layer: Country map geom_polygon(data = map_data_country, aes(x=long, y=lat, group = group), color = \u0026#39;#4d696e\u0026#39;, fill = \u0026#39;#8caeb4\u0026#39;) + coord_map() + coord_fixed(1.3, xlim = x_limits, ylim = y_limits) + ggtitle(paste0(\u0026#34;A map of \u0026#34;, country)) + scale_x_continuous(n.breaks = 20) + scale_y_continuous(n.breaks = 20) + map_country_theme } ## Test the function with a different country map_country(\u0026#34;Germany\u0026#34;, c(-2, 22), c(47, 55)) Although the function might seem complicated at first, it is in fact the same code as we used to create the map, but instead of typing directly the name of the country or the limits for X and Y, we replace them with the arguments country, x_limits and y_limits respectively; in that way all the parts were we had the string \u0026quot;Spain\u0026quot; we now have the argument country, and so on. These are the only arguments that we need to change when we want to map a different country. You can define more arguments in case you want to have more possibilities to be editable, for example, we could define an argument country_color to specify the color we want for the target country. In our case we wanted to keep the same standards for all the maps due to branding reasons and thus, we rather wanted to have the exact same colors and styles for all of our maps.\nThere are also some additions on the top before the actual code to make the maps, all the if and else statements that are simply used to validate that the information passed by the user is the info that we actually need to make the function work. If any incorrect argument is passed to the function, we stop the process and write a message of what is wrong using the function stop(). For the case that no limits of either X or Y are defined, I send a warning message using warning(). In that case the process continues but we define a theme() that allows the user to see the country in the context of the worldwide map, with excess of values in the X and Y axes to provide the points of reference and give an idea of where to set the limits. By the end, when we ensure that all the values are fine, we define the final theme that we actually want to apply. About that, probably I should make special mention of !all(grepl('^-?[0-9.]+$', c(x_limits, y_limits)))): it is used to ensure that X and Y limits are of type numeric. See the visualization of the code below together with the help of the function(s) you don\u0026rsquo;t understand for a more detail explanation. Feel free to test the errors and warnings by providing to the function no country names or letters where there should be numbers, etc.\nThe lower part of the function is exactly the same as our first map, replacing the actual values for the arguments. We also have changed the colors for more specific ones. Almost by the end of the function we have added scale_x_continuous(n.breaks = 20) which will add 20 marks of the X axis scale (same for Y). We want to use it to ensure that, in case the user doesn\u0026rsquo;t have idea of which limit values to choose, it can have a good approach regarding the position of the target country. In case that both limits for X and Y are passed to the function, our other theme will mask this 20 breaks with axis.text.x = element_blank() and axis.ticks.x = element_blank().\nThe final line is the test that our function can plot a map other than Spain, in this case I chose Germany. We can basically choose any country included in the maps package and now make the map with the same standards in one line of R code.\nFinal remarks Here I am somehow showing one of the methods I use to create functions: I basically write first the code of what I want to achieve and once it does exactly what I want, I wrap it in a function, replacing the arguments that the user will need to modify later. Then I think what could go wrong and create the corresponding warnings an errors. It is a good practice to do that not only for the user to know better how to use the function, but also for yourself, it proves very useful when we need to debug code. Another good practice in R functions is the call to the libraries inside the function using require(). Even if you are writing many functions that use the same libraries, is good to repeat it on each function, or per script, to make it self contained and again, help yourself in the debugging process. Not long ago I started collaborating in a project where there was no call to the libraries per function, but rather only at the top level when the main action of the program was called. This made almost impossible for me to test and debug code so, the first activity I did as a new member of the team was to spend 2 full working days adding require() where necessary.\nI hope you get some fun mapping different countries. Because different countries have different sizes and shapes, one way to improve the visuals related to this is by adjusting the ratio, for example, my own map of Germany looks out of shape, but it improves considerably if instead of 1.3 we give a ratio of 1.4, check the documentation to learn more about it.\nOnce that we have the basic map, we could add the cities were we want to add data values. Unfortunately, for cities there are many limitations, specially for countries where no special packages has been created to be mapped, and even there, most packages of particular countries don\u0026rsquo;t contain all the cities, especially minor ones. Thus, in our second part I will show how I tackled this problem doing some web scrapping to open street maps.\n","pubDate":"2022-10-08","title":"Map any region in the world with R - Part I: The basic map"},{"link":"http://example.org/es/posts/2022/mapa_de_cualquier_region_con_ggplot2_i/","plain":"Pueden encontrar todas las publicaciones en este tema bajo la etiqueta maps-app (incluyendo las versiones en inglés).\nTambién pueden encontrar el estado actual del proyecto en mi GitHub repo mapic.\nSobre esta entrada Cuando nos preparamos para una entrevista de trabajo, una de las preguntas que más recomiendan preparar es \u0026ldquo;Menciona el proyecto del que estés más orgulloso?\u0026rdquo;. Personalmente nunca me han hecho esa pregunta en una entrevista de trabajo pero me mantuvo pensando. Hace algunos años desarrollé el código en R para la creación de mapas de infraestructura para un proyecto de Ciencias Políticas, y puedo decir que este es uno de los proyectos de los que estoy más orgulloso. Sin embargo, también es cierto lo que comúnmente se dice entre los desarrolladores, que a nadie le importa cómo lo hiciste. Al usuario final solo le interesa el producto final y cómo utilizarlo, mientras que al equipo de investigación le interesa saber las posibilidades que propone.\nEl proyecto me enseñó tanto en términos de habilidades técnicas que he decidido compartir el cómo en caso de que pueda ayudar a alguien más. También es mi forma de contribuir a la comunidad de R, ya que yo mismo aprendí R y programación gracias a las amables personas que publican su experiencia en la web (y también a los que tienen la paciencia de responder preguntas en StackOverflow). Debido al acuerdo de confidencialidad con mi cliente no puedo compartir el código completo o el repositorio de Git.\nCreamos mapas de datos que muestran los cambios durante un período de tiempo para diferentes países y orientados a todo tipo de ciudades. Esto básicamente significa que necesitamos mapear cualquier región del mundo con R. Hoy en día existen todo tipo de paquetes y técnicas para hacerlo. Compartiré la estrategia que utilicé con ggplot2 y maps, utilizando el soporte de Open Street Map para obtener las coordenadas de las ciudades y finalmente hacerlo interactivo con shiny.\nEl proyecto es bastante largo para una sola publicación. Por otro lado, recientemente logré extraer el código base y hacerlo público sin comprometer la privacidad. También es un proyecto vivo en el que estoy trabajando actualmente. Por lo que decidí compartir mis experiencias durante el proceso de creación de la aplicación Shiny. Estas publicaciones no son sólo acerca de Shiny apps, si no más bien sobre la creación del paquete detrás. Tocaré temas sobre la generación de funciones, creación de los mapas, clases de objetos, entre otros, incluyendo cualquier tema interesante que aparezca en el camino. Es mi manera de contribuir a la comunidad de R y al mismo tiempo documentar el proyecto en si mismo.\nEspero que lo disfruten. Siéntanse libres de dejar cualquier tipo de comentario y/o preguntas al final.\nMotivación Cuando me uní al equipo, todo lo que sabían era que querían hacer mapas de infraestructura (por ejemplo hospitales, cafés, iglesias, oficinas públicas, etc., pero el proyecto básicamente se puede aplicar a cualquier cosa contable en una ciudad dada). Los mapas deben cambiar en el tiempo de acuerdo con los datos (generalmente crecimiento) y debe ser posible aplicarlo para cualquier país y, por lo tanto, cualquier tipo de ciudad en dicho país. Este último punto representa un desafío porque para hacer un mapa se necesitan las coordenadas del punto en particular para mapear, pero en cambio obtuvimos las dirección postales en el mejor escenario, o solo el nombre de la ciudad en el peor. Por lo tanto, lo dejamos a nivel de ciudad y decidimos trabajar con eso.\nLa mayoría de los paquetes de R para hacer mapas tienen granularidad hasta algunas regiones y ciudades importantes por país, y estamos hablando de países donde alguien ha desarrollado algún paquete de R para eso. Sin embargo, incluso a los mejores paquetes les faltan algunas ciudades en sus datos. Necesitábamos estandarizar todo sin necesidad de cambiar paquetes por país. Antes de unirme, el equipo intentaron usar Google Maps y Microsoft Excel, pero la cantidad de datos se volvió desastrosa y la flexibilidad para editar los mapas era bastante limitada. Además no querían agregar problemas de derechos de autor o copyright a la lista de limitaciones. Por lo tanto, propuse usar R. Por supuesto, nadie en el equipo había oído hablar de él antes. Podríamos haber usado cualquier otra herramienta, aprendí que tanto Python como JavaScript tienen algunas posibilidades decentes. Pero R es lo que he estado usando durante los últimos 10 años y es lo que quería utilizar para este proyecto. Y así comencé a escribir código.\nLos primeros mapas eran códigos personalizados para un país en particular con estilos decentes. Pero rápidamente se convirtió en un conjunto de funciones y argumentos para mantener los mismos estándares para cada mapa. El apoyo de los diseñadores gráficos también llevó los estilos a un nivel muy profesional. Después de unos meses teníamos mapas muy profesionales que se podían hacer en un par de horas (o menos) con un par de líneas de código. Cada mapa por cada país con el lapso de años deseado para ser impreso.\nNo puedo compartir cada uno de los detalles, pero al menos quiero mostrar cómo pasamos del mapa básico a su forma dinámica de mapeo durante un período de tiempo, y cómo lo envolví todo en un par de funciones para que sea rápidamente replicable para cualquier conjunto de datos dado. Siéntanse libres de compartir su opinión.\nCómo crear un mapa de cualquier país en R usando la librería maps El primer paso es crear el mapa básico de un país. Aquí está la función para lograr exactamente eso.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 library(maps) library(ggplot2) ## hacer un df con sólo pais para traslapar map_data_es \u0026lt;- map_data(\u0026#39;world\u0026#39;)[map_data(\u0026#39;world\u0026#39;)$region == \u0026#34;Spain\u0026#34;,] ## El mapa (maps + ggplot2 ) ggplot() + ## Primera capa: mapa del mundo geom_polygon(data = map_data(\u0026#34;world\u0026#34;), aes(x=long, y=lat, group = group), color = \u0026#39;#9c9c9c\u0026#39;, fill = \u0026#39;#f3f3f3\u0026#39;) + ## Segunda capa: mapa del país geom_polygon(data = map_data_es, aes(x=long, y=lat, group = group), color = \u0026#39;red\u0026#39;, fill = \u0026#39;pink\u0026#39;) + coord_map() + coord_fixed(1.3, xlim = c(-13.5, 8.5), ylim = c(34, 45)) + ggtitle(\u0026#34;A map of Spain\u0026#34;) + theme(panel.background =element_rect(fill = \u0026#39;blue\u0026#39;)) Utilizamos la librería maps en combinación con [ggplot2](https://cran.r-project.org/ web/packages/ggplot2/index.html). El paquete maps contiene un sistema de coordenadas para un mapa de todo el mundo separado por países (aunque es posible que las fronteras políticas no estén totalmente actualizadas). También puede hacer los mapas, pero para eso decidí hacer uso del soporte ggplot2.\nEmpezamos extrayendo los datos relevantes del país que queremos mapear, en este caso España. Por supuesto, es importante pasar el nombre del país de la misma manera que está escrito en map_data('world')$region. Puedes usar la función unique() para encontrar los nombres exactos de todos los países incluidos en los paquetes (si ejecutas unique(map_data('world')$region) da 252 países al momento de escribir esta publicación).\nUna vez que tengamos los datos para un país en particular, podríamos simplemente mapearlo directamente usando geom_polygon() sin embargo, eso mapearía a España rodeada por un espacio vacío a su alrededor. Para ubicarlo en el contexto de su vecindario, aplicamos dos capas de geom_polygon(): la primera con el mapa de todo el mundo y la segunda con el mapa del país únicamente.\nLuego necesitamos decirle a ggplot que use un sistema de coordenadas para crear mapas en lugar de sólo polígonos. Para eso usamos la función coord_map() y luego pasamos los detalles de la proporción del mapa y los límites en X e Y a la función coord_fixed( ).\nHasta aquí podemos obtener nuestro mapa. ggplot está básicamente trazando lo que estamos especificando dentro del sistema de coordenadas, todo a su alrededor (los océanos) estará vacío y el gráfico será completado con las cuadrículas predeterminadas y los colores grises de ggplot(). Por lo tanto, necesitamos definir el color de los océanos como color de fondo para todo el gráfico. Eso es lo que hace la última línea de código.\nPor supuesto, hay muchas mejoras que hacer aún. Hasta ahora he dado colores exagerados para que el lector sepa qué fragmento de código controla qué. En ese sentido, puedes notar que se puede simplemente pasar los nombres de los colores, lo cual aplica los valores predeterminados, o se puede ser más específico y proporcionar la notación html del color (es decir, '#9c9c9c'). Con esto podemos ahora mejorar las imágenes y al mismo tiempo crear una función para trazar cualquier país que queramos.\nFunción para crear el mapa básico en R 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 map_country \u0026lt;- function(country, x_limits = NULL, y_limits = NULL){ ## Verificar los argumentos tomados por la función if(!is.character(country)) stop(\u0026#34;Nombre del país debe ser de tipo string\u0026#34;) if(length(country) != 1) stop(\u0026#34;La función soporta sólo un país por mapa\u0026#34;) ## Cargar las librerías require(maps) require(ggplot2) if(!country %in% map_data(\u0026#39;world\u0026#39;)$region) stop(\u0026#39;Nombre del país no reconocido\\nPara ver una lista de paises reconocidos ejecute \u0026lt;unique(maps::map_data(\u0026#34;world\u0026#34;)$region)\u0026gt;\u0026#39;) ## Si no se proporcionaron los limites de las coordenadas, imprime el mapa mundial if(missing(x_limits) || missing(y_limits)) { warning(\u0026#34;Límites de X y/o Y no han sido encontrados.\\nImprimiendo el mapa mundial\u0026#34;) map_country_theme \u0026lt;- theme(panel.background = element_rect(fill = \u0026#39;#4e91d2\u0026#39;)) } else { if(length(x_limits) != 2 || length(y_limits) != 2 || !all(grepl(\u0026#39;^-?[0-9.]+$\u0026#39;, c(x_limits, y_limits)))){ stop(\u0026#34;Los límites de las coordenadas X y Y deben ser ingresadas como vectores con dos valores numéricos\u0026#34;) } else { ## Definiendo el tema seleccionado para el mapa final map_country_theme \u0026lt;- theme_bw() + theme(panel.background = element_rect(fill = \u0026#39;#4e91d2\u0026#39;), legend.position = \u0026#39;none\u0026#39;, panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = \u0026#34;black\u0026#34;), axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank()) } } ## Un df con el pais a agregar únicamente map_data_country \u0026lt;- map_data(\u0026#39;world\u0026#39;)[map_data(\u0026#39;world\u0026#39;)$region == country,] ## El mapa (maps + ggplot2 ) ggplot() + ## Primera capa: mapa mundial geom_polygon(data = map_data(\u0026#34;world\u0026#34;), aes(x=long, y=lat, group = group), color = \u0026#39;#9c9c9c\u0026#39;, fill = \u0026#39;#f3f3f3\u0026#39;) + ## Segunda capa: mapa del país geom_polygon(data = map_data_country, aes(x=long, y=lat, group = group), color = \u0026#39;#4d696e\u0026#39;, fill = \u0026#39;#8caeb4\u0026#39;) + coord_map() + coord_fixed(1.3, xlim = x_limits, ylim = y_limits) + ggtitle(paste0(\u0026#34;A map of \u0026#34;, country)) + scale_x_continuous(n.breaks = 20) + scale_y_continuous(n.breaks = 20) + map_country_theme } ## Probando la función con un país diferente map_country(\u0026#34;Germany\u0026#34;, c(-2, 22), c(47, 55)) Aunque la función puede parecer complicada al principio, de hecho es el mismo código que usamos para crear el mapa en un principio, pero en lugar de escribir directamente el nombre del país o los límites para X o Y, los reemplazamos con los argumentos país , x_limits y y_limits respectivamente; de esa manera todas las partes donde teníamos el string \u0026quot;España\u0026quot; ahora tenemos el argumento país, y así sucesivamente. Ahora estos son los únicos argumentos que necesitamos cambiar cuando queremos mapear un país diferente. Puedes definir más argumentos en caso de que quieras tener más posibilidades de ser editable, por ejemplo, podríamos definir un argumento country_color para especificar el color que queremos para el país de destino. En nuestro caso, queríamos mantener los mismos estándares para todos los mapas por motivos de control de calidad, por lo tanto, queríamos tener exactamente los mismos colores y estilos para todos nuestros mapas.\nTambién hay algunas adiciones en la parte superior antes del código inicial para hacer los mapas: son una serie de declaraciones if y else que simplemente se usan para validar que la información ingresada por el usuario es la información que realmente necesita la función para hacer su trabajo. Si se ingresa algún argumento incorrecto a la función, detenemos el proceso y escribimos un mensaje de lo que está mal utilizando la función stop(). Para el caso de que no se definan límites de X o Y, se envía un mensaje de advertencia usando warning(). En ese caso el proceso continúa pero definimos un theme() que permite al usuario ver el país en el contexto del mapa mundial, con exceso de valores en los ejes X e Y para proporcionar los puntos de referencia y dar un idea de dónde poner los límites. Al final, cuando nos aseguramos de que todos los valores estén bien, definimos el tema final que realmente queremos aplicar. A este respecto debería hacer una mención especial sobre !all(grepl('^-?[0-9.]+$', c(x_limits, y_limits)))): se usa para asegurar que tanto los valores de X como Y son de tipo numérico. Puedes ver la visualización del código a continuación junto con la ayuda de las funciones que no comprendes para obtener una explicación más detallada. Siéntete libre de probar los errores y advertencias proporcionando a la función nombres de países o letras donde debería haber números, etc.\nLa parte inferior de la función es exactamente igual a nuestro primer mapa, reemplazando los valores reales con los argumentos. También hemos cambiado los colores por unos más específicos. Casi al final de la función hemos agregado scale_x_continuous(n.breaks = 20) que agrega 20 marcas en la escala del eje X (y después, lo mismo para Y). Usamos esto para asegurarnos de que, en caso de que el usuario no tenga idea de qué valores límite elegir, pueda tener un buen enfoque con respecto a la posición del país objetivo. En caso de que ambos límites para X e Y se ingresen a la función, nuestro otro tema enmascarará estas 20 marcas con axis.text.x = element_blank() y axis.ticks.x = element_blank().\nLa línea final es la prueba de que nuestra función puede trazar un mapa que no sea España, en este caso elegí Alemania. Básicamente, podemos elegir cualquier país incluido en el paquete maps y entonces hacer el mapa con los mismos estándares en tan sólo una línea de código de R.\nObservaciones finales He querido mostrar aquí uno de los métodos que utilizo para crear funciones: básicamente escribo primero el código de lo que quiero lograr y, una vez que hace exactamente lo que quiero, lo envuelvo en una función, reemplazando valores por los argumentos que el usuario necesitará modificar más adelante. Luego pienso en qué podría salir mal y genero las advertencias y errores correspondientes. Es una buena práctica hacer eso no solo para que el usuario sepa mejor cómo usar la función, sino también para uno mismo, pues resulta muy útil cuando necesitamos depurar el código. Otra buena práctica en las funciones de R es la llamada a las librerías dentro de la función usando require(). Incluso si se están escribiendo muchas funciones que usan las mismas bibliotecas, es bueno repetirlo en cada función, o al menos por script, para que se mantenga independiente y, nuevamente, nos ayude en el proceso de debug. No hace mucho comencé a colaborar en un proyecto donde no hacían la llamada a los paquetes de R por cada función, sino solo en el nivel superior cuando se llamaba al proceso principal del programa. Esto me hizo casi imposible probar y depurar el código, así que la primera actividad que hice como nuevo miembro del equipo fue pasar 2 días completos agregando require() donde fuera necesario.\nEspero que te diviertas mapeando diferentes países. Debido a que los diferentes países tienen diferentes tamaños y formas, una forma de mejorar las imágenes es ajustando la proporción (prportion), por ejemplo, mi propio mapa de Alemania parece fuera de forma, pero mejora considerablemente si en lugar de 1.3 le damos una proporción de 1.4, consulta la documentación para obtener más información al respecto.\nUna vez que tengamos el mapa básico, podríamos agregar las ciudades donde queremos agregar valores de datos. Desafortunadamente, para las ciudades hay muchas limitaciones, especialmente para países donde no se tienen pquetes específicos. E incluso en los que se tienen, la mayoría de los paquetes tienen carencias de algunas ciudades, especialmente cuando son muy pequeñas. Por lo tanto, en la segunda parte se verá como enfrentar este problema haciendo un poco de web scrap utilizando open street maps.\n","pubDate":"2022-10-08","title":"Mapa de cualquier región del mundo con R - Parte I: El mapa base"},{"link":"http://example.org/es/posts/2022/minitut_hacer_bool/","plain":"Acerca de este post. Este es mi primer post en español. Es en realidad la traducción de un post que escribí originalmente en inglés hace un par de meses. Pueden ver el post original aqui. Espero que sea útil para la comunidad hispanohablante de usuarios de R.\nEste post se basa en un trabajo reciente donde mi tarea fue la revisión y depuración de piezas de código pequeñas o simples que pueden resultar en consejos prácticos y rápidos para otros usuarios de R, especialmente principiantes o personas sin mucha experiencia en el uso de R.\nCon ese objetivo en mente, mientras recuperaba un poco de mi tiempo libre y un poco de estabilidad mental, y celebraba mi nuevo puesto como programador en R, decidí crear publicaciones simples pero útiles llamadas mini tutoriales, comenzando con un ejemplo muy simple, incluso tonto, pero útil.\nMini tutorial: Hacer lógico cualquier texto (make_logical_any_string). Una función para hacer lógica cualquier texto en R.\n1 2 3 4 5 6 make_logical_any_string \u0026lt;- function(texto){ texto \u0026lt;- as.character(texto) resultado_logico \u0026lt;- as.logical(texto) if(is.na(resultado_logico)){resultado_logico \u0026lt;- FALSE} return(resultado_logico) } La función toma cualquier valor, lo convierte en texto (character) y devuelve TRUE SÓLO SI el valor adopta cualquiera de las siguientes formas: \u0026quot;T\u0026quot;, \u0026quot;TRUE\u0026quot;, \u0026quot;true\u0026quot;, \u0026quot;true\u0026quot; o TRUE, el último el valor lógico, no en formato texto.\nLógica de la función La función as.character() convierte cualquier forma de texto \u0026ldquo;true\u0026rdquo; listado arriba en un TRUE lógico. Si el texto es \u0026quot;False\u0026quot; o sus formas equivalentes, la función devolverá FALSE. Si se pasa cualquier otro valor a la función, el resultado será NA. Por lo tanto, necesitamos modificar los resultados cuando se producen NA, ya que necesitamos un resultado de Verdadero/Falso. Así que implementamos if(is.na(resultado_logico)){resultado_logico \u0026lt;- FALSE} que obligará a cualquier otra cadena de texto a devolver FALSE.\nEstamos usando este código para ejecutar scripts de R en la consola que pasa una serie de argumentos para su funcionamiento, algunos de los cuales deben ser \u0026ldquo;TRUE\u0026rdquo; solo cuando se especifica, y \u0026ldquo;FALSE\u0026rdquo; en cualquier otro caso, de ahí el truco de convertir cualquier otro valor a FALSE en lugar de NA.\nAlgo importante a tomar en cuenta es que los argumentos siempre se pasan al script R como texto y, por lo tanto, escribí el ejemplo para esta publicación convirtiendo todo en texto en la primera línea de la función, lo cual no es necesario en nuestro código original ejecutado en el Terminal. De esta forma, si se le pasa algún número a la función, también devolverá FALSE, emulando lo que pasaría si se ingresa un número en la consola. Este comportamiento es diferente para la función as.logical(), que devuelve FALSE si ingresa el valor numérico 0 y TRUE si se ingresa cualquier otro valor numérico.\n","pubDate":"2022-09-18","title":"Mini tutorial: hacer tipo lógico cualquier texto"},{"link":"http://example.org/posts/2022/minitut_makebool/","plain":"Welcome to R minitutorials of R White Dwarf Since the beginning of this year I\u0026rsquo;ve been forced to abandon completely the blog for countless and rather abstract personal reasons that include personal health, family matters and changes in my daily activities including volunteer work as well as main job. As part of the last, I finally got hired for a position as R developer, which brings great joy to me.\nThus, I\u0026rsquo;ve been using R more lately in all kinds of forms, including review and debug of small or simple code pieces that can result in practical quick hints for other R users, especially beginners or people with not much experience using R.\nWith that aim in mind while regaining a little bit of my free time and a piece of mental stability, and celebrating my new position, I decided to take care of the blog again with simple yet useful posts called minitutorials, starting with a very simple, even silly, but useful example.\nI hope they can be useful for you or your friends. Enjoy them!\nMinitutorial: make_logical_any_string A function to make logical any string\n1 2 3 4 5 6 make_logical_any_string \u0026lt;- function(a_string){ a_string \u0026lt;- as.character(a_string) logical_result \u0026lt;- as.logical(a_string) if(is.na(logical_result)){logical_result \u0026lt;- FALSE} return(logical_result) } The function takes any value, convert it to character and returns TRUE ONLY IF the value takes either of the following forms: \u0026quot;T\u0026quot;, \u0026quot;TRUE\u0026quot;, \u0026quot;True\u0026quot;, \u0026quot;true\u0026quot; or TRUE, the last one the logical value, not the string.\nLogic of the function The function as.character() will convert any of the true strings listed above into a logical TRUE. If the string is rather \u0026quot;False\u0026quot; or its equivalent forms, the function will return FALSE. If any other character is passed to the function, the result will be NA. Therefore, we need to tweak the results when NA\u0026rsquo;s are produced since we forcefully need a True/False result. Thus, we implement if(is.na(logical_result)){logical_result \u0026lt;- FALSE} which will force any other string to return FALSE.\nWe are using this code for running R scripts in the terminal which passes a series of arguments for its functioning, some of which are required to be TRUE only when specified so, and FALSE in any other case, hence the trick of converting any other value to FALSE rather than NA.\nSomething to keep in mind is that the arguments are always passed to R script as character and thus, I wrote the example for this post converting everything into character in the first line of the function, which is not necessary in our original code executed in the terminal. In this way, if any number is passed to the function, it will also return FALSE, emulating what would happen if a number is entered into the console. This behavior is different for the function as.logical() itself, which returns FALSE if you enter the numerical value 0 and TRUE if any other numerical value is passed.\n","pubDate":"2022-09-18","title":"Minitutorial: make_logical any string"},{"link":"http://example.org/posts/2021/first_shiny_app/","plain":"I am happy and excited as I have just deployed my first shiny app on the web. You can find it running at shiny.rwhitedwarf.com (NOTE: I don\u0026rsquo;t have ssl certificate so, your browser might tell you that is not secure, but you can trust me that there\u0026rsquo;s no risk). I have created a few shiny apps in the past but I never deployed one, especially in an owned domain.\nThe app can create a map of all cities listed in a table for a given country. The idea is to simulate a table with a list of organizations, franchises, shops, etc. However, columns for name of organization or ID are missing in order to ensure data protection. In this way the user only needs to provide to the table name of the city, country, region (optional) and year of opening. The app creates the map, placing bigger dots in cities with more organizations. The year is interactive.\nThe app uses the package RJSONIO to do a simple web scrapping on Open Street Maps using its API Nominatim to obtain the coordinates (latitude and longitude), in this way any city that can be found in open street maps can be pointed in the map. The data is then sorted and cleaned with some basic R functions and some Tidyverse and finally the map is made with ggplot2 and maps. The front end is created of course with shiny and css but I have to mention also the use of rhandsontable, a wonderful package that allows the user to interact with the tables and therefore, the data. The app was very easily deployed in heroku thanks to the wonderful work of Chris Stefano who did all the hard work of creating a buildpack for applications written in R. The buildpack recognizes shiny and plumber apps. For shiny, it builds based on the run.R file and installs all the packages listed in init.R, making the deployment in heroku extremely easy.\nThe app is still in a raw state but already functional. The plan is to improve both, the functionality and the view in the following days. If you are interested in the source code to get inspiration or create your own, you can find it on github under the MIT license: teotenn/dynamic_maps_shiny.\nIf you want to learn how to make a similar shiny app, stay connected for a 3-4 part tutorial to get full details step by step.\n","pubDate":"2021-12-20","title":"My first shiny app"},{"link":"http://example.org/posts/2021/fill_merged_cells/","plain":"This post is part of our series on functions in R. You can see our previous post if you want to understand the basics but it is not strictly necessary. Here we will go into detail about for loops and if statements in R, two key elements of any function. We are going to define a process, map it in a step-by-step approach and wrape it in a function that can repeat it automatically. Even if you have a very basic understanding of R you should be able to follow this tutorial without problem.\nOur outcome will be an R function that by calling it, is able to fill in empty rows generated from imported sheets (like excel) when it contains merged cells. If you are only interested in the function itself you can go to the end of the post and find it in the section Final remarks.\nDescription of the problem In our previous post we saw the basics for creating functions, yet using silly examples with not much of practical usage. Now we are ready to write a function that can have more practical use.\nThere are different ways how to import data sheets (i.e. from excel) to R. Regardless of its limitations, these sheets are widely used in data analysis today. If you are used to do data analysis with a different software you should be familiar with the complications of sorting your data imported from sheets when there are merged cells in the rows. Usually, a file like below\nresults in a table like this\nSpecie Dup Treat Rep Value A. cap A 0 1 34 AA NA NA 26 A 25 NA 18 AA NA NA 24 A 50 NA 11 AA NA NA 12 A 100 NA 15 AA NA NA 11 F. rub F 0 NA 25 FF NA NA 26 F 25 NA 17 FF NA NA 11 F 50 NA 13 FF NA NA 11 F 100 NA 11 when the amount of rows to be filled in is small, there\u0026rsquo;s no big problem in copying and pasting the values. But as the DRY principle says, if we know how to create functions there is no need to do that, we can make a function that will do it automatically. This will specially pay off when you will have a table with hundreds or even thousands of cells merged. You might be thinking that nobody will merge cells for thousands of rows every 3 or 4 lines, but believe me, I have seen such things.\nKeep in mind that this is mainly a tutorial for writting functions in R. It does not intend to deal with all the issues that migh appear with the importing of data such as merged columns or a mixture of both, among others. But if you have problems with that or are interested in the topic, leave us a comment and we can cover some points in a future post.\nR function to fill in merged cells from excel With today\u0026rsquo;s technology there are many ways to solve this problem. However sometimes the easiest way to import data to R as data analyst or statistician is by simply taking the working sheet containing the data and exporting it in csv format.\nRegardless of the source (excel, libre office, google sheets, etc.) this method produces empty rows by default. When some rows have been merged because they belong to the same group or factor, the csv file will capture the value only on the first row and leave the rest empty until the next factor appear, where it again, will capture the value on the first row and leave the rest empty until the next factor appears. The process continues like this, iteratively until the end of the table. We basically need to copy the value stored on that first row and paste it to the empty rows, until a new factor appears.\nLet\u0026rsquo;s map the process in terms of R steps to complete our task.\nMaping the process We will start by calling the table. If you have an excel, libre office calc or google sheet file with merged rows as our example above feel free to use it. Otherwise you can quickly simulate one similar to the image above. Start by exporting the sheet of interest to csv, then we call it using read.csv\n1 2 my.table \u0026lt;- read.csv(\u0026#39;../../../static/post/2021/fill_merged_cells/Hydroponic_results.csv\u0026#39;) head(my.table, n = 10) \u0026gt; Specie Dup Treat Rep Value \u0026gt; 1 A. cap A 0 1 34 \u0026gt; 2 AA NA NA 26 \u0026gt; 3 A 25 NA 18 \u0026gt; 4 AA NA NA 24 \u0026gt; 5 A 50 NA 11 \u0026gt; 6 AA NA NA 12 \u0026gt; 7 A 100 NA 15 \u0026gt; 8 AA NA NA 11 \u0026gt; 9 F. rub F 0 NA 25 \u0026gt; 10 FF NA NA 26 Here we can see the first 10 rows containing NA for numeric columns and empty string for character columns. Now let\u0026rsquo;s go step by step to fill empty values.\n1. Identify and capture the factor Let\u0026rsquo;s start with the first column Specie (an experiment was run for 3 different species of plants). We want to check if the first row contains a categorical value\n1 2 no.row \u0026lt;- 1 my.table[[\u0026#39;Specie\u0026#39;]][no.row] \u0026gt; [1] \u0026#34;A. cap\u0026#34; 2. Copy it into the empty rows Now we want to paste the value stored in category to all empty rows. So we first need to check if the next row is empty\n1 2 no.row \u0026lt;- 2 my.table[[\u0026#39;Specie\u0026#39;]][no.row] \u0026gt; [1] \u0026#34;\u0026#34; And when it is, we place the value contained in the previous row to our current row 2\n1 2 my.table[[\u0026#39;Specie\u0026#39;]][no.row] \u0026lt;- my.table[[\u0026#39;Specie\u0026#39;]][no.row-1] head(my.table) \u0026gt; Specie Dup Treat Rep Value \u0026gt; 1 A. cap A 0 1 34 \u0026gt; 2 A. cap AA NA NA 26 \u0026gt; 3 A 25 NA 18 \u0026gt; 4 AA NA NA 24 \u0026gt; 5 A 50 NA 11 \u0026gt; 6 AA NA NA 12 Now row 2 contains it\u0026rsquo;s categorical value, and when we move to row 3 (which is also empty), it can be copied from the previous row 2\n1 2 no.row \u0026lt;- 3 my.table[[\u0026#39;Specie\u0026#39;]][no.row] \u0026gt; [1] \u0026#34;\u0026#34; 1 2 my.table[[\u0026#39;Specie\u0026#39;]][no.row] \u0026lt;- my.table[[\u0026#39;Specie\u0026#39;]][no.row-1] head(my.table) \u0026gt; Specie Dup Treat Rep Value \u0026gt; 1 A. cap A 0 1 34 \u0026gt; 2 A. cap AA NA NA 26 \u0026gt; 3 A. cap A 25 NA 18 \u0026gt; 4 AA NA NA 24 \u0026gt; 5 A 50 NA 11 \u0026gt; 6 AA NA NA 12 3. When a new factor appears, repeat the process We can repeat this process until a new factor appears, as it is the case of row 9. Therefore we should not paste anything in row 9, and continue the process on row 10 which is also empty\n1 2 no.row \u0026lt;- 10 my.table[[\u0026#39;Specie\u0026#39;]][no.row] \u0026gt; [1] \u0026#34;\u0026#34; 1 2 my.table[[\u0026#39;Specie\u0026#39;]][no.row] \u0026lt;- my.table[[\u0026#39;Specie\u0026#39;]][no.row-1] head(my.table, n = 10) \u0026gt; Specie Dup Treat Rep Value \u0026gt; 1 A. cap A 0 1 34 \u0026gt; 2 A. cap AA NA NA 26 \u0026gt; 3 A. cap A 25 NA 18 \u0026gt; 4 AA NA NA 24 \u0026gt; 5 A 50 NA 11 \u0026gt; 6 AA NA NA 12 \u0026gt; 7 A 100 NA 15 \u0026gt; 8 AA NA NA 11 \u0026gt; 9 F. rub F 0 NA 25 \u0026gt; 10 F. rub FF NA NA 26 4. Repeat steps 1-3 for each column that needs it The process moves forward in this way until the whole column Specie is filled in. Then we can move to the next column with empty values, in my case this is Treat.\nIf you look at the process, we basically need to write an R command for step 2. The rest is just a process of verification and repetition. We are going to automate verification using the function if() and the repetition using for().\nWriting my first for loop Since the present post is directed to R beginners with not much experience with programming or coding I will avoid all the technicalities of for loops and if statements and instead dive deeply into them by applying our logic above. Then we are going to use them and explain carefully to obtain a pragmatic understanding of the process.\nWe will start with a for loop to go row by row in one column and check what is inside, as described in the step 1 of our process. Let\u0026rsquo;s start with only 20 rows as an example\n1 2 3 for(no.row in 1:20){ print(my.table[[\u0026#34;Specie\u0026#34;]][no.row]) } \u0026gt; [1] \u0026#34;A. cap\u0026#34; \u0026gt; [1] \u0026#34;A. cap\u0026#34; \u0026gt; [1] \u0026#34;A. cap\u0026#34; \u0026gt; [1] \u0026#34;\u0026#34; \u0026gt; [1] \u0026#34;\u0026#34; \u0026gt; [1] \u0026#34;\u0026#34; \u0026gt; [1] \u0026#34;\u0026#34; \u0026gt; [1] \u0026#34;\u0026#34; \u0026gt; [1] \u0026#34;F. rub\u0026#34; \u0026gt; [1] \u0026#34;F. rub\u0026#34; \u0026gt; [1] \u0026#34;\u0026#34; \u0026gt; [1] \u0026#34;\u0026#34; \u0026gt; [1] \u0026#34;\u0026#34; \u0026gt; [1] \u0026#34;\u0026#34; \u0026gt; [1] \u0026#34;\u0026#34; \u0026gt; [1] \u0026#34;\u0026#34; \u0026gt; [1] \u0026#34;A. ela\u0026#34; \u0026gt; [1] \u0026#34;\u0026#34; \u0026gt; [1] \u0026#34;\u0026#34; \u0026gt; [1] \u0026#34;\u0026#34; The function for()uses the first argument that you define (here no.row) and goes one by one in the series specified as the second argument, in this case a series of numbers from 1 to 20 (1:20). It means that in the first iteration no.row will take the value 1, in the second iteration the value 2, and so on, until the last iteration where it will have the value 20. Each iteration will execute the code inside the curly braces {} which, in this case, is simply to print the value of each row.\nBecause the first argument in for() is defined by us, we could as well use any arbitrary argument we want, for example\n1 2 3 for(n in 1:20){ print(my.table[[\u0026#34;Specie\u0026#34;]][n]) } would do exactly the same but now n is taking the values from 1 to 20.\nWe can then initialize a function that takes the name of our data frame, the name of the column, and do exactly the same as our code above, but for all the rows contained in the table, no matter how many they are\n1 2 3 4 5 6 fill_merged \u0026lt;- function(dat, column){ ## Get value of each row for(n in 1:nrow(dat)){ print(my.table[[column]][n]) } } Here our for loop will create a local variable n that will take values from 1 until nrow(dat) which means number of rows in the table dat, and then print each row value contained in the column stated in the argument column. If we apply it to our data frame\n1 fill_merged(my.table, \u0026#34;Specie\u0026#34;) The R console will print, one by one, each of the values contained in the column Specie (I have 120 rows, it makes no sense to take space to show it in the post, but you can go ahead and try it yourself).\nIf the last two pieces of code are not clear for you, I recommend you to read our previous post about functions in R.\nHow to use If statement in R Printing the values is far from what we want to achieve. As we defined in the first step of the process, we need to check the value inside, if it has a value we leave it alone, but if it is empty, we fill it in with the previous value. To check if the value is empty or not we use the if() function\n1 2 3 4 5 6 7 8 9 10 fill_merged \u0026lt;- function(dat, column){ ## Get value of each row for(n in 1:nrow(dat)){ ## Check if it is empty if(dat[[column]][n] == \u0026#39;\u0026#39;){ dat[[column]][n] \u0026lt;- dat[[column]][n - 1] } } return(dat) } The function if() checks the expression inside parentheses and if it returns TRUE it executes the code inside curly braces {}, otherwise it will skip it. Therefore it is crucial that the expression inside if() returns either TRUE or FALSE. You can always test it by sending the exact expression directly to the console\n1 my.table[[\u0026#39;Specie\u0026#39;]][1] == \u0026#39;\u0026#39; \u0026gt; [1] FALSE 1 my.table[[\u0026#39;Specie\u0026#39;]][5] == \u0026#39;\u0026#39; \u0026gt; [1] TRUE Once we confirm that the value is empty, we enter the if statement and execute the code from step 2, which inside the function takes the form of dat[[column]][n] \u0026lt;- dat[[column]][n - 1].If the value is not empty, we simply do nothing.\nNow we can actually try the function in one of our columns\n1 2 my.filled.table \u0026lt;- fill_merged(my.table, \u0026#39;Specie\u0026#39;) head(my.filled.table, n = 15) \u0026gt; Specie Dup Treat Rep Value \u0026gt; 1 A. cap A 0 1 34 \u0026gt; 2 A. cap AA NA NA 26 \u0026gt; 3 A. cap A 25 NA 18 \u0026gt; 4 A. cap AA NA NA 24 \u0026gt; 5 A. cap A 50 NA 11 \u0026gt; 6 A. cap AA NA NA 12 \u0026gt; 7 A. cap A 100 NA 15 \u0026gt; 8 A. cap AA NA NA 11 \u0026gt; 9 F. rub F 0 NA 25 \u0026gt; 10 F. rub FF NA NA 26 \u0026gt; 11 F. rub F 25 NA 17 \u0026gt; 12 F. rub FF NA NA 11 \u0026gt; 13 F. rub F 50 NA 13 \u0026gt; 14 F. rub FF NA NA 11 \u0026gt; 15 F. rub F 100 NA 11 Note that so far it works only for columns with character values, not numeric\n1 fill_merged(my.table, \u0026#39;Treat\u0026#39;) \u0026gt; Error in if (dat[[column]][n] == \u0026#34;\u0026#34;) {: missing value where TRUE/FALSE needed The reason is that only character columns produce empty strings. Numeric columns will produce NA values. Therefore, we need to add a condition to our if expression to test also if the value is NA. To do that we use double | which in R means OR\n1 2 3 4 5 6 7 8 9 10 fill_merged \u0026lt;- function(dat, column){ ## Get value of each row for(n in 1:nrow(dat)){ ## Check if it is empty if(dat[[column]][n] == \u0026#39;\u0026#39; || is.na(dat[[column]][n])){ dat[[column]][n] \u0026lt;- dat[[column]][n - 1] } } return(dat) } Now our if statement is telling to R \u0026ldquo;IF the value is empty ('') OR is NA (is.na()) then, execute this code\u0026rdquo;, and so we enter to the code inside the if-curly-braces.\nNA are not exactly values and therefore we cannot test them by using the expression\n1 my.table[[\u0026#39;Treat\u0026#39;]][2] == NA \u0026gt; [1] NA Instead of returning TRUE or FALSE returns NA which means Not Available. To check if the value is NA or really a value we use the function is.na()\n1 is.na(my.table[[\u0026#39;Treat\u0026#39;]][2]) \u0026gt; [1] TRUE Now we can use our function for columns with numeric values also\n1 2 my.filled.table \u0026lt;- fill_merged(my.table, \u0026#39;Treat\u0026#39;) head(my.filled.table, n = 10) \u0026gt; Specie Dup Treat Rep Value \u0026gt; 1 A. cap A 0 1 34 \u0026gt; 2 A. cap AA 0 NA 26 \u0026gt; 3 A. cap A 25 NA 18 \u0026gt; 4 AA 25 NA 24 \u0026gt; 5 A 50 NA 11 \u0026gt; 6 AA 50 NA 12 \u0026gt; 7 A 100 NA 15 \u0026gt; 8 AA 100 NA 11 \u0026gt; 9 F. rub F 0 NA 25 \u0026gt; 10 F. rub FF 0 NA 26 Check, confirm and repeat (for and if together) Now we could use our function for each column that presents this issue, but we are actually trying to apply the DRY principle. Instead we could use for() to go through all the columns where we want to apply it. There are other functions that can help with this as well such as map() and its derived functions from the package purrr.We could also write a new function that calls our first function to repeat it into each column. Feel free to experiment, for this tutorial we are going to take a different approach.\nWe are going to improve the same old function and add yet one more for loop that iterates from each column of interest and repeats the same process. This will cover the step 4 of our mapped process.\nThe implementation is actually easy, we just need to wrap the whole previous process of if\u0026rsquo;s and for\u0026rsquo;s inside a for loop that goes column by column\n1 2 3 4 5 6 7 8 9 10 11 12 13 fill_merged \u0026lt;- function(dat, columns.as.vector){ ## Go through the columns for(column in columns.as.vector){ ## Get value of each row for(n in 1:nrow(dat)){ ## Check if it is empty if(dat[[column]][n] == \u0026#39;\u0026#39; || is.na(dat[[column]][n])){ dat[[column]][n] \u0026lt;- dat[[column]][n - 1] } } } return(dat) } I have changed the argument for initiating the function from column to columns.as.vector. Now this will take a vector containing all the names of the columns that should be treated. Notice that in our new for loop I am declaring column to iterate over each value of column.as.vector therefore, the variable column will contain each string in the vector for each iteration. In this way we don\u0026rsquo;t need to change the rest of the code.\nNow you can call exactly the same function for each column that needs it\n1 2 3 target_cols \u0026lt;- names(my.table)[c(1,3,4)] my.filled.table \u0026lt;- fill_merged(my.table, target_cols) head(my.filled.table, n = 15) \u0026gt; Specie Dup Treat Rep Value \u0026gt; 1 A. cap A 0 1 34 \u0026gt; 2 A. cap AA 0 1 26 \u0026gt; 3 A. cap A 25 1 18 \u0026gt; 4 A. cap AA 25 1 24 \u0026gt; 5 A. cap A 50 1 11 \u0026gt; 6 A. cap AA 50 1 12 \u0026gt; 7 A. cap A 100 1 15 \u0026gt; 8 A. cap AA 100 1 11 \u0026gt; 9 F. rub F 0 1 25 \u0026gt; 10 F. rub FF 0 1 26 \u0026gt; 11 F. rub F 25 1 17 \u0026gt; 12 F. rub FF 25 1 11 \u0026gt; 13 F. rub F 50 1 13 \u0026gt; 14 F. rub FF 50 1 11 \u0026gt; 15 F. rub F 100 1 11 Also notice the trick in the first line: names(my.table) returns a vector containing all the column names of the data frame and names(my.table)[c(1,3,4)] is taking only the columns 1, 3 and 4, which are the ones that need to be fixed. This is extremely useful when you have many columns that need to be fixed\nMarking the errors You might have noticed that I\u0026rsquo;m adding text preceded by ## within the function. If you are not familiar with it, this are comments, it means that anything that is written in the same line after one # will not be evaluated by R (I use double for technical reasons of my text editor). Although this function is quite small and simple, and we know what exactly we are doing on each line thanks to the explanations, it is a good practice to add comments to your code because after a while, when you will look back at the code you might had forgotten the logic and structure. Adding comments help us to know what each piece is about, making it easier to apply changes in the future.\nIn the same way, it is a good practice to add errors when the function is expecting something in particular and we can foresee potential problems. Often we don\u0026rsquo;t foresee all the mistakes and problems that the user or we ourselves can have when using our own functions and thus, errors are usually added along the way based on the experience gathered by using the function.\nFor example, our function is expecting that at least the first row will not have empty values, otherwise it cannot go one row before to find the value to paste on it. Although it is not expected, our table can still present this situation due to human errors, for example, somebody by accident pressed Delete button somewhere on the first row in the source file. In such case R will mark some error that will be difficult to understand and track back. We might wonder for hours what we did wrong in our function only to find out that the problem comes from the data table itself. Instead we can mark our own error in advance by sending a message when the value on the first row is missing.\nAn easy way of implementing this is using the function stop(). Let\u0026rsquo;s implement our error into our function right before it copies the value from the row n - 1.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 fill_merged \u0026lt;- function(dat, columns.as.vector){ ## Go through the columns for(column in columns.as.vector){ ## Get value of each row for(n in 1:nrow(dat)){ ## Check if it is empty if(dat[[column]][n] == \u0026#39;\u0026#39; || is.na(dat[[column]][n])){ ## If it is the row 1, stop with Error if(n == 1){ stop(paste0(\u0026#34;Row 1 of column \u0026#34;, column, \u0026#34; has empty values. Check your data.\u0026#34;)) } else{ dat[[column]][n] \u0026lt;- dat[[column]][n - 1] } } } } return(dat) } If the value of the first row is empty, the function will stop, printing a message that says in which column the row no. 1 is empty. When the row is not the first, R will evaluate the code next, contained inside else{}. else is a complement for if that tell R what to do when the if() part is not fulfilled. Sometimes we can omit it, when the if() part is not fulfilled R will simply go to the next part of the code. But when we want to make sure that nothing will happen outside these options, we include else. Here we are giving only two options, either n equals 1 and the function stops with an error, or else n is not one and the function continues.\nLet\u0026rsquo;s try the error by making a copy of our data frame with the first row empty\n1 2 test.error \u0026lt;- my.table[2:10,] fill_merged(test.error, \u0026#39;Rep\u0026#39;) \u0026gt; Error in fill_merged(test.error, \u0026#34;Rep\u0026#34;): Row 1 of column Rep has empty values. Check your data. Another misunderstanding that the user can encounter is with the argument columns.as.vector. We are expecting that the user will provide a string, or vector of strings with the names of the columns, but the user as well might think that the function is expecting the whole data as vector. We can prevent the user for doing this by adding an error at the beginning of the function.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 fill_merged \u0026lt;- function(dat, columns.as.vector){ ## Check if column names are provided as strings if(!is.character(columns.as.vector)){ stop(\u0026#34;Column names must be provided as string or vector of strings of class character\u0026#34;) } ## Go through the columns for(column in columns.as.vector){ ## Get value of each row for(n in 1:nrow(dat)){ ## Check if it is empty if(dat[[column]][n] == \u0026#39;\u0026#39; || is.na(dat[[column]][n])){ ## If it is the row 1, stop with Error if(n == 1){ stop(paste0(\u0026#34;Row 1 of column \u0026#34;, column, \u0026#34; has empty values. Check your data.\u0026#34;)) } else{ dat[[column]][n] \u0026lt;- dat[[column]][n - 1] } } } } return(dat) } We want to make sure that columns.as.vector is character. To test this, we use the function is.character(), which will return TRUE when the values inside are character, and FALSE otherwise.\n1 2 a \u0026lt;- \u0026#39;foo\u0026#39; is.character(a) \u0026gt; [1] TRUE However we want to send the error only when the value is NOT character. To tell R to test the opposite, we start the argument with the symbol !\n1 !is.character(a) \u0026gt; [1] FALSE Now with our new version, when the user might provide any value that is not string, the error will be triggered\n1 fill_merged(my.table, 1) \u0026gt; Error in fill_merged(my.table, 1): Column names must be provided as string or vector of strings of class character Still if the user provides a vector of strings, or a misspelled name of the column, our function is not aware of it. We can add one more error when column.as.vector is string but not a string that we are expecting\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 fill_merged \u0026lt;- function(dat, columns.as.vector){ ## Check if column names are provided as strings if(!is.character(columns.as.vector)){ stop(\u0026#34;Column names must be provided as string or vector of strings of class character\u0026#34;) } ## Go through the columns for(column in columns.as.vector){ ## Check if the column name matches with dat column names if (!column %in% names(dat)){ stop(paste0(\u0026#39;Column \u0026lt;\u0026#39;, column, \u0026#39;\u0026gt; cannot be found in the data frame\u0026#39;)) } ## Get value of each row for(n in 1:nrow(dat)){ ## Check if it is empty if(dat[[column]][n] == \u0026#39;\u0026#39; || is.na(dat[[column]][n])){ ## If it is the row 1, stop with Error if(n == 1){ stop(paste0(\u0026#34;Row 1 of column \u0026lt;\u0026#34;, column, \u0026#34;\u0026gt; has empty values. Check your data.\u0026#34;)) } else{ dat[[column]][n] \u0026lt;- dat[[column]][n - 1] } } } } return(dat) } Here we are implementing if (!column %in% names(dat)). Again we are using ! to tell R to test the opposite. column %in% names(dat) will take the value of column and check if it is present in the vector names(dat) (which has the names of the columns).\nLet\u0026rsquo;s test the last error by misspelling the name of one column\n1 fill_merged(my.table, c(\u0026#39;Specie\u0026#39;, \u0026#39;Treatment\u0026#39;)) \u0026gt; Error in fill_merged(my.table, c(\u0026#34;Specie\u0026#34;, \u0026#34;Treatment\u0026#34;)): Column \u0026lt;Treatment\u0026gt; cannot be found in the data frame If you can think of more errors feel free to add them, it will be good for you as a practice. However you should also try and see what happens with other potential scenarios before adding the errors yourself. Sometimes the default errors from other functions are enough to solve problems. For example, try providing to our function a data frame that does not exist, R will immediately tell you object 'x' not found.\nFinal remarks I hope that the post has helped you to have a better understanding of for() and if(), and provided you with a good guidance on how you can plan and structure functions. If something was not clear or you still have questions, or something in your code did not work as expected, feel welcome to leave us a comment below (you will need a github account for that).\nThere are many ways how you can call your function now to your future projects. One of the easiest for now would be to save it in an R script, for example fill_merged_cells.R and then you can call it from any script or R code by providing the path to your script to the function source()\n1 source(\u0026#39;~/Rscripts/fill_merged_cells.R\u0026#39;) changing the path to the exact location of your file. Source will run all the code contained inside the .R file in the R session where you call it, making your function available for the current session.\nHere is the final form of the function for filling in empty rows produced by merged cells. I hope it will help with your work. Enjoy it!\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 fill_merged \u0026lt;- function(dat, columns.as.vector){ ## Check if column names are provided as strings if(!is.character(columns.as.vector)){ stop(\u0026#34;Column names must be provided as string or vector of strings of class character\u0026#34;) } ## Go through the columns for(column in columns.as.vector){ ## Check if the column name matches with dat column names if (!column %in% names(dat)){ stop(paste0(\u0026#39;Column \u0026lt;\u0026#39;, column, \u0026#39;\u0026gt; cannot be found in the data frame\u0026#39;)) } ## Get value of each row for(n in 1:nrow(dat)){ ## Check if it is empty if(dat[[column]][n] == \u0026#39;\u0026#39; || is.na(dat[[column]][n])){ ## If it is the row 1, stop with Error if(n == 1){ stop(paste0(\u0026#34;Row 1 of column \u0026lt;\u0026#34;, column, \u0026#34;\u0026gt; has empty values. Check your data.\u0026#34;)) } else{ dat[[column]][n] \u0026lt;- dat[[column]][n - 1] } } } } return(dat) } ","pubDate":"2021-12-05","title":"R function to fill in merged cells"},{"link":"http://example.org/posts/2021/functions/","plain":"Background This is the first post of R with White Dwarf and I decided to start this blog with a basic tutorial. There is already a lot of information in the web about getting started with R. With a simple google search you can easily find info on how to install it, how to use R studio or other text editor, learn about the basic functions and concepts, what is a vector, a data frame, how to use them, etc. Therefore, I decided to start with a topic that is also basic and fundamental but slightly less common: Functions.\nHow to create a function is not an easy topic for non-programmers and non-mathematicians, Myself I have a background in Ecology and when I started using R for my statistical analysis I was avoiding using functions at all cost, while most of my colleagues where avoiding R fully. Many people has the idea that, as a programming language, R is really difficult to use and it should be left for the initiated ones. They end up using user interface based-software which assumes not only that the user doesn\u0026rsquo;t know about programming, but also about statistics. It makes things easy for the user but also limits the possibilities of what you can do with your data and as a result, it also what you can learn.\nIn today\u0026rsquo;s world, it is important to to have at least a basic understanding of programming. Learning how to write simple functions in R will widen your perception about R and programming by showing you that it is actually easy. I am writing this post especially for all the people who are not programmers, not statisticians and are thinking to learn R. By the end of the post I hope that you can agree with me that writing functions in R is not difficult.\nHow to write functions in R Basically, when we use R we are using functions all the time. When you want to obtain the summation of values, or the mean or standard deviation, you can simply call a function to do that\n1 2 values \u0026lt;- c(2, 3, 4, 5) sum(values) \u0026gt; [1] 14 As you should already know from any R tutorial, the example above is storing the values in the vector value and then calling the function sum to obtain the summation of the values. One way to create our own version of sum would be:\n1 2 3 4 5 6 7 my_sum \u0026lt;- function(user.values){ cumulative.sum \u0026lt;- user.values[1] for(i in 2:length(user.values)){ cumulative.sum \u0026lt;- cumulative.sum + user.values[i] } return(cumulative.sum) } Now we can call our brand new function and obtain the same results\n1 my_sum(values) \u0026gt; [1] 14 Let\u0026rsquo;s go piece by piece. Line no. 1 is simply placing the function that we are creating into the object my_sum which means that later, we can call our function using that same argument: my_func(some values). This is similar to creating a vector or data frame or variables, as you know, if you enter x \u0026lt;- 12 then each time you type x in the console it will return the value 12, and so it explains line 2, when we define cumulative.sum \u0026lt;- user.values[1] this places the first value of the vector user.values into the variable cumulative.sum. It means that now we can start by adding the second value to the cumulative.sum, then we move forward to the third value, and so on until the last element in the vector. This process is defined in the for loop: we move value by value from the second element to the last one: for(i in 2:length(user.values)), each time we stored the cumulative value in our variable cumulative.sum until we reach the last value. I will not go deep into the for loop, but I understand that it can also be somehow complicated for a beginner, if it is your case I invite you to leave us a comment (you will need a github account for that) and I might cover it in a future issue.\nOnce we are outside the for loop we have collected the final value in cumulative.sum so, we make sure that our function is returning exactly that by using return(cumulative.sum). If you have seen some other tutorials you might have noticed that the return() is not always added at the end of the function. And indeed, it is not strictly necessary (more on that later), but as a beginner it is good to start with good habits and defining what exactly you want your function to return is a good habit for your future functions.\nSimple error handling When you work with functions you need to tell the user what exactly went wrong in order to help him fix it. Even if you are writing functions only for yourself, after a while has passed you might forget all the logic behind your function and thus, obtaining errors that you don\u0026rsquo;t understand where they come from. A basic knowledge of error handling can help us prevent that.\nWhat I\u0026rsquo;m explaining here is a very basic and simple management of errors but yet, practical and useful, it can save us wasted time and headaches. It is something I wish I had learned when I started writing my first functions. Due to my ignorance it used to take me a lot of time just to figure out what was wrong with my own code.\nLet\u0026rsquo;s go back to our function. As you probably already noticed, it starts summing up from the second value in the vector, therefore if we provide only one value instead of a vector of values the result will be NA\n1 my_sum(12) \u0026gt; [1] NA quite silly compared to the professional function from base-R which returns the value itself\n1 sum(12) \u0026gt; [1] 12 We could try to imitate the base-R sum() and continue in that direction, but instead we are going to have a little fun with simple examples of errors. Let\u0026rsquo;s say that instead of returning the value itself, we want our new function to send an error when a single value is entered. For that, we simply need to check if the value size is bigger than 1, and if not, send the error. We can achieve that with an if statement:\n1 2 3 4 5 6 7 8 9 10 my_sum \u0026lt;- function(user.values){ if(length(user.values) == 1){ stop(\u0026#39;We cannot sum individual values here!\u0026#39;) } cumulative.sum \u0026lt;- user.values[1] for(i in 2:length(user.values)){ cumulative.sum \u0026lt;- cumulative.sum + user.values[i] } return(cumulative.sum) } As you can see in line 2, we will enter inside the if-part-of-code if the length of the values is one (we cannot have length smaller than 1, if we run the function without a value, R will say that the argument is missing), calling stop() which basically stops the function at that point, and exits printing whatever message you define inside it. Go ahead and try it.\n1 my_sum(12) \u0026gt; Error in my_sum(12): We cannot sum individual values here! I am sure that with this basic info you can already move forward and improve it even more to send an error message when an object other than a vector is entered. Try to do it yourself and feel free to leave me a comment below if you get any trouble. Some hints: You can use the function is.vector() to test if the value entered by the user is a vector or not; and you can place one if statement inside the other, first to check if it is a vector, and secondly to check its size.\nFunction arguments You might be wondering what about the argument used as variable user.values, where does it come from? how is it defined? how does R knows how to use it? Keeping it simple, all the arguments that you define inside the parenthesis of a function will be searched by R when you execute the function and will be used accordingly. You can easily see how we were using the variable user.values to tell the rest of the program what to do with it. The function has no idea if the user will enter a single value, a vector or a data frame, this is the reason why we created the errors with stop(). As the creator of the function, it is your role to decide what kind of object you need, how to use it and how to ensure that the user knows what is wrong if an unexpected object is entered.\nYou can define as many arguments as you wish for your function, for example\n1 2 3 4 5 sum_four_nums \u0026lt;- function(num1, num2, num3, num4){ return(sum(num1, num2, num3, num4)) } sum_four_nums(2, 4, 6, 8) \u0026gt; [1] 20 Here we are telling R to take the four values entered by the user and sum them up. R will check the values in the order they are entered, so in our example it will associate the value 2 with our first variable num1, then the value 4 with the second variable num2 and so on. If we miss one of the values, R will tell us that one of the variables is missing\n1 sum_four_nums(2, 4, 6) \u0026gt; Error in sum_four_nums(2, 4, 6): argument \u0026#34;num4\u0026#34; is missing, with no default If we want to allow the user to provide only 3 values, we can initialize one of them as null\n1 2 3 4 5 sum_four_nums \u0026lt;- function(num1, num2, num3, num4 = NULL){ return(sum(num1, num2, num3, num4)) } sum_four_nums(2, 4, 6) \u0026gt; [1] 12 This means that we can actually initialize our variables with whatever we want to put on it, for example we can tell our function to always add 10 if only 3 values are entered by the user\n1 2 3 4 5 sum_four_nums \u0026lt;- function(num1, num2, num3, num4 = 10){ return(sum(num1, num2, num3, num4)) } sum_four_nums(2, 4, 6) \u0026gt; [1] 22 Also notice that we are telling R to take strictly four values, and not a vector of size 4. If we do this, R will associate the vector to the variable num1 as one object and will complain that the other arguments are missing\n1 sum_four_nums(c(2, 4, 6, 8)) \u0026gt; Error in sum_four_nums(c(2, 4, 6, 8)): argument \u0026#34;num2\u0026#34; is missing, with no default As I mentioned already, R is not aware of what type of object the user should enter, therefore we could as well enter only a vector, or vector and numbers, and R will simply apply the sum() function to whatever is inside it, because this is how we defined our function\n1 sum_four_nums(c(2, 4, 6, 8), 20, 50) \u0026gt; [1] 100 Here R is summing first all values contained in the vector, then 20 and 50, and finally the predefined 10. As you can see, the proper handling of errors is important when you want to ensure that you function does what is intended to do, or to help you or the user identify what exactly when wrong.\nFunctions without arguments You can also define functions without arguments, meaning without direct input from the user. For example, let\u0026rsquo;s write the classical Hello World!, a function that, when called, prints the sentence itself\n1 2 3 4 5 hello_world_function \u0026lt;- function(){ print(\u0026#39;Hello World!\u0026#39;) } hello_world_function() \u0026gt; [1] \u0026#34;Hello World!\u0026#34; As you can see, in line 1 when we define the function there is nothing inside the parenthesis and thus, when we call the function we don\u0026rsquo;t need to include anything inside it. This example might look silly, but sometimes we want the functions for their side effects, rather than for the values they return.\nWhen we write a function, R will search for the variable inside the function\n1 2 3 4 5 6 sum_my_vector \u0026lt;- function(){ my.vector \u0026lt;- c(10, 20, 30) return(sum(my.vector)) } sum_my_vector() \u0026gt; [1] 60 1 ls() \u0026gt; [1] \u0026#34;base.dir\u0026#34; \u0026#34;base.url\u0026#34; \u0026#34;changing.wd\u0026#34; \u0026gt; [4] \u0026#34;dirs\u0026#34; \u0026#34;fig.path\u0026#34; \u0026#34;func.params\u0026#34; \u0026gt; [7] \u0026#34;hello_world_function\u0026#34; \u0026#34;my_sum\u0026#34; \u0026#34;rmd.file\u0026#34; \u0026gt; [10] \u0026#34;rmd.path\u0026#34; \u0026#34;sum_four_nums\u0026#34; \u0026#34;sum_my_vector\u0026#34; \u0026gt; [13] \u0026#34;values\u0026#34; \u0026#34;work.in\u0026#34; As you can see, the vector called my.vector is created inside the function and thus, when we call it, the function returns the sum of the vector. However, when we list all the objects in memory using ls(), the object my.vector doesn\u0026rsquo;t exists. All the objects that we define inside the function live only there. If we now create an object called my.vector and call again the function, the result will not change\n1 2 my.vector \u0026lt;- c(1, 2, 3) sum_my_vector() \u0026gt; [1] 60 1 ls() \u0026gt; [1] \u0026#34;base.dir\u0026#34; \u0026#34;base.url\u0026#34; \u0026#34;changing.wd\u0026#34; \u0026gt; [4] \u0026#34;dirs\u0026#34; \u0026#34;fig.path\u0026#34; \u0026#34;func.params\u0026#34; \u0026gt; [7] \u0026#34;hello_world_function\u0026#34; \u0026#34;my_sum\u0026#34; \u0026#34;my.vector\u0026#34; \u0026gt; [10] \u0026#34;rmd.file\u0026#34; \u0026#34;rmd.path\u0026#34; \u0026#34;sum_four_nums\u0026#34; \u0026gt; [13] \u0026#34;sum_my_vector\u0026#34; \u0026#34;values\u0026#34; \u0026#34;work.in\u0026#34; The reason is that R functions search for objects inside the function. Therefore, you could give the same names to objects inside and outside the functions without affecting the outcome, however this is not recommended because it might cause confusion in the future. Another reason why is not recommended is that R searches for the object inside the function first, but when it cannot find it, it searches for the object outside of the function, in your working environment (it means, what we can see listed by ls()), for example\n1 2 3 4 5 sum_other_vector \u0026lt;- function(){ return(sum(my.vector)) } sum_other_vector() \u0026gt; [1] 6 here I have created a similar function but this time I did not create the object my.vector inside it, therefore R is using the one that I loaded into the working environment as my.vector \u0026lt;- c(1, 2, 3).\nWe could consider the objects created inside the function as local variables because they have local effect only, and the ones defined outside of the function as global variables. Other programming languages make a clear difference of this two and handle each of them differently, often by initiating the global variables with special characters, or creating them using special functions, in order to avoid mistakes and confusion. In R you should be very careful on how you name your objects and where you use them when you are creating functions.\nOn the other hand it has the advantage that it is very easy to create functions that use the same structure of data. For example, I could create a data frame called elements that will always contain the columns called Pb, As, Cd and Zn and then just make functions that take no arguments to do all my statistics at once by calling the same table and the same columns inside them.\nWhy to write functions As mentioned above, I started writing functions when I did my Ph.D. I was working with contaminated soils and basically for all my projects I had to analyze data of concentration of elements. This means that for each project, I had to repeat the same process for each element and then, for the next project do the same for the new data and for different or more elements. Luckily my first project was only focused on 4 different elements. I did a script for the statistics and visualizations of the first element, organize the workflow, decided what would be variable and what constant, and created two functions, one for the statistics and one for the visualizations, based on the output of the first one, and then just applied the functions to the remaining 3 elements.\nWhen I got the first results of my second experiment it was related to more than 10 different elements, and that only for soils, I knew that later I\u0026rsquo;d have to do the same statistics for different parts of the plants. Therefore I decided to create a package. I simply googled how to put all my functions together in a package, installed it and then, for each of my next data results I could simply call my own functions directly in my R environment from any folder and do all the statistical analysis way faster than I can even measure.\nLearning how to write functions in R is not only intended for processes or calculations that don\u0026rsquo;t have a particular function yet (today basically everything is cover in one or another package). It can save a lot of time in any kind of work you are doing. It can reduce the time you need for your data analysis and the amount of code written in your scripts. As a result it also makes your code more organized and more understandable. It can also help you to understand better how R works, as you need to get more familiar with the type of objects used, the structures of the functions, the application of conditionals and iterative processes, etc.\nFunctions are a key element of most (probably all) programming languages and thus, learning how to create your own will also develop your programming skills and teach you how to automatize tasks. There is a general informal rule for programming that is called the DRY principle, which means Don\u0026rsquo;t Repeat Yourself. In other words, if there is a process in your code/program/script that has to be repeated at least once, it is worth it to write a function and then call it twice with the different arguments that will be variable rather than coping the whole code from the first case and pasting it where the second case needs it and only changing the arguments that are variable in the second case. The next post will be exactly about that.\nFinal remarks I hope that this tutorial has reach its goal of showing how easy and useful is to write your own functions in R. I agree that all the functions created here had minimum practical application. It is usually the case when getting started. But right in our next post we are going to write our first complete function with practical application: A function that fills empty rows generated from merged cells imported from excel.\nStay in touch!\n","pubDate":"2021-11-30","title":"Functions in R"}];
    var search_theEnd = "The End";
    var search_nothing = "Nothing was found";
    var search_found = "Found";
    var search_result = "result";
    var search_results = "results";
    var enable_mermaid =  null 
</script>





        
    </body>
</html>

